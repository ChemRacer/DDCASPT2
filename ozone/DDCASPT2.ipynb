{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install --upgrade  h5py\n",
    "#######################################################\n",
    "#Import packages\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from math import sin, cos, pi\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import pickle\n",
    "from subprocess import call, check_output\n",
    "import pandas as pd\n",
    "# import psi4\n",
    "from joblib import Parallel,effective_n_jobs,delayed\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from plumbum.cmd import grep, awk\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "import sklearn\n",
    "from shutil import copy\n",
    "import csv\n",
    "import h5py as h5\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Obital labels\n",
    "## Inactive i,j\n",
    "## Active t,u,v\n",
    "## Virtual a,b\n",
    "\n",
    "## Type 1: IA->AA\n",
    "## Type 2: II->AA (P)\n",
    "## Type 3: II->AA (M)\n",
    "## Type 4: AA->VA\n",
    "## Type 5: IA->VA/AV\n",
    "## Type 6: II->AV (P)\n",
    "## Type 7: II->AV (M)\n",
    "## Type 8: AA->VV (P)\n",
    "## Type 9: AA->VV (M)\n",
    "## Type 10: IA->VV (P)\n",
    "## Type 11: IA->VV (M)\n",
    "## Type 12: II->VV (P)\n",
    "## Type 13: II->VV (M)\n",
    "\n",
    "## A: IA->AA\n",
    "## B: II->AA\n",
    "## C: AA->VA\n",
    "## D: IA->VA/AV\n",
    "## E: II->AV\n",
    "## F: AA->VV\n",
    "## G: IA->VV \n",
    "## H: II->VV\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete excessive extra files\n",
    "def del_useless():\n",
    "    '''\n",
    "    Delete the extra files\n",
    "    '''\n",
    "    for root, dirs, files in os.walk(os.getcwd()):\n",
    "        for file in files:\n",
    "            for j in ['status','GssOrb','LprOrb','LoProp','guessorb','xmldump','RasOrb','SpdOrb']:\n",
    "                if j in file:\n",
    "    #                 print(root,dirs,file)\n",
    "                    os.remove(os.path.join(root,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When restarting a setr of calculations just clear everyting out\n",
    "def clean_dir():\n",
    "    for entry in os.scandir(path=os.getcwd()):\n",
    "        if entry.is_dir():\n",
    "            if entry.name=='Fock':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if entry.name=='hdf5':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if entry.name=='e2':\n",
    "                shutil.rmtree(entry.name)                \n",
    "            if entry.name=='Labels':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if entry.name=='Coords':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if 'dir' in entry.name:\n",
    "                shutil.rmtree(entry.name)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before clean_dir, this pulls the xyz files out just to \n",
    "def pull_xyz():\n",
    "    import re\n",
    "    for i in struct_name:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),i))==False and os.path.exists(os.path.join(os.getcwd(),'Coords')):\n",
    "            shutil.copy(os.path.join(os.getcwd(),'/'.join(('Coords',i))),os.path.join(os.getcwd(),i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gateway(name,basis_set):\n",
    "    string=f'''&GATEWAY \n",
    "coord={f'{name}.xyz'}\n",
    "Basis = {basis_set}\n",
    "Group = nosymm\n",
    "Expert\n",
    "End of Input\n",
    "'''\n",
    "    return string\n",
    "\n",
    "def gen_seward():\n",
    "    string=f'''&SEWARD\n",
    "End of Input\n",
    "'''\n",
    "    return string\n",
    "\n",
    "def gen_motra(name):\n",
    "    string=f'''&MOTRA\n",
    "Frozen=0\n",
    ">>> COPY $WorkDir/GMJ_one_int_indx.csv $CurrDir/{name}.GMJ_one_int_indx.csv\n",
    ">>> COPY $WorkDir/GMJ_one_int.csv $CurrDir/{name}.GMJ_one_int.csv\n",
    ">>> COPY $WorkDir/GMJ_two_int_indx.csv $CurrDir/{name}.GMJ_two_int_indx.csv\n",
    ">>> COPY $WorkDir/GMJ_two_int.csv $CurrDir/{name}.GMJ_two_int.csv\n",
    "'''\n",
    "    return string\n",
    "\n",
    "def gen_scf(name):\n",
    "    string=f\"\"\"&SCF &END\n",
    ">>> COPY $WorkDir/{name}.scf.h5 $CurrDir/\n",
    "\"\"\"\n",
    "    return string    \n",
    "\n",
    "\n",
    "def gen_rasscf(name,e,o,i,previous=None):\n",
    "    start_string=\"\"\"&RASSCF &END\n",
    "Title= RASSCF\n",
    "\"\"\"\n",
    "    if previous!=None:\n",
    "        fileorb=f\"\"\"FileOrb\n",
    "{previous}\n",
    "\"\"\"\n",
    "    else:\n",
    "        fileorb=''\n",
    "\n",
    "    end_string=f\"\"\"\n",
    "NACTEL\n",
    "{e} 0 0\n",
    "Inactive\n",
    "{i}\n",
    "RAS2\n",
    "{o}\n",
    "Symmetry\n",
    "1\n",
    "Spin\n",
    "1\n",
    "orblisting\n",
    "all\n",
    "ITERation\n",
    "200 100\n",
    "CIMX\n",
    "200\n",
    "SDAV\n",
    "500\n",
    "PRWF\n",
    "0\n",
    "PRSD\n",
    ">>> COPY $WorkDir/{name}.rasscf.h5 $CurrDir/\n",
    ">>> COPY $WorkDir/GMJ_Fock_MO.csv $CurrDir/{name}.GMJ_Fock_MO.csv\n",
    "\"\"\"\n",
    "    return start_string+fileorb+end_string \n",
    "\n",
    "def gen_caspt2():\n",
    "    string=\"\"\"&CASPT2 &END\n",
    "Frozen \n",
    "0\n",
    "Imaginary Shift\n",
    "0.0\n",
    "\n",
    ">>foreach i in (B,E,F,G,H)\n",
    ">>foreach j in (P,M)\n",
    ">>if ( -FILE GMJ_e2_${i}_${j}.csv )\n",
    ">>> COPY $WorkDir/GMJ_RHS_${i}_${j}.csv $CurrDir/GMJ_RHS_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECW_${i}_${j}.csv $CurrDir/GMJ_IVECW_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_e2_${i}_${j}.csv $CurrDir/GMJ_e2_${i}_${j}.csv\n",
    ">>endif\n",
    ">>enddo\n",
    ">>enddo\n",
    "\n",
    ">>foreach i in (A,C,D)\n",
    ">>if ( -FILE GMJ_e2_$i.csv )\n",
    ">>> COPY $WorkDir/GMJ_RHS_$i.csv $CurrDir/GMJ_RHS_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECW_$i.csv $CurrDir/GMJ_IVECW_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_e2_$i.csv $CurrDir/GMJ_e2_$i.csv\n",
    ">>endif\n",
    ">>enddo\n",
    "\n",
    "\"\"\"\n",
    "    return string    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_set='ANO-RCC-VDZP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top='/home/grierjones/DDCASPT2/ozone'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 38\n"
     ]
    }
   ],
   "source": [
    "radius_range=np.arange(106,182,1)\n",
    "\n",
    "\n",
    "\n",
    "train_ind,test_ind=radius_range[0::2],radius_range[1::2]\n",
    "# train_test_split(radius_range, test_size=0.3, random_state=0)\n",
    "# print(len(train_ind),len(test_ind))\n",
    "# with open('train_ind.pickle', 'wb') as handle:\n",
    "#     pickle.dump(train_ind, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('test_ind.pickle', 'wb') as handle:\n",
    "#     pickle.dump(test_ind, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('test_ind.pickle', 'rb') as handle:\n",
    "    test_ind = pickle.load(handle)\n",
    "\n",
    "with open('train_ind.pickle', 'rb') as handle:\n",
    "    train_ind = pickle.load(handle)\n",
    "    \n",
    "print(len(train_ind),len(test_ind))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "    dirname=f'O3'\n",
    "    if os.path.exists(dirname)==False:\n",
    "        os.mkdir(dirname)\n",
    "        \n",
    "        \n",
    "    for idxr, r in enumerate(radius_range):\n",
    "        \n",
    "        # Loop radius\n",
    "        name=f\"O3_{int(r)}\"\n",
    "\n",
    "        # Create files\n",
    "        if os.path.exists(os.path.join(dirname,f'{name}'))==False:\n",
    "            os.mkdir(os.path.join(dirname,f'{name}'))\n",
    "\n",
    "        # Write xyz\n",
    "        with open(os.path.join(dirname,f'{name}',f'{name}.xyz'),'w') as f:\n",
    "            f.write(f'{3}\\n\\n')\n",
    "            \n",
    "            radius=1.278\n",
    "            f.write(f\"\"\"O {radius*cos(((int(r)/2)*(pi/180))):>8f} {radius*sin((int(r)/2)*(pi/180)):>8f} {0.0000:>8f}\n",
    "O {0:>8f} {0:>8f} {0:>8f}\n",
    "O {radius*cos(-(int(r)/2)*(pi/180)):>8f} {radius*sin(-(int(r)/2)*(pi/180)):>8f} {0:>8f}\n",
    "\"\"\")\n",
    "        # Write input\n",
    "        with open(os.path.join(dirname,f'{name}',f'{name}.input'),'wb') as g:\n",
    "            g.write(gen_gateway(name,basis_set).encode())\n",
    "            g.write(gen_seward().encode())\n",
    "            g.write(gen_motra(name).encode())\n",
    "            g.write(gen_scf(name).encode())   \n",
    "            # Choose active space and inactive orbitals\n",
    "            #g.write(gen_rasscf(name,2,2,int((i/2)-1)).encode())\n",
    "            if idxr==0:\n",
    "                g.write(gen_rasscf(name,4,3,10,previous=None).encode()) # int((i/2)-1)\n",
    "            else:\n",
    "\n",
    "                previous=os.path.join(top,dirname,f'O3_{radius_range[idxr-1]:.2f}',f\"O3_{radius_range[idxr-1]:.2f}.RasOrb\")\n",
    "                g.write(gen_rasscf(name,4,3,10,previous=previous).encode()) # int((i/2)-1)\n",
    "            g.write(gen_caspt2().encode())\n",
    "\n",
    "        # Change dir\n",
    "        if os.getcwd()!=os.path.join(dirname,f'{name}'):    \n",
    "            os.chdir(os.path.join(dirname,f'{name}'))\n",
    "\n",
    "        # Run\n",
    "        call(['pymolcas','-new','-clean',f'{name}.input', '-oe', f'{name}.output'])\n",
    "\n",
    "        # Back to top dir\n",
    "        if os.getcwd()!=top:\n",
    "            os.chdir(top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_energy():\n",
    "    chain_E={}\n",
    "    drop=[]\n",
    "    for i in chains:\n",
    "        energy=[]\n",
    "        dirname=f'O3'\n",
    "        # Loop radius\n",
    "        for idr,r in enumerate(radius_range):\n",
    "            name=f\"O3_{int(r)}\"\n",
    "            try:\n",
    "                output=os.path.join(dirname,f'{name}',f'{name}.output')\n",
    "                energy.append([r,float((grep['-i', '::    CASPT2',output] | awk['{print $NF }'])())])\n",
    "            except:\n",
    "                energy.append([r,0])\n",
    "                drop.append(idr)\n",
    "        chain_E[i]=np.array(energy)\n",
    "\n",
    "    for i in chains:\n",
    "        chain_E[i]=chain_E[i][~np.in1d(range(len(chain_E[i])),drop)]    \n",
    "        pd.DataFrame(chain_E[i],columns=['radius','energy']).to_csv(f'O3/CASPT2.csv')\n",
    "        \n",
    "\n",
    "    casscf_E={}\n",
    "    for i in chains:\n",
    "        casscf_energy=[]\n",
    "        dirname=f'O3'\n",
    "        # Loop radius\n",
    "        for idr,r in enumerate(radius_range):\n",
    "            name=f\"O3_{int(r)}\"\n",
    "            try:\n",
    "                output=os.path.join(dirname,f'{name}',f'{name}.output')\n",
    "                casscf_energy.append([r,float((grep['-i', '::    RASSCF root number  1',output] | awk['{print $8 }'])())])\n",
    "            except:\n",
    "                casscf_energy.append([r,0])\n",
    "        casscf_E[i]=np.array(casscf_energy)\n",
    "\n",
    "    for i in chains:\n",
    "        casscf_E[i]=casscf_E[i][~np.in1d(range(len(casscf_E[i])),drop)]    \n",
    "        pd.DataFrame(casscf_E[i],columns=['radius','energy']).to_csv(f'O3/CASSCF.csv')        \n",
    "        \n",
    "\n",
    "    E2_E={}\n",
    "    for i in chains:\n",
    "        E2_energy=[]\n",
    "        dirname=f'O3'\n",
    "        # Loop radius\n",
    "        for idr,r in enumerate(radius_range):\n",
    "            name=f\"O3_{int(r)}\"\n",
    "            try:\n",
    "                output=os.path.join(dirname,f'{name}',f'{name}.output')\n",
    "                E2_energy.append([r,float((grep['-i', 'E2 (Variational):',output] | awk['{print $NF }'])())])\n",
    "            except:\n",
    "                E2_energy.append([r,0])\n",
    "        E2_E[i]=np.array(E2_energy)\n",
    "\n",
    "    for i in chains:\n",
    "        E2_E[i]=E2_E[i][~np.in1d(range(len(E2_E[i])),drop)]    \n",
    "        pd.DataFrame(E2_E[i],columns=['radius','energy']).to_csv(f'O3/E2.csv')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=sns.color_palette('rocket',7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chains' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58506/1037949652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# gen_energy()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msharex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchains\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mCASSCF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"O3/CASSCF.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mCASPT2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"O3/CASPT2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chains' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gen_energy()\n",
    "fig,ax=plt.subplots(2,2,figsize=(10,6),sharex=True)\n",
    "for idx,i in enumerate(chains):\n",
    "    CASSCF=pd.read_csv(f\"O3/CASSCF.csv\",index_col=0).to_numpy()\n",
    "    CASPT2=pd.read_csv(f\"O3/CASPT2.csv\",index_col=0).to_numpy()\n",
    "    if i<=4:\n",
    "        ax[0,idx%2].plot(CASSCF[:,0],CASSCF[:,1],color=cmap[idx],label='CASSCF')\n",
    "        ax[0,idx%2].plot(CASPT2[:,0],CASPT2[:,1],'--',color=cmap[idx],label='CASPT2')\n",
    "        ax[0,idx%2].legend()\n",
    "        ax[0,idx%2].set_title(f\"H$_{i}$\")\n",
    "        ax[0,idx%2].set_xlabel(\"Radius (Å)\")\n",
    "        ax[0,idx%2].set_ylabel(\"Energy (E$_{h}$)\")\n",
    "    else:\n",
    "        ax[1,idx%2].plot(CASSCF[:,0],CASSCF[:,1],color=cmap[idx],label='CASSCF')\n",
    "        ax[1,idx%2].plot(CASPT2[:,0],CASPT2[:,1],'--',color=cmap[idx],label='CASPT2')\n",
    "        ax[1,idx%2].legend()\n",
    "        ax[1,idx%2].set_title(\"H$_{\"+str(i)+\"}$\")\n",
    "        ax[1,idx%2].set_xlim(0.5,3.1)\n",
    "        ax[1,idx%2].set_xticks(np.round(np.linspace(min(radius_range),max(radius_range),4),2))\n",
    "        ax[1,idx%2].set_xlabel(\"Radius (Å)\")\n",
    "        ax[1,idx%2].set_ylabel(\"Energy (E$_{h}$)\")        \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('energies.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,i in enumerate(chains):\n",
    "    CASSCF=pd.read_csv(f\"O3/CASSCF.csv\",index_col=0).to_numpy()\n",
    "    CASPT2=pd.read_csv(f\"O3/CASPT2.csv\",index_col=0).to_numpy()\n",
    "    plt.plot(CASSCF[:,0],CASSCF[:,1],color=cmap[idx],label=f'CASSCF H$_{i}$')\n",
    "    plt.plot(CASPT2[:,0],CASPT2[:,1],'--',color=cmap[idx],label=f'CASPT2 H$_{i}$')    \n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "#   Keep everything at float64\n",
    "DTYPE = np.float_\n",
    "# DTYPE = np.float16\n",
    "\n",
    "#   Create an array with the easy data\n",
    "def createArrray(filename):\n",
    "    files = sorted(glob(filename))\n",
    "    arrayname = []\n",
    "    for i in sorted(files):\n",
    "        arrayname.append(\n",
    "            np.stack(\n",
    "                np.array(pd.read_csv(i, header=None),\n",
    "                         dtype=DTYPE,\n",
    "                         copy=False).flatten()))\n",
    "\n",
    "    arrayname = np.asarray(arrayname, dtype=DTYPE)\n",
    "    return arrayname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Start transforming the HDF5 files from the data directory\n",
    "h5list = sorted(glob('O3/*/*rasscf.h5'))\n",
    "f = h5.File(h5list[0], 'r')\n",
    "datasetNames = [n for n in f.keys()]\n",
    "b = []\n",
    "labels = []\n",
    "\n",
    "# Useful attributes from the hdf5 files\n",
    "NBAS=[]\n",
    "NACTEL=[]\n",
    "for k, elem in enumerate(h5list):\n",
    "    for count, ele in enumerate([i for i in f.attrs]):\n",
    "        if ele =='NBAS':\n",
    "            for i, elemt in enumerate(np.array(h5.File(h5list[k],'r').attrs[ele]).reshape(-1)):\n",
    "                NBAS.append(elemt)\n",
    "        if ele =='NACTEL':\n",
    "            for i, elemt in enumerate(np.array(h5.File(h5list[k],'r').attrs[ele]).reshape(-1)):\n",
    "                NACTEL.append(elemt)\n",
    "\n",
    "\n",
    "MO_ENERGIES=[]\n",
    "MO_OCCUPATIONS=[]\n",
    "MO_TYPEINDICES=[]\n",
    "MO_VECTORS=[]\n",
    "t0=time()\n",
    "#   Eliminate certain features that won't be good for regression\n",
    "for k, elem in enumerate(h5list):\n",
    "    for count, ele in enumerate([n for n in h5.File(elem, 'r').keys()]):\n",
    "        if ele =='MO_TYPEINDICES':\n",
    "            for i, elemt in enumerate(np.array(h5.File(elem,'r')[ele]).reshape(-1)):\n",
    "                MO_TYPEINDICES.append(elemt)\n",
    "\n",
    "        if ele =='MO_ENERGIES':\n",
    "            for i, elemt in enumerate(np.array(h5.File(elem,'r')[ele]).reshape(-1)):\n",
    "                MO_ENERGIES.append(elemt)\n",
    "\n",
    "        if ele =='MO_OCCUPATIONS':\n",
    "            for i, elemt in enumerate(np.array(h5.File(elem,'r')[ele]).reshape(-1)):\n",
    "                MO_OCCUPATIONS.append(elemt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'time: {time()-t0} s')\n",
    "shape=len(h5list),int(NBAS[0])\n",
    "# AO_FOCKINT_MATRIX=np.array(AO_FOCKINT_MATRIX).reshape(len(dislist),int(NBAS[0]),int(NBAS[0]))\n",
    "MO_ENERGIES= np.array(MO_ENERGIES).reshape(shape)\n",
    "MO_OCCUPATIONS= np.array(MO_OCCUPATIONS).reshape(shape)\n",
    "MO_TYPEINDICES=np.array(MO_TYPEINDICES).reshape(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5list_scf = sorted(glob('O3/*/*.scf.h5'))\n",
    "f = h5.File(h5list_scf[0], 'r')\n",
    "datasetNames = [n for n in f.keys()]\n",
    "b = []\n",
    "labels = []\n",
    "# AO_FOCKINT_MATRIX=[]\n",
    "# Useful attributes from the hdf5 files\n",
    "NBAS=[]\n",
    "NACTEL=[]\n",
    "for k, elem in enumerate(h5list_scf):\n",
    "    for count, ele in enumerate([i for i in f.attrs]):\n",
    "        if ele =='NBAS':\n",
    "            for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r').attrs[ele]).reshape(-1)):\n",
    "                NBAS.append(elemt)\n",
    "MO_VECTORS=[]\n",
    "scf_F=[]  \n",
    "scf_OCC=[]\n",
    "t0=time()\n",
    "#   Eliminate certain features that won't be good for regression\n",
    "for k, elem in enumerate(h5list_scf):\n",
    "    for count, ele in enumerate([n for n in h5.File(h5list_scf[k], 'r').keys()]):\n",
    "        if ele =='MO_VECTORS':\n",
    "            for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r')[ele]).reshape(-1)):\n",
    "                MO_VECTORS.append(elemt)\n",
    "        if ele =='MO_ENERGIES':\n",
    "            for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r')[ele]).reshape(-1)):\n",
    "                scf_F.append(elemt)\n",
    "        if ele =='MO_OCCUPATIONS':\n",
    "            for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r')[ele]).reshape(-1)):\n",
    "                scf_OCC.append(elemt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f'time: {time()-t0} s')\n",
    "scf_F= np.array(MO_ENERGIES).reshape(shape)\n",
    "scf_OCC= np.array(MO_OCCUPATIONS).reshape(shape)\n",
    "MO_VECTORS=np.array(MO_VECTORS).reshape(len(h5list),int(NBAS[0]),int(NBAS[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists=sorted(sum(list([j.replace('GMJ_e2_','') for j in i.split('/')[-1].split('.') if 'GMJ' in j] for i in glob('O3/O3_106/GMJ_e2_*.csv')),[]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the labels that match the IVECW and IVECC2 files\n",
    "def gen_labels(path,typ):\n",
    "    return [j.split()[0].replace('\\n','').replace('00','').replace('S0','S').replace('I0','I').replace(',','') for j in pd.read_csv(f'{path}/GMJ_RHS_{typ}.csv',header=None)[0]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair_labels(path,typ):\n",
    "    Labels=[]\n",
    "    Indexes=[]\n",
    "    return sorted(set(['_'.join(j.split()[0].replace('\\n','').replace('00','').replace('S0','S').replace('I0','I').replace(',','').split('_')[0:2]) for j in open(f'{path}/GMJ_RHS_{typ}.csv','r').readlines()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dim_dict(path,typ_exists):\n",
    "    '''    \n",
    "    Dimension check for DDCASPT2: check the ordering of the pair-energies,\n",
    "    this notation follows a mix of the papers and code.\n",
    "    \n",
    "    A (IA->AA): \\n TIUV \\n E_{ti} E_{uv} \\n pqrs=tiuv=0123 \\n    \n",
    "    B_P (II->AA) (P): \\n IJTU \\n E_{ti} E_{uj} \\n pqrs=tiuj=2031 \\n\n",
    "    B_M (II->AA) (M): \\n IJTU \\n E_{ti} E_{uj} \\n pqrs=tiuj=2031 \\n\n",
    "    C (AA->VA): \\n UVAT \\n E_{at} E_{uv} \\n pqrs=atuv=2301 \\n\n",
    "    D (IA->VA/AV): \\n IUAT/IUTA \\n E_{ai} E_{tu}/E_{ti} E_{au} \\n pqrs=(a/t)i(t/a)u=2031 \\n\n",
    "    E_P (II->AV) (P): \\n IJAT \\n E_{ti} E_{aj} \\n pqrs=tiaj=3021 \\n\n",
    "    E_M (II->AV) (M): \\n IJAT \\n E_{ti} E_{aj} \\n pqrs=tiaj=3021 \\n\n",
    "    F_P (AA->VV) (P): \\n TUAB \\n E_{at} E_{bu} \\n pqrs=atbu=2031 \\n\n",
    "    F_M (AA->VV) (M): \\n TUAB \\n E_{at} E_{bu} \\n pqrs=atbu=2031 \\n\n",
    "    G_P (IA->VV) (P): \\n ITAB \\n E_{ai} E_{bt} \\n pqrs=aibt=2031 \\n\n",
    "    G_M (IA->VV) (M): \\n ITAB \\n E_{ai} E_{bt} \\n pqrs=aibt=2031 \\n\n",
    "    H_P (II->VV) (P): \\n IJAB \\n E_{ai} E_{bj} \\n pqrs=aibj=2031 \\n\n",
    "    H_M (II->VV) (M): \\n IJAB \\n E_{ai} E_{bj} \\n pqrs=aibj=2031 \\n\n",
    "    '''    \n",
    "    dims=[]\n",
    "    for typ in typ_exists:\n",
    "        dims.append((typ,np.array([i.split('=')[-1].split('x') for i in open(os.path.join(f'{path}',f'GMJ_e2_{typ}.csv'),'r').readlines() if 'mat. size =' in i ]).flatten().astype(int)))\n",
    "    return dict(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_dict=gen_dim_dict('O3/O3_106/',typ_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(lst):   \n",
    "    return '_'.join(i.replace('A00','A').replace('I00','I').replace('S00','S').replace('I0','I').replace('A0','A').replace('S0','S') for i in lst.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ordered(path,typ):\n",
    "    '''\n",
    "    Return a dataframe for each type\n",
    "    Index=proper indexing\n",
    "    level_0=row\n",
    "    level_1=column\n",
    "    0=W value\n",
    "    '''\n",
    "    ordered=pd.read_csv(os.path.join(path,f'GMJ_IVECW_{typ}.csv'),delim_whitespace=True, skiprows=[0],header=None).astype(np.float64).dropna(axis=1)\n",
    "    ordered.columns=list(range(len(ordered.columns)))\n",
    "    ordered=ordered.stack()\n",
    "    df=pd.read_csv(os.path.join(path,f'GMJ_RHS_{typ}.csv'),header=None,delimiter=',',index_col=0)\n",
    "    df.index=list(map(strip,df.index))\n",
    "    merged=ordered.reset_index().sort_values(by=0).set_index(df.sort_values(by=1).index).sort_values(['level_0','level_1'])    \n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate IVECW\n",
    "def gen_e2(paths,typ):\n",
    "    e2=[]\n",
    "    \n",
    "    for i in paths:\n",
    "        proper_labels=gen_labels(i,typ)\n",
    "        df=pd.read_csv(os.path.join(i,f'GMJ_e2_{typ}.csv'),delim_whitespace=True, skiprows=[0],header=None).astype(np.float64).dropna(axis=1).stack()\n",
    "        df.index=gen_ordered(i,typ).index\n",
    "        df=df.to_frame(name=str(i.split('/')[1].split('_')[1]))\n",
    "        e2.append(df)\n",
    "    df1=pd.concat(e2,axis=1).loc[proper_labels]\n",
    "    df1.index=[i for idx,i in enumerate(proper_labels)]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair(paths,typ):\n",
    "    Y=gen_e2(paths,typ).astype(float)\n",
    "# Needs to be qs, we're summing over the occupied orbitals    \n",
    "    Y_pair_set=list(set(['_'.join((i.split('_')[0],i.split('_')[1]))+'_' for i in Y.index.tolist()]))\n",
    "    Y_pair_df=pd.concat([Y[Y.index.str.find(j)==0].sum() for j in Y_pair_set],axis=1)\n",
    "    Y_pair_df.columns=list(set(['_'.join((i.split('_')[0],i.split('_')[1])) for i in Y.index.tolist()]))\n",
    "    return Y_pair_df.T.sort_index().groupby(level=0).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_label(path,typ):\n",
    "    if f'{typ}_M' in typ_exists and f'{typ}_P' in typ_exists:\n",
    "        return gen_pair_labels(path,f'{typ}_P')+gen_pair_labels(path,f'{typ}_M')\n",
    "    elif f'{typ}_P' in typ_exists:\n",
    "        return gen_pair_labels(path,f'{typ}_P')\n",
    "    elif f'{typ}_M' in typ_exists:\n",
    "        return gen_pair_labels(path,f'{typ}_M')\n",
    "    elif f'{typ}' in typ_exists:\n",
    "        return gen_pair_labels(path,f'{typ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_e2(path,typ):\n",
    "    if f'{typ}_M' in typ_exists and f'{typ}_P' in typ_exists:\n",
    "        df=pd.concat([gen_pair(path,f'{typ}_M'),gen_pair(path,f'{typ}_P')],axis=0).groupby(level=0).sum()\n",
    "        return df\n",
    "    elif f'{typ}_P' in typ_exists:\n",
    "        return gen_pair(path,f'{typ}_P').groupby(level=0).sum()\n",
    "    elif f'{typ}_M' in typ_exists:\n",
    "        return gen_pair(path,f'{typ}_M').groupby(level=0).sum()\n",
    "    elif f'{typ}' in typ_exists:\n",
    "        return gen_pair(path,f'{typ}').groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths=glob('O3/O3_*/')\n",
    "path=paths[0]\n",
    "# Generate the data\n",
    "for typ in set([i.split('_')[0] for i in typ_exists ]):\n",
    "    if typ=='A':\n",
    "        typA_e2=stack_e2(paths,typ)\n",
    "        typA_labels=stack_label(path,typ)\n",
    "        \n",
    "    if typ=='B':        \n",
    "        typB_e2=stack_e2(paths,typ)\n",
    "        typB_labels=stack_label(path,typ)\n",
    "        \n",
    "    if typ=='C':\n",
    "        typC_e2=stack_e2(paths,typ)\n",
    "        typC_labels=stack_label(path,typ)\n",
    "        \n",
    "    if typ=='D':        \n",
    "        typD_e2=stack_e2(paths,typ)\n",
    "        typD_labels=stack_label(path,typ)\n",
    "                \n",
    "    if typ=='E':\n",
    "        typE_e2=stack_e2(paths,typ)\n",
    "        typE_labels=stack_label(path,typ)\n",
    "                \n",
    "    if typ=='F':        \n",
    "        typF_e2=stack_e2(paths,typ)\n",
    "        typF_labels=stack_label(path,typ)\n",
    "                \n",
    "    if typ=='G':        \n",
    "        typG_e2=stack_e2(paths,typ)\n",
    "        typG_labels=stack_label(path,typ)\n",
    "                \n",
    "    if typ=='H':  \n",
    "        typH_e2=stack_e2(paths,typ)\n",
    "        typH_labels=stack_label(path,typ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_e2=pd.concat([gen_e2(paths,typ) for typ in typ_exists]).groupby(level=0).sum()\n",
    "E2Dict=pd.read_csv(f\"O3/E2.csv\",index_col=0).to_numpy()\n",
    "# stacked_e2.columns=[float(i.split('/')[1].split('_')[1]) for i in stacked_e2.columns]\n",
    "stacked_e2=stacked_e2.sum(axis=0).sort_index().reset_index().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(E2Dict[:,1],stacked_e2[:,1])\n",
    "plt.plot(E2Dict[:,1],E2Dict[:,1],'k--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pairs=pd.concat([stack_e2(paths,typ) for typ in typ_exists]).groupby(level=0).sum()\n",
    "pair_labels=stacked_pairs.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_stack=pd.concat([gen_e2(paths,typ) for typ in typ_exists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indx(list_of_dicts):\n",
    "    indx=[]\n",
    "    for i in list_of_dicts.keys():\n",
    "        if len(list_of_dicts[i])>0:\n",
    "            indx.append(list(list_of_dicts[i].keys()))\n",
    "    return indx[0]\n",
    "\n",
    "\n",
    "path_check='O3/O3_106/O3_106.output'\n",
    "\n",
    "# Sanity check...\n",
    "# REMEVDZPER FROZEN CORE APPROXIMATION\n",
    "# Number of frozen orbitals\n",
    "fro=int(subprocess.Popen(f\"grep -i 'Frozen orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of inactive orbitals\n",
    "inact=int(subprocess.Popen(f\"grep -i 'Inactive orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of active orbitals\n",
    "act=int(subprocess.Popen(f\"grep -i 'Active orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of seconary orbitals\n",
    "virt=int(subprocess.Popen(f\"grep -i 'Secondary orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of basis functions for sanity check\n",
    "bas_check=int(subprocess.Popen(f\"grep -i 'Number of basis functions' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "\n",
    "Basis_Indices=[]\n",
    "for i in range(fro):\n",
    "    Basis_Indices.append(f'F{i+1}')\n",
    "for i in range(inact):\n",
    "    Basis_Indices.append(f'I{i+1}')\n",
    "for i in range(act):\n",
    "    Basis_Indices.append(f'A{i+1}')\n",
    "for i in range(virt):\n",
    "    Basis_Indices.append(f'S{i+1}')    \n",
    "    \n",
    "print(f'Basis sanity check passed={bas_check==len(Basis_Indices)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab molecular orbital occupations and make it into a dataframe labeled with xyz file name\n",
    "MO_OCC=[]\n",
    "for j in range(len(chains)):\n",
    "    MO_OCC.append(dict(zip(Basis_Indices,[i for i in list(MO_OCCUPATIONS[j])])))\n",
    "MO_OCC_Dict=dict(zip([str(k) for k in paths],MO_OCC))\n",
    "MO_OCC_DF=pd.DataFrame(MO_OCC_Dict)\n",
    "\n",
    "# Dataframe of MO occupation, index=basis indices and columns=paths\n",
    "MO_OCCUPATIONS_DF=pd.DataFrame(MO_OCCUPATIONS,index=paths,columns=Basis_Indices).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Keep in mind HDF5 zeroes out the actrive orbitals... we'll use the Fock matrix to recover these\n",
    "# \n",
    "# Grab molecular orbital energy and make it into a dataframe labeled with xyz file name\n",
    "MO_ENERGIES=[]\n",
    "for j in paths:\n",
    "    MO_ENERGIES.append(np.genfromtxt(os.path.join(j,f\"{j.split('/')[1]}.GMJ_Fock_MO.csv\"), delimiter=''))\n",
    "\n",
    "\n",
    "# Dataframe of MO energies, index=basis indices and columns=paths\n",
    "MO_ENERGIES_DF=pd.DataFrame(MO_ENERGIES,index=paths,columns=Basis_Indices).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Basis_Indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_int():\n",
    "    one_int=[]\n",
    "    Labels=[]\n",
    "    Indexes=[]\n",
    "    upd_1int_indx=[]\n",
    "    def one_gener(i):\n",
    "        return pd.DataFrame(np.genfromtxt(os.path.join(i,f\"{i.split('/')[1]}.GMJ_one_int.csv\"), delimiter='',dtype=float),index=Basis_Indices,columns=Basis_Indices)\n",
    "            \n",
    "\n",
    "#     Dict=dict(zip(Indexes,Labels))\n",
    "    return dict((i,one_gener(i)) for i in paths)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time()\n",
    "int1=gen_one_int()\n",
    "print(f'Integrals loaded in {time()-t0:0.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"precision\", 2)\n",
    "# np.set_printoptions(precision=2)\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "\n",
    "\n",
    "nmo=len(Basis_Indices)\n",
    "indice=[]\n",
    "ad_ind=[]\n",
    "for ind,i in enumerate(range(nmo)):\n",
    "    for indx,j in enumerate(range(nmo)):\n",
    "        ad_ind.append(f'{i+1}_{j+1}')\n",
    "        if j<=i:\n",
    "            indice.append(f'{i+1}_{j+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indice),len(ad_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# raw_MO=pd.DataFrame(np.genfromtxt(os.path.join(path_to_2_ints,f'{paths[0]}.GMJ_two_int.csv'), delimiter='',dtype=float),index=indice,columns=indice)\n",
    "\n",
    "# # This is wrong\n",
    "# for ind,a in enumerate(indice):\n",
    "#     for indx,b in enumerate(indice):\n",
    "#         if a!=b:\n",
    "#             print(a.split('_'),b.split('_'))\n",
    "#             # print(f'{j+1}_{i+1}',raw_MO[f'{j+1}_{i+1}'])\n",
    "#             # raw_MO.loc[f'{j+1}_{i+1}']=AO_DF.loc[f'{i+1}_{j+1}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def gen_MO(k):\n",
    "    \n",
    "    if os.path.exists(os.path.join(k,f\"{k.split('/')[1]}.GMJ_two_int.csv\"))==True:\n",
    "\n",
    "        raw_MO=np.genfromtxt(os.path.join(k,f\"{k.split('/')[1]}.GMJ_two_int.csv\")).reshape(len(Basis_Indices),len(Basis_Indices),len(Basis_Indices),len(Basis_Indices))\n",
    "    return raw_MO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featurelist=list()\n",
    "# def GenerateFeatures(wf_object, Miller=False, values=4):\n",
    "#     b =   wf_object.triplecheck\n",
    "\n",
    "#     #c = np.log10(np.absolute(wf_object.get_MO('oovv')*wf_object.t2start))\n",
    "#     ##infcheck=(c == -np.inf)\n",
    "#     #c[infcheck]=20\n",
    "\n",
    "#     #d = wf_object.pairs\n",
    "\n",
    "#     if Miller == False:\n",
    "#         for i in range(b.shape[0]):\n",
    "#             for j in range (b.shape[1]):\n",
    "#                 print('Top',i,j)\n",
    "#                 featurelist.clear()\n",
    "# # sort MP2 two-electron excitations e_{ij}^{ab} for ij\n",
    "# # (most negative, …, smallest negative, …, smallest positive, …, largest positive)\n",
    "# # [:values]=first x values        \n",
    "# # [-values:]=last x values\n",
    "#                 ind=np.argsort(b[i,j].flatten(),axis=0)\n",
    "# # εij{MP2}\n",
    "#                 new=np.sum(b[i,j])#0\n",
    "# #                 featurelist.append('Pair_Energy')\n",
    "# # <ii||jj>        \n",
    "#                 new=np.hstack((new,wf_object.MO[i,i,j,j]))\n",
    "# # screen1 first 4 values (i) <ii||aa>\n",
    "#                 new=np.hstack((new,np.take_along_axis(wf_object.screen1[i,j].flatten(), ind, axis=0)[:values]))#1,2,3,4\n",
    "# # screen2 first 4 values (j) <jj||bb>\n",
    "#                 new=np.hstack((new,np.take_along_axis(wf_object.screen2[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "# # <aa||bb> matrix first 4 values \n",
    "#                 new=np.hstack((new,np.take_along_axis(wf_object.screenvirt[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "# # e_{ij}^{ab}{MP2} first 4 values\n",
    "#                 new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values]))#17,18,19,20\n",
    "#                 if i==j:       \n",
    "# # <ii||jj> is excluded since i==j                \n",
    "#                     ind=np.argsort(b[i,j].flatten(),axis=0)\n",
    "# # εij{MP2}                    \n",
    "#                     new=np.sum(b[i,j])#0\n",
    "# # screen1 first 4 values (i)\n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen1[i,j].flatten(), ind, axis=0)[:values]))#1,2,3,4\n",
    "# # screen2 first 4 values (j)       \n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen2[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "# # screen1 last 4 values (i)\n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen1[i,j].flatten(), ind, axis=0)[-values:]))#1,2,3,4\n",
    "# # screen2 last 4 values (j)\n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen2[i,j].flatten(), ind, axis=0)[-values:]))#9,10,11,12\n",
    "\n",
    "# # e_{ij}^{ab}{MP2} first 4 values                    \n",
    "#                     new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values]))#17,18,19,20\n",
    "# # e_{ij}^{ab}{MP2} last 4 values    \n",
    "#                     new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:]))#17,18,19,20\n",
    "# # Missing εij{MP2} correlation in representation                    \n",
    "#                     one=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:])\n",
    "#                     two=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values])\n",
    "#                     new=np.hstack((new, np.sum(b[i,j])-one-two))\n",
    "#                     featurelist.append('triplecheck1')\n",
    "#                 else:\n",
    "# # i!=j                    \n",
    "#                     ind=np.argsort(b[i,j].flatten(),axis=0)\n",
    "# # εij{MP2}    \n",
    "#                     new=np.sum(b[i,j])#0      \n",
    "# # <ii||jj>                    \n",
    "#                     new=np.hstack((new,wf_object.MO[i,i,j,j]))\n",
    "# # screen1 first 4 values (i)\n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen1[i,j].flatten(), ind, axis=0)[:values]))#1,2,3,4\n",
    "# # screen2 first 4 values (j)                    \n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen2[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "# # screen1 last 4 values (i)\n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen1[i,j].flatten(), ind, axis=0)[-values:]))#1,2,3,4\n",
    "# # screen2 last 4 values (j)                    \n",
    "#                     new=np.hstack((new,np.take_along_axis(wf_object.screen2[i,j].flatten(), ind, axis=0)[-values:]))#9,10,11,12\n",
    "# # e_{ij}^{ab}{MP2} first 4 values                                        \n",
    "#                     new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values]))#17,18,19,20\n",
    "# # e_{ij}^{ab}{MP2} last 4 values    \n",
    "#                     new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:]))#17,18,19,20                    \n",
    "# # Missing εij{MP2} correlation in representation                    \n",
    "#                     one=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:])\n",
    "#                     two=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values])\n",
    "#                     new=np.hstack((new, np.sum(b[i,j])-one-two))\n",
    "\n",
    "\n",
    "#                 if ((i==0) and (j==0)):\n",
    "#                     a=new.copy()\n",
    "#                     diag=wf_object.pairs[i,j]\n",
    "#                 elif ((i==0) and (j==1)):\n",
    "#                     g=new.copy()\n",
    "#                     offdiag=wf_object.pairs[i,j]\n",
    "#                 elif (i==j):        \n",
    "#                     a=np.vstack((a,new))#41\n",
    "#                     diag=np.vstack((diag,wf_object.pairs[i,j]))\n",
    "#                 elif (j > i):\n",
    "#                     g=np.vstack((g,new))#41\n",
    "#                     offdiag=np.vstack((offdiag,wf_object.pairs[i,j]))\n",
    "#         return a,diag,g,offdiag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "froz=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('F')]\n",
    "inact=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('I')]\n",
    "act=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('A')]\n",
    "virt=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('S')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen_F=dict(zip(paths,scf_F))\n",
    "# gen_occ=dict(zip(paths,scf_OCC))\n",
    "\n",
    "gen_F=MO_ENERGIES_DF\n",
    "gen_occ=MO_OCCUPATIONS_DF\n",
    "gen_F_SCF=pd.DataFrame(scf_F,columns=Basis_Indices,index=paths).T\n",
    "gen_occ_SCF=pd.DataFrame(scf_OCC,columns=Basis_Indices,index=paths).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Basis_Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_set=sorted(set(sum([gen_pair_labels(path,typ) for typ in typ_exists],[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite the jacob style featurization step\n",
    "occcc=len(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=0])\n",
    "virttt=len(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START HERE TOMORROW\n",
    "- Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argged=np.argsort(dummy_stack.abs().values,axis=0).T\n",
    "top_excits={}\n",
    "for idxc,c in enumerate(dummy_stack.columns):\n",
    "    top_excits[c]=dummy_stack[c].iloc[argged[idxc]].iloc[-4:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gen_big_4(object):\n",
    "    '''\n",
    "    Generate a set of i,j,k,l indices corresponding to the largest 4 two-electron excitations \n",
    "    per pair-energy.\n",
    "\n",
    "    !!!From here on out we need to use the same training set and test set.!!!\n",
    "    Indices:\n",
    "    i-internal\n",
    "    j-internal\n",
    "    k-external\n",
    "    l-external\n",
    "\n",
    "    '''    \n",
    "    # Pick 4 largest contributers to the pair energy\n",
    "    def big_4(self,dist):\n",
    "        return [['_'.join(k.split('_')[2:4]) for k in dummy_stack.loc[[ j for j in dummy_stack.index.tolist() if j.split('_')[0]==i.split('_')[0] and j.split('_')[1]==i.split('_')[1]]][dist].abs().sort_values(ascending=False).index[0:4].tolist()] for i in stacked_pairs.index.tolist()]\n",
    "    \n",
    "    def gen_ijkl(self):\n",
    "        # Dimensions: training index x pair energies x top 4 most frequent virtual orbitals for two electrion excitations\n",
    "        \n",
    "        self.train_4=np.array(Parallel(n_jobs=6,verbose=10)(delayed(self.big_4)(f'{i:.2f}') for i in train_ind))\n",
    "        print(self.train_4.shape)\n",
    "        # Most frequent: list of tuples containing (pair energy index, [top 4 most frequent virtual orbitals for two electrion excitations])\n",
    "        # This can serve as a label too.\n",
    "        self.train_freq=[(i,pd.DataFrame(self.train_4[:,idx,:]).describe().loc['top'].tolist()) for idx,i in enumerate(stacked_pairs.index.tolist())]\n",
    "        # i,j, set of 4 largest [(k,l)]\n",
    "        self.set_ijkl_indices=[(Basis_Indices.index(i.split('_')[0]),Basis_Indices.index(i.split('_')[1]),[(Basis_Indices.index(k.split('_')[0]),Basis_Indices.index(k.split('_')[1])) for k in pd.DataFrame(self.train_4[:,idx,:]).describe().loc['top'].tolist()]) for idx,i in enumerate(stacked_pairs.index.tolist())]\n",
    "        internal_basis=[i for i in Basis_Indices if 'S' not in i]\n",
    "        external_basis=[i for i in Basis_Indices if 'I' not in i]\n",
    "        print(external_basis)\n",
    "    # This is 1 indices per pair energy!        \n",
    "        set_i_indices=[]\n",
    "    # This is 1 indices per pair energy!            \n",
    "        set_j_indices=[]\n",
    "    # This is a set of 4 indices per pair energy!    \n",
    "        set_k_indices=[]\n",
    "    # This is a set of 4 indices per pair energy!    \n",
    "        set_l_indices=[]\n",
    "        for idx,i in enumerate(stacked_pairs.index.tolist()):\n",
    "            set_i_indices.append(internal_basis.index(i.split('_')[0]))\n",
    "            set_j_indices.append(internal_basis.index(i.split('_')[1]))\n",
    "            set_k_indices.append([external_basis.index(k.split('_')[0]) for k in pd.DataFrame(self.train_4[:,idx,:]).describe().loc['top'].tolist()])\n",
    "            set_l_indices.append([external_basis.index(k.split('_')[1]) for k in pd.DataFrame(self.train_4[:,idx,:]).describe().loc['top'].tolist()])\n",
    "            \n",
    "        return set_i_indices,set_j_indices,set_k_indices,set_l_indices,self.train_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ijkl_idx=gen_big_4().gen_ijkl()\n",
    "set_i_indices=ijkl_idx[0]\n",
    "set_j_indices=ijkl_idx[1]\n",
    "set_k_indices=ijkl_idx[2]\n",
    "set_l_indices=ijkl_idx[3]\n",
    "set_indices=ijkl_idx[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "occcc=len(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=0])\n",
    "virttt=len(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create slices for AA->AA indices\n",
    "# This will help zero out infinities\n",
    "internal_A=[idx for idx,i in enumerate(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=0].index) if 'A' in i]\n",
    "external_A=[idx for idx,i in enumerate(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=2].index) if 'A' in i]\n",
    "\n",
    "inner_slice=slice(min(internal_A),max(internal_A)+1)\n",
    "outer_slice=slice(min(external_A),max(external_A)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class gen_two_ints(object):\n",
    "# Some of the D_{ij}^{ab}=f_{ii}+f_{jj}-f_{aa}-f_{bb}=e_{ii}+e_{jj}-e_{aa}-e_{bb} elements \n",
    "# will be 0 since ij and ab overlap for CASPT2\n",
    "# ij \\in {I,A}\n",
    "# ab \\in {A,V}\n",
    "# So ignore the warnings since they'll only be 0 when ijab \\in {A} only\n",
    "    import warnings\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    def get_MO(self, string):\n",
    "        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],self.slice_dict[string[2]], self.slice_dict[string[3]]]\n",
    "\n",
    "    def get_F(self, string):\n",
    "        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]] \n",
    "    \n",
    "    def compute_pairmatrix(self,selft2start,selfdoublecheck):\n",
    "        test = 2*selft2start*selfdoublecheck\n",
    "        test -= np.swapaxes(selft2start,2,3)*selft2start\n",
    "        c=np.sum(test,axis=(2,3))\n",
    "        return c    \n",
    "    \n",
    "    def build_tau(self,t2,t1):\n",
    "        ttau = t2.copy()\n",
    "        tmp = np.einsum('ia,jb->ijab', t1, t1,optimize=True)\n",
    "        ttau += tmp\n",
    "        return ttau    \n",
    "    \n",
    "#     def __init__(self,k):\n",
    "    def gen_feat(self,k):\n",
    "# Set variables\n",
    "# nocc:=Occupied orbitals\n",
    "# nvirt:=virtual orbitals\n",
    "# nfzc:=frozen orbitals\n",
    "# nmo:=number of orbitals\n",
    "        nocc=occcc\n",
    "        nvirt=virttt\n",
    "        self.nfzc=len(froz)\n",
    "        self.nocc=nocc\n",
    "        self.nvirt=nvirt\n",
    "        self.nmo=len(Basis_Indices)\n",
    "        nmo=nocc+nvirt\n",
    "# nmo=nocc+nvirt\n",
    "# Set slices\n",
    "# In CASPT2 occupied run I-A and virtual run A-S\n",
    "# Unlike MP2 there will be overlap between internal and external indices\n",
    "        self.slice_o = slice(0,nocc)\n",
    "        self.slice_v = slice(len(Basis_Indices)-virttt,len(Basis_Indices))\n",
    "        self.slice_a = slice(0,nmo)    \n",
    "\n",
    "# Dictionary with the slices        \n",
    "\n",
    "        self.slice_dict = {\n",
    "            'o': self.slice_o,\n",
    "            'v': self.slice_v,\n",
    "            'a': self.slice_a\n",
    "        }\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        featurelist=list()    \n",
    "# Virtual\n",
    "        self.empty=np.zeros((nvirt,))\n",
    "# Occupied    \n",
    "        self.occupado=np.zeros((nocc,))\n",
    "# MO integrals    \n",
    "        self.MO=gen_MO(k)\n",
    "# MO Fock matrix    \n",
    "        self.F=gen_F[k].to_numpy()\n",
    "# Zero out t1 matrix, dim(occ,virt)    \n",
    "        self.t1=np.zeros((nocc,nvirt))\n",
    "# MO Fock matrix internal\n",
    "        Focc = self.F[self.slice_o]\n",
    "# MO Fock matrix external    \n",
    "        Fvir = self.F[self.slice_v]  \n",
    "        self.orbocc=Focc\n",
    "        self.orbvirt=Fvir\n",
    "\n",
    "        self.Dia = Focc.reshape(-1, 1) - Fvir\n",
    "        self.Dijab = Focc.reshape(-1, 1, 1, 1) + Focc.reshape(-1, 1, 1) - Fvir.reshape(-1, 1) - Fvir \n",
    "\n",
    "        \n",
    "# Clean up AA block to get rid of infinities, we do not need this anyway              \n",
    "# t2=<ij||ab>/(e_i+e_j-e_a-e_b)\n",
    "# But this is <ij|ab>... idk...\n",
    "        self.t2start=self.MO[self.slice_o, self.slice_o, self.slice_v,self.slice_v] / self.Dijab\n",
    "# Zero out AA->AA\n",
    "        self.t2start[inner_slice,inner_slice,outer_slice,outer_slice]=0\n",
    "\n",
    "# Related to the correlation energy\n",
    "# np.einsum('ijab->',triplecheck)=MP2 correlation energy in jacob's code\n",
    "#dim(triplecheck)=(occ,occ,virt,virt)\n",
    "        self.triplecheck=2*self.t2start*self.get_MO('oovv')\n",
    "        self.triplecheck -=  np.swapaxes(self.get_MO('oovv'),2,3)*self.t2start \n",
    "# Zero out AA->AA\n",
    "        self.triplecheck[inner_slice,inner_slice,outer_slice,outer_slice]=0\n",
    "\n",
    "        \n",
    "        \n",
    "# Integral\n",
    "# doublecheck =<ij|ab>\n",
    "#dim(doublecheck)=(occ,occ,virt,virt)\n",
    "        self.doublecheck = self.MO[self.slice_o, self.slice_o, self.slice_v, self.slice_v]   \n",
    "# Zero out AA->AA\n",
    "        self.doublecheck[inner_slice,inner_slice,outer_slice,outer_slice]=0\n",
    "\n",
    "\n",
    "    \n",
    "# Not related to the correlation energy?\n",
    "# dim(pairenergy)=(occ,occ,virt,virt)\n",
    "# dim(compute_pairmatrix(t2start,doublecheck))=(occ,occ)->(occ,occ,virt,virt)\n",
    "        self.pairenergy=(np.zeros(self.doublecheck.shape)+self.compute_pairmatrix(self.t2start,self.doublecheck)[:,:,np.newaxis,np.newaxis])\n",
    "# Zero out AA->AA\n",
    "        self.pairenergy[inner_slice,inner_slice,outer_slice,outer_slice]=0\n",
    "\n",
    "\n",
    "# Related to the correlation energy\n",
    "#dim(pairs)=(virt,virt)\n",
    "# np.einsum('ab->',pairs)=np.einsum('ijab->',triplecheck)=MP2 correlation energy in jacob's code\n",
    "        tmp_tau = self.build_tau(self.t2start,self.t1)\n",
    "        self.pairs=2*tmp_tau*self.get_MO('oovv')\n",
    "        self.pairs-= np.swapaxes(self.get_MO('oovv'),2,3)*tmp_tau\n",
    "        self.pairs = np.sum(self.pairs,axis=(2,3))\n",
    "# Zero out AA->AA\n",
    "        self.pairs[inner_slice,outer_slice]=0        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        test=np.zeros(self.t2start.shape)\n",
    "        self.diag=test\n",
    "        for i in range (0,self.nocc):\n",
    "            for j in range (0,self.nocc):\n",
    "                np.fill_diagonal(self.diag[i,j,:,:],1)\n",
    "\n",
    "# Dim(temp)=(occ,virt)\n",
    "# Basically dim(<ii|jj>)->dim(<i|j>)\n",
    "        temp=np.zeros((self.nocc,self.nvirt))\n",
    "        for i in range (0,self.nocc):\n",
    "            for j in range (0,self.nvirt):\n",
    "                temp[i,j]=self.doublecheck[i,i,j,j]\n",
    "# Dim(test1)=(occ,occ,virt,virt)                \n",
    "        test1=np.zeros((self.t2start.shape))\n",
    "\n",
    "# dim(temp)=(occ,virt) -> dim(temp[:,np.newaxis,:,np.newaxis])=(occ,1,virt,1)\n",
    "# np.newaxis makes this a dummy index, : will be unique\n",
    "# i.e. (occ,copy,virt,copy)\n",
    "# (occ,occ,virt,virt) + (occ,1,virt,1)\n",
    "# <ii||aa>    \n",
    "        self.screen1=test1+temp[:,np.newaxis,:,np.newaxis]\n",
    "# Zero out AA->AA\n",
    "        self.screen1[inner_slice,inner_slice,outer_slice,outer_slice]=0            \n",
    "\n",
    "# dim(temp)=(occ,virt) -> dim(temp[np.newaxis,:,np.newaxis,:])=(1,occ,1,virt)\n",
    "# (occ,occ,virt,virt) + (1,occ,1,virt)\n",
    "# np.newaxis makes this a dummy index, : will be unique\n",
    "# i.e. (copy,occ,copy,virt)\n",
    "# <jj||bb>    \n",
    "        self.screen2=test1+temp[np.newaxis,:,np.newaxis,:]\n",
    "# Zero out AA->AA\n",
    "        self.screen2[inner_slice,inner_slice,outer_slice,outer_slice]=0                \n",
    "# screen1[i,j,k,l]==screen2[j,i,l,k].T\n",
    "\n",
    "# nfzc=# frozen core\n",
    "        val=self.nmo-self.nfzc\n",
    "# Dim(temp)=(nmo,nmo)\n",
    "# Basically dim(<ii|jj>)->dim(<i|j>)    \n",
    "        temp=np.zeros((val,val))        \n",
    "        for i in range (0,val):\n",
    "            for j in range (0,val):\n",
    "                temp[i,j]=self.MO[i,i,j,j]\n",
    "# Get virtual indices: <aa|bb> basically\n",
    "# <aa||bb>\n",
    "# (occ,occ,virt,virt) + (virt,virt)\n",
    "# (occ,occ,virt,virt) + (1,1,virt,virt)                \n",
    "        temp =temp[self.slice_v,self.slice_v]\n",
    "        self.screenvirt=test1+temp[np.newaxis,np.newaxis,:,:]\n",
    "# Zero out AA->AA\n",
    "        self.screenvirt[inner_slice,inner_slice,outer_slice,outer_slice]=0\n",
    "        # b=(i,j,a,b)=(13, 13, 5, 5)\n",
    "        b=self.triplecheck\n",
    "# Zero out AA->AA\n",
    "        diag_indx=[]\n",
    "        off_diag_indx=[]     \n",
    "        featurelist=[]\n",
    "        featurelist.clear()\n",
    "        feature=[]\n",
    "        feature.clear()    \n",
    "        index=['pair_energy','coulomb','screen1_1','screen1_2','screen1_3','screen1_4','screen2_1','screen2_2','screen2_3','screen2_4','eijab_1','eijab_2','eijab_3','eijab_4','screenvirt_1','screenvirt_2','screenvirt_3','screenvirt_4']        \n",
    "        for idx,i in enumerate([j for j,v in set_indices]):\n",
    "# εij{MP2}              \n",
    "            new=np.sum(b[set_i_indices[idx],set_j_indices[idx]])#0\n",
    "# <ii||jj>    \n",
    "            new=np.hstack((new,self.MO[set_i_indices[idx],set_i_indices[idx],set_j_indices[idx],set_j_indices[idx]]))\n",
    "# <ii||aa>    \n",
    "            new=np.hstack((new,np.array([self.screen1[set_i_indices[idx],set_j_indices[idx],k,l] for k,l in zip(set_k_indices[idx],set_l_indices[idx])]).flatten()))\n",
    "# <jj||bb>    \n",
    "            new=np.hstack((new,np.array([self.screen2[set_i_indices[idx],set_j_indices[idx],k,l] for k,l in zip(set_k_indices[idx],set_l_indices[idx])]).flatten()))\n",
    "# e_{ij}^{ab} MP2\n",
    "            new=np.hstack((new,np.array([b[set_i_indices[idx],set_j_indices[idx],k,l] for k,l in zip(set_k_indices[idx],set_l_indices[idx])]).flatten()))\n",
    "# # <aa||bb>    \n",
    "            new=np.hstack((new,np.array([self.screenvirt[set_i_indices[idx],set_j_indices[idx],k,l] for k,l in zip(set_k_indices[idx],set_l_indices[idx])]).flatten()))\n",
    "            featurelist.append((i,new))\n",
    "        return pd.DataFrame(dict(featurelist),index=index).T\n",
    "#         return pd.concat([pd.DataFrame(self.a,index=diag_indx),pd.DataFrame(self.g,index=off_diag_indx)]).loc[full_set]\n",
    "\n",
    "# gen_feat\n",
    "#     self.dict=dict([(k,gen_feat(k))for k in paths])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elements(x):\n",
    "    '''\n",
    "    Takes an integer, x, and returns the number of off-diagonal elements of an upper triangular matrix\n",
    "    f(x)=(x*(x-1))/2\n",
    "    '''\n",
    "    return (x*(x-1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_indices[0][0],set_indices[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_1_feats(k):\n",
    "    # t0=time()\n",
    "    # For an e_pq, there should be 10 F, 10 occs, and then 10 SCF F and 10 SCF occs\n",
    "    Fp=[]\n",
    "    Fq=[]\n",
    "\n",
    "    occp=[]\n",
    "    occq=[]\n",
    "\n",
    "    SCFFp=[]\n",
    "    SCFFq=[]\n",
    "\n",
    "\n",
    "    SCFOCCp=[]\n",
    "    SCFOCCq=[]\n",
    "\n",
    "    hpp=[]\n",
    "    hqq=[]\n",
    "    hrr=[]\n",
    "    hss=[]\n",
    "\n",
    "    rs_df=[]\n",
    "    h=int1[k]\n",
    "    for idx,i in enumerate(set_indices):\n",
    "\n",
    "        p,q=i[0].split('_')\n",
    "        # print(p,q)\n",
    "        Fp.append(gen_F.loc[p,k])\n",
    "        Fq.append(gen_F.loc[q,k])\n",
    "        occp.append(gen_occ.loc[p,k])\n",
    "        occq.append(gen_occ.loc[q,k])\n",
    "\n",
    "        SCFFp.append(gen_F_SCF.loc[p,k])\n",
    "        SCFFq.append(gen_F_SCF.loc[q,k])\n",
    "        SCFOCCp.append(gen_occ_SCF.loc[p,k])\n",
    "        SCFOCCq.append(gen_occ_SCF.loc[q,k])\n",
    "        hpp.append(h.loc[p,p])\n",
    "        hqq.append(h.loc[p,p])\n",
    "\n",
    "\n",
    "\n",
    "        Fr=[]\n",
    "        Fs=[]\n",
    "        occr=[]\n",
    "        occs=[]\n",
    "        SCFFr=[]\n",
    "        SCFFs=[]\n",
    "        SCFOCCr=[]\n",
    "        SCFOCCs=[]\n",
    "        for idxx,j in enumerate(i[1]):\n",
    "            r,s=j.split('_')\n",
    "\n",
    "            Fr.append((f'Fr{idxx+1}',gen_F.loc[r,k]))\n",
    "            Fs.append((f'Fs{idxx+1}',gen_F.loc[s,k]))\n",
    "\n",
    "            occr.append((f'occr{idxx+1}',gen_occ.loc[r,k]))\n",
    "            occs.append((f'occs{idxx+1}',gen_occ.loc[s,k]))\n",
    "\n",
    "            SCFFr.append((f'SCFFr{idxx+1}',gen_F_SCF.loc[r,k]))\n",
    "            SCFFs.append((f'SCFFs{idxx+1}',gen_F_SCF.loc[s,k]))\n",
    "\n",
    "\n",
    "            SCFOCCr.append((f'SCFOCCr{idxx+1}',gen_occ_SCF.loc[r,k]))\n",
    "            SCFOCCs.append((f'SCFOCCs{idxx+1}',gen_occ_SCF.loc[s,k]))\n",
    "\n",
    "            hrr.append((f'hrr{idxx+1}',h.loc[r,r]))\n",
    "            hss.append((f'hss{idxx+1}',h.loc[s,s]))\n",
    "\n",
    "\n",
    "        rs_df.append(pd.DataFrame.from_dict({**dict(Fr),**dict(Fs),**dict(occr),**dict(occs),**dict(SCFFr),**dict(SCFFs),**dict(SCFOCCr),**dict(SCFOCCs),**dict(hrr),**dict(hss)},orient='index',columns=[i[0]]))\n",
    "    rs=pd.concat(rs_df,axis=1).T\n",
    "    dummy_df=pd.DataFrame({'hpp':hpp,'hqq':hqq,'Fp':Fp,'Fq':Fq,'occp':occp,'occq':occq,'SCFFp':SCFFp,'SCFFq':SCFFq,'SCFOCCp':SCFOCCp,'SCFOCCq':SCFOCCq},index=pair_labels)\n",
    "    # print(f'{k} {time()-t0}')\n",
    "    return pd.concat([rs,dummy_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_two_el():\n",
    "    return dict([(k,gen_two_ints().gen_feat(k))for k in paths])\n",
    "\n",
    "\n",
    "def gen_one_diag():\n",
    "    return dict([(k,gen_1_feats(k)) for k in paths])\n",
    "\n",
    "\n",
    "def gen_bin():\n",
    "    # FSO=From same orbital\n",
    "    FSO=[]\n",
    "    # Indexing\n",
    "    featind=[]\n",
    "    # Keys=paths in string format\n",
    "    keys=[]\n",
    "    for i in paths:\n",
    "        k=str(i)\n",
    "        keys.append(k)\n",
    "        for ind,g in enumerate(full_set):\n",
    "# Epq Ers\n",
    "# # e_q+e_s-e_p-e_r\n",
    "# TIUV\n",
    "#'A'+g[0]+'_I'+g[1]+''+g[2]+''+g[3]\n",
    "# Eti Euv (E01 E23)\n",
    "# e_i+e_v-e_u-e_t\n",
    "# e[0] + e[3] - e[1] - e[2]\n",
    "            featind.append(g)\n",
    "            idx=g.split('_')\n",
    "            q=idx[0]\n",
    "            s=idx[1]\n",
    "# Since I!=A just append 0 since they'll never both come from the same orbital                \n",
    "            if q==s:\n",
    "                FSO.append(1)\n",
    "            else:\n",
    "                FSO.append(0)\n",
    "    return dict([(z,pd.DataFrame({'From_Same_Orbital':np.array(FSO).reshape(len(paths),-1)[idx]},index=np.array(featind).reshape(len(paths),-1)[idx])) for idx,z in enumerate(keys)])               \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Big_Data_GS():\n",
    "    t0=time()\n",
    "    with open('O3/fixed_feats.pickle', 'wb') as handle:\n",
    "        pickle.dump(pd.concat([pd.concat({k: v for k,v in gen_bin().items()},axis=0),\n",
    "                               pd.concat({k: v for k,v in gen_two_el().items()},axis=0),\n",
    "                               pd.concat({k: v for k,v in gen_one_diag().items()},axis=0)],axis=1), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('O3/fixed_targets.pickle', 'wb') as handle:\n",
    "        pickle.dump(stacked_pairs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(time()-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_Data_GS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(f'fixed_feats.pickle'),\n",
    "# pd.read_pickle(f'typH_targets.pickle').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([pd.concat({k: v for k,v in gen_bin().items()},axis=0),\n",
    "                               pd.concat({k: v for k,v in gen_two_el().items()},axis=0),\n",
    "                               pd.concat({k: v for k,v in gen_one_diag().items()},axis=0)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere(np.isnan(df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isna().values==True).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
