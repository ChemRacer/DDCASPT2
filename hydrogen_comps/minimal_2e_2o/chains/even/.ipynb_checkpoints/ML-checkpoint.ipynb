{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07f4ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data generation\n",
    "import sys\n",
    "# !{sys.executable} -m pip install matplotlib --upgrade\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#random\n",
    "from time import perf_counter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30fd72cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "with open('test_ind.pickle', 'rb') as handle:\n",
    "    test_ind = pickle.load(handle)\n",
    "\n",
    "with open('train_ind.pickle', 'rb') as handle:\n",
    "    train_ind = pickle.load(handle)\n",
    "    \n",
    "print(len(train_ind),len(test_ind))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da9c080a-2174-42f9-8841-1b21362d1e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_name=['From_Same_Orbital', 'pair_energy', 'coulomb', 'screen1_1', 'screen1_2',\n",
    "       'screen1_3', 'screen1_4', 'screen2_1', 'screen2_2', 'screen2_3',\n",
    "       'screen2_4', 'eijab_1', 'eijab_2', 'eijab_3', 'eijab_4', 'screenvirt_1',\n",
    "       'screenvirt_2', 'screenvirt_3', 'screenvirt_4', 'Fr1', 'Fr2', 'Fr3',\n",
    "       'Fr4', 'Fs1', 'Fs2', 'Fs3', 'Fs4', 'occr1', 'occr2', 'occr3', 'occr4',\n",
    "       'occs1', 'occs2', 'occs3', 'occs4', 'SCFFr1', 'SCFFr2', 'SCFFr3',\n",
    "       'SCFFr4', 'SCFFs1', 'SCFFs2', 'SCFFs3', 'SCFFs4', 'SCFOCCr1',\n",
    "       'SCFOCCr2', 'SCFOCCr3', 'SCFOCCr4', 'SCFOCCs1', 'SCFOCCs2', 'SCFOCCs3',\n",
    "       'SCFOCCs4', 'hrr1', 'hrr2', 'hrr3', 'hrr4', 'hss1', 'hss2', 'hss3',\n",
    "       'hss4', 'hpp', 'hqq', 'Fp', 'Fq', 'occp', 'occq', 'SCFFp', 'SCFFq',\n",
    "       'SCFOCCp', 'SCFOCCq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69415391",
   "metadata": {},
   "outputs": [],
   "source": [
    "['screen1_1', 'screen1_2', 'screen1_3', 'screen1_4', 'screen2_1','screen2_2', 'screen2_3', 'screen2_4', 'eijab_1', 'eijab_2','eijab_3', 'eijab_4', 'screenvirt_1', 'screenvirt_3','screenvirt_4', 'Fr1', 'Fr2', 'Fr3', 'Fr4', 'Fs2', 'Fs3', 'Fs4','occs1', 'occs3', 'SCFFr1', 'SCFFr2', 'SCFFr3', 'SCFFr4', 'SCFFs1','SCFFs2', 'SCFFs3', 'SCFFs4', 'hrr1', 'hrr2', 'hrr3', 'hrr4','hss1', 'hss2', 'hss3', 'hpp', 'Fp', 'Fq', 'occp', 'occq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdc66dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=[]\n",
    "train_y = []\n",
    "\n",
    "test_X=[]\n",
    "test_y = []\n",
    "# for nam in sorted(glob('*/fixed_feats.pickle'),key=lambda x: int(x.split('_')[0].strip('H')))[2:]:\n",
    "for nam in glob('*/fixed_feats.pickle'):\n",
    "    trydf=pd.read_pickle(nam).astype(float)[['SCFFp', 'SCFFq', 'SCFFr1', 'SCFFr2', 'SCFFr3', 'SCFFr4', 'SCFFs1', 'SCFFs2', 'SCFFs3', 'SCFFs4', 'SCFOCCp', 'SCFOCCq', 'SCFOCCr1', 'SCFOCCr2', 'SCFOCCr3', 'SCFOCCr4', 'SCFOCCs1', 'SCFOCCs2', 'SCFOCCs3', 'SCFOCCs4']]\n",
    "    #[['screen1_1', 'screen1_2', 'screen1_3', 'screen1_4', 'screen2_1','screen2_2', 'screen2_3', 'screen2_4', 'eijab_1', 'eijab_2','eijab_3', 'eijab_4', 'screenvirt_1', 'screenvirt_3','screenvirt_4', 'Fr1', 'Fr2', 'Fr3', 'Fr4', 'Fs2', 'Fs3', 'Fs4','occs1', 'occs3', 'SCFFr1', 'SCFFr2', 'SCFFr3', 'SCFFr4', 'SCFFs1','SCFFs2', 'SCFFs3', 'SCFFs4', 'hrr1', 'hrr2', 'hrr3', 'hrr4','hss1', 'hss2', 'hss3', 'hpp', 'Fp', 'Fq', 'occp', 'occq']]\n",
    "    \n",
    "    Hnam=nam.split('/')[0].split('_')[0]\n",
    "    for i in train_ind:\n",
    "        train_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{i:.2f}'].values)\n",
    "    for j in test_ind: \n",
    "        test_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{j:.2f}'].values)\n",
    "    \n",
    "    \n",
    "# This recover is wrong... did not account for the # of pair-energies     \n",
    "recover_train=[]    \n",
    "recover_test=[]    \n",
    "tst_idx=0\n",
    "tr_idx=0\n",
    "for nidx,nam in enumerate(glob('*/fixed_targets.pickle')):\n",
    "    trydf=pd.read_pickle(nam).astype(float)\n",
    "    Hnam=nam.split('/')[0].split('_')[0]\n",
    "    for tridx,i in enumerate(train_ind):\n",
    "        pairdf=trydf[f'{i:.2f}'].values\n",
    "        train_y.append(pairdf)\n",
    "        for k in range(len(pairdf)):\n",
    "            recover_train.append((nam.split('_')[0],tridx,tr_idx))\n",
    "            tr_idx+=1\n",
    "        \n",
    "    for teidx,j in enumerate(test_ind): \n",
    "        pairdf=trydf[f'{j:.2f}'].values\n",
    "        test_y.append(pairdf)        \n",
    "        \n",
    "        for k in range(len(pairdf)):\n",
    "            recover_test.append((nam.split('_')[0],teidx,tst_idx))\n",
    "            tst_idx+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f5dc3b-568d-4790-becf-af15cfa57e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test=np.vstack(train_X).astype(float),np.vstack(test_X).astype(float)\n",
    "for u,v in np.argwhere(np.isnan(X_train)):\n",
    "    X_train[u,v]=0\n",
    "    \n",
    "for u,v in np.argwhere(np.isnan(X_test)):\n",
    "    X_test[u,v]=0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbbf74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train,y_test=np.hstack(train_y).astype(float),np.hstack(test_y).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e64801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acff856",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dfb823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b6610-2a11-4ac4-9c8d-4c7df2e7510c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# model=XGBRegressor(reg_lambda=0.3,max_depth=100,min_child_weight=5)\n",
    "model=XGBRegressor(max_depth=100,min_child_weight=1,n_estimators=100, reg_alpha=0.001, reg_lambda=0.001)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_train=model.predict(X_train)\n",
    "y_pred_test=model.predict(X_test)\n",
    "print(f\"R2: {r2_score(y_train,y_pred_train):.4f},{r2_score(y_test,y_pred_test):.4f}\")\n",
    "print(f\"RMSE (mEh): {mean_squared_error(y_train,y_pred_train,squared=False)*1e3:.4f},{mean_squared_error(y_test,y_pred_test,squared=False)*1e3:.4f}\")\n",
    "\n",
    "# params = {'max_depth': [1, 10, 100],\n",
    "# #           'n_estimators': [100, 500, 1000],\n",
    "#           'reg_lambda': [1e-6, 1e-3,1e-1],\n",
    "#           'reg_alpha': [1e-6, 1e-3,1e-1]}\n",
    "\n",
    "# model = XGBRegressor()\n",
    "# grid = GridSearchCV(estimator=model, \n",
    "#                    param_grid=params,\n",
    "#                    scoring='r2', \n",
    "#                    verbose=1000,n_jobs=12).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# gmodel=grid.best_estimator_\n",
    "# y_pred_train=gmodel.predict(X_train)\n",
    "# y_pred_test=gmodel.predict(X_test)\n",
    "# print(f\"R2: {r2_score(y_train,y_pred_train):.4f},{r2_score(y_test,y_pred_test):.4f}\")\n",
    "# print(f\"RMSE (mEh): {mean_squared_error(y_train,y_pred_train,squared=False)*1e3:.4f},{mean_squared_error(y_test,y_pred_test,squared=False)*1e3:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fb4f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bfbe7-26b3-4e59-9967-492a9267e947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "font=12\n",
    "plt.rc('font', size=font)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=font)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=font)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=font)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=font)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=font)    # legend fontsize\n",
    "plt.rc('figure', titlesize=font)  # fontsize of the figure title\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(13,6))\n",
    "scale=1e-1\n",
    "ax1.set_title('Train')\n",
    "ax1.scatter(1e3*y_train,1e3*y_pred_train,label=\"R$^{2}$=\"+f'{r2_score(y_train,y_pred_train):.2f}\\nMAE={1e3*mean_absolute_error(y_train,y_pred_train):.4f}'+\" mE$_{h}$\")\n",
    "ax1.plot(1e3*y_train,1e3*y_train,'k-')\n",
    "ax1.set_xlim(1e3*min(y_train)-scale,1e3*max(y_train)+scale)\n",
    "ax1.set_ylim(1e3*min(y_train)-scale,1e3*max(y_train)+scale)\n",
    "ax1.set_xlabel('Calculated Pair-Energies (mE$_{h}$)')\n",
    "ax1.set_ylabel('Predicted Pair-Energies (mE$_{h}$)')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.set_title('Test')\n",
    "ax2.scatter(1e3*y_test,1e3*y_pred_test,label=\"R$^{2}$=\"+f'{r2_score(y_test,y_pred_test):.2f}\\nMAE={1e3*mean_absolute_error(y_test,y_pred_test):.4f}'+\" mE$_{h}$\",color='orange')\n",
    "ax2.plot(1e3*y_test,1e3*y_test,'k-')\n",
    "ax2.set_xlim(1e3*min(y_test)-scale,1e3*max(y_test)+scale)\n",
    "ax2.set_ylim(1e3*min(y_test)-scale,1e3*max(y_test)+scale)\n",
    "ax2.set_xlabel('Calculated Pair-Energies (mE$_{h}$)')\n",
    "ax2.set_ylabel('Predicted Pair-Energies (mE$_{h}$)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/H2n_parity.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507573f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdct={}\n",
    "for n in np.arange(2,14,2):\n",
    "    index=np.array(recover_test)[np.array(recover_test)[:,0]==f'H{n}'][:,2].astype(int)\n",
    "    testdct[f'H{n}']=np.vstack([y_test[index],y_pred_test[index]])\n",
    "    \n",
    "test_errors={}    \n",
    "for k,v in sorted(testdct.items(),key=lambda x: int(x[0].strip('H'))):\n",
    "    test_errors[k]=1e3*mean_absolute_error(v[0],v[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad4b4c-12eb-44b5-98c1-65552232e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindct={}\n",
    "for n in np.arange(2,14,2):\n",
    "    index=np.array(recover_train)[np.array(recover_train)[:,0]==f'H{n}'][:,2].astype(int)\n",
    "    traindct[f'H{n}']=np.vstack([y_train[index],y_pred_train[index]])\n",
    "    \n",
    "train_errors={}    \n",
    "for k,v in sorted(traindct.items(),key=lambda x: int(x[0].strip('H'))):\n",
    "    train_errors[k]=1e3*mean_absolute_error(v[0],v[1])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=pd.DataFrame.from_dict(test_errors,orient='index').rename(columns={0:'test'})\n",
    "traindf=pd.DataFrame.from_dict(train_errors,orient='index').rename(columns={0:'train'})\n",
    "errormelt=pd.concat([traindf,testdf],axis=1).reset_index().melt(id_vars='index')\n",
    "errormelt['index']=[i.split('_')[0] for i in errormelt['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASSCF=pd.concat([pd.read_csv(i,index_col=1).drop(columns=['Unnamed: 0']).rename(columns={'energy':i.split('_')[0]}) for i in glob('*/CASSCF.csv')],axis=1)\n",
    "CASPT2=pd.concat([pd.read_csv(i,index_col=1).drop(columns=['Unnamed: 0']).rename(columns={'energy':i.split('_')[0]}) for i in glob('*/CASPT2.csv')],axis=1)\n",
    "E2=pd.concat([pd.read_csv(i,index_col=1).drop(columns=['Unnamed: 0']).rename(columns={'energy':i.split('_')[0]}) for i in glob('*/E2.csv')],axis=1)    \n",
    "\n",
    "CASSCF.index=[f'{i:.2f}' for i in CASSCF.index]\n",
    "CASPT2.index=[f'{i:.2f}' for i in CASPT2.index]\n",
    "E2.index=[f'{i:.2f}' for i in E2.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83a3e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairedcp=sns.color_palette('Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e99e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,5),sharey=False)\n",
    "for idx,(k,v) in enumerate(testdct.items()):\n",
    "    sns.histplot(np.hstack([v[0],traindct[k][0]]),label=k,color=pairedcp[idx],kde=True,stat='probability',ax=ax1)\n",
    "\n",
    "sns.histplot(np.hstack([np.hstack([v[0],traindct[k][0]]) for idx,(k,v) in enumerate(testdct.items())]),label='all',color=pairedcp[idx+1],kde=True,stat='probability',ax=ax1)\n",
    "ax1.set_xlim(-1.2e-2,3e-3)\n",
    "ax1.set_xticks(np.linspace(-1.2e-2,3e-3,5))\n",
    "ax1.set_xticklabels([f'{i:.2e}' for i in np.linspace(-1.2e-2,3e-3,5)])\n",
    "ax1.legend(loc=2)\n",
    "ax1.set_xlabel('Pair-Energies')\n",
    "\n",
    "sns.histplot(data=E2[sorted(E2.columns,key=lambda x: int(x.strip('H')))].melt(),x='value',hue='variable',kde=True,stat='probability',palette=sns.color_palette('Paired'), multiple=\"stack\",ax=ax2)\n",
    "\n",
    "ax2.set_xlabel('Correlation Energies')\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/dist.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09541b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincorrdict={}\n",
    "for n in np.arange(2,14,2):\n",
    "    dat=np.array(recover_train)[np.array(recover_train)[:,0]==f'H{n}']\n",
    "    corrdf=[]\n",
    "    for idr,r in enumerate(train_ind):\n",
    "        chunked=dat[dat[:,1].astype(int)==idr]\n",
    "        index=chunked[:,2].astype(int)\n",
    "        dfcorr=pd.DataFrame([y_train[index].sum(),y_pred_train[index].sum()],index=['train','pred'])\n",
    "        corrdf.append(dfcorr)\n",
    "    \n",
    "    df=pd.concat(corrdf,axis=1).T\n",
    "    df.index=[f'{i:.2f}' for i in train_ind]\n",
    "    traincorrdict[f'H{n}']=df\n",
    "    \n",
    "traincorr_err={}\n",
    "for k,v in traincorrdict.items():\n",
    "    traincorr_err[k]=1e3*mean_absolute_error(v['train'],v['pred'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51455dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcorrdict={}\n",
    "for n in np.arange(2,14,2):\n",
    "    dat=np.array(recover_test)[np.array(recover_test)[:,0]==f'H{n}']\n",
    "    corrdf=[]\n",
    "    for idr,r in enumerate(test_ind):\n",
    "        chunked=dat[dat[:,1].astype(int)==idr]\n",
    "        index=chunked[:,2].astype(int)\n",
    "        dfcorr=pd.DataFrame([y_test[index].sum(),y_pred_test[index].sum()],index=['test','pred'])\n",
    "        corrdf.append(dfcorr)\n",
    "    \n",
    "    df=pd.concat(corrdf,axis=1).T\n",
    "    df.index=[f'{i:.2f}' for i in test_ind]\n",
    "    testcorrdict[f'H{n}']=df\n",
    "    \n",
    "testcorr_err={}\n",
    "for k,v in testcorrdict.items():\n",
    "    testcorr_err[k]=1e3*mean_absolute_error(v['test'],v['pred'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_CASPT2=pd.DataFrame.from_dict({k:CASSCF[k].loc[v['pred'].index]+v['pred'] for k,v in testcorrdict.items()},orient='index').T\n",
    "train_CASPT2=pd.DataFrame.from_dict({k:CASSCF[k].loc[v['pred'].index]+v['pred'] for k,v in traincorrdict.items()},orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b0ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairedcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in test_CASPT2.columns:\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "    train,test=traincorrdict[n],testcorrdict[n]\n",
    "    true_train,pred_train=train['train'],train['pred']\n",
    "    true_test,pred_test=test['test'],test['pred']\n",
    "    \n",
    "    ax1.scatter(train.index.astype(float),pred_train*1e3,label='R$^{2}$='+f'{r2_score(true_train,pred_train):.4f}\\nMAE={1e3*mean_absolute_error(true_train,pred_train):.2e}'+\" mE$_{h}$\",color=pairedcp[4])\n",
    "    ax1.plot(E2[n].index.astype(float),E2[n]*1e3,'k')\n",
    "    ax1.set_xlabel('Radius (Å)')\n",
    "    ax1.set_ylabel('Correlation Energy (mE$_{h}$)')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.scatter(test.index.astype(float),pred_test*1e3,label='R$^{2}$='+f'{r2_score(true_test,pred_test):.4f}\\nMAE={1e3*mean_absolute_error(true_test,pred_test):.2e}'+\" mE$_{h}$\",color=pairedcp[5])\n",
    "    ax2.plot(E2[n].index.astype(float),E2[n]*1e3,'k')\n",
    "    ax2.set_xlabel('Radius (Å)')\n",
    "    ax2.legend()\n",
    "    \n",
    "    fig.suptitle(n)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0,wspace=0)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'images/{n}_E2.png',dpi=300,bbox_inches='tight')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3ff99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in test_CASPT2.columns:\n",
    "    fig,((ax1,ax2),(ax3,ax4))=plt.subplots(2,2,figsize=(10,10),sharey=True)\n",
    "    pt2=CASPT2[n]\n",
    "    true_train,pred_train=pt2.loc[train_CASPT2.index],train_CASPT2[n]\n",
    "    true_test,pred_test=pt2.loc[test_CASPT2.index],test_CASPT2[n]\n",
    "    ax1.scatter(true_train,pred_train,label='R$^{2}$='+f'{r2_score(true_train,pred_train):.4f}\\nMAE={1e3*mean_absolute_error(true_train,pred_train):.2e}'+\" mE$_{h}$\",color=pairedcp[4])\n",
    "    ax1.plot(true_train,true_train,'k')\n",
    "    ax1.set_xlabel('Calculated CASPT2 Energy (E$_{h}$)')\n",
    "    ax1.set_ylabel('Predicted CASPT2 Energy (E$_{h}$)')\n",
    "    ax1.set_title('Train')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.scatter(true_test,pred_test,label='R$^{2}$='+f'{r2_score(true_test,pred_test):.4f}\\nMAE={1e3*mean_absolute_error(true_test,pred_test):.2e}'+\" mE$_{h}$\",color=pairedcp[5])\n",
    "    ax2.plot(true_test,true_test,'k')\n",
    "    ax2.set_xlabel('Calculated CASPT2 Energy (E$_{h}$)')\n",
    "    ax2.set_ylabel('Predicted CASPT2 Energy (E$_{h}$)')\n",
    "    ax2.set_title('Test')    \n",
    "    ax2.legend()\n",
    "    \n",
    "    ax3.scatter(np.array(pred_train.index,dtype=float),pred_train,color=pairedcp[4])\n",
    "    ax3.plot(np.array(pt2.index,dtype=float),pt2.values,'k')\n",
    "    ax3.set_xlabel('Radius (Å)')\n",
    "    ax3.set_ylabel('CASPT2 Energy (E$_{h}$)')\n",
    "    ax3.set_title('Train')\n",
    "    \n",
    "    ax4.scatter(np.array(pred_test.index,dtype=float),pred_test,color=pairedcp[5])\n",
    "    ax4.plot(np.array(pt2.index,dtype=float),pt2.values,'k')\n",
    "    ax4.set_xlabel('Radius (Å)')\n",
    "    ax4.set_ylabel('CASPT2 Energy (E$_{h}$)')\n",
    "    ax4.set_title('Train')\n",
    "    \n",
    "    fig.suptitle(n)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'images/{n}_CASPT2.png',dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdad1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdfcorr=pd.DataFrame.from_dict(testcorr_err,orient='index').rename(columns={0:'test'})\n",
    "traindfcorr=pd.DataFrame.from_dict(traincorr_err,orient='index').rename(columns={0:'train'})\n",
    "errormeltcorr=pd.concat([traindfcorr,testdfcorr],axis=1).reset_index().melt(id_vars='index')\n",
    "errormeltcorr['index']=[i.split('_')[0] for i in errormeltcorr['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=pd.concat([CASPT2[i]-CASSCF[i] for i in sorted(CASSCF.columns,key=lambda x: int(x.strip('H')))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4dfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errormelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "\n",
    "sns.barplot(data=errormelt,x='index',y='value',hue='variable',palette=sns.color_palette('Paired'),ax=ax1)\n",
    "ax1.set_ylabel('Mean Absolute Error (mE$_{h}$)')\n",
    "ax1.set_xlabel('Structures')\n",
    "ax1.set_title('Pair-Energies')\n",
    "\n",
    "sns.barplot(data=errormeltcorr,x='index',y='value',hue='variable',palette=sns.color_palette('Paired'),ax=ax2)\n",
    "# ax2.set_ylabel('Mean Absolute Error (mE$_{h}$)')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_xlabel('Structures')\n",
    "ax2.set_title('Correlation Energies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/MAE_bar.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27ae96-a184-48c5-bf0f-ebeb7f42fac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SHAP\n",
    "feat_name=['screen1_1', 'screen1_2', 'screen1_3', 'screen1_4', 'screen2_1','screen2_2', 'screen2_3', 'screen2_4', 'eijab_1', 'eijab_2','eijab_3', 'eijab_4', 'screenvirt_1', 'screenvirt_3','screenvirt_4', 'Fr1', 'Fr2', 'Fr3', 'Fr4', 'Fs2', 'Fs3', 'Fs4','occs1', 'occs3', 'SCFFr1', 'SCFFr2', 'SCFFr3', 'SCFFr4', 'SCFFs1','SCFFs2', 'SCFFs3', 'SCFFs4', 'hrr1', 'hrr2', 'hrr3', 'hrr4','hss1', 'hss2', 'hss3', 'hpp', 'Fp', 'Fq', 'occp', 'occq']\n",
    "import shap\n",
    "explainer = shap.Explainer(model.predict, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "dffeat=pd.DataFrame(shap_values.abs.values.mean(axis=0),index=feat_name,columns=['shap']).reset_index().rename(columns={'index':'feat'})\n",
    "\n",
    "plt.figure(figsize=(8,10))\n",
    "color_map=sns.color_palette('rocket',6)\n",
    "fontsize = 18\n",
    "ax=dffeat.sort_values('shap').plot.barh(x='feat',y='shap',figsize=(9,10),legend=False,color=color_map[3])\n",
    "ax.bar_label(ax.containers[0], fmt='%.4e',fontsize=12,padding=1)\n",
    "plt.xticks(np.linspace(0,6e-3,4))\n",
    "plt.xlim(0,6e-3)\n",
    "plt.xlabel('mean(|SHAP value|)',fontsize=fontsize)\n",
    "plt.ylabel('Features',fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "plt.savefig('images/shap_bar.png',dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f48b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(feat_name).to_excel('kept_feat.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc200cee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
