{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "#Import packages\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from math import sin, cos, pi\n",
    "import glob\n",
    "import subprocess\n",
    "import pickle\n",
    "from subprocess import call, check_output\n",
    "import pandas as pd\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from plumbum.cmd import grep, awk\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "import sklearn\n",
    "from shutil import copy\n",
    "import csv\n",
    "import h5py as h5\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Obital labels\n",
    "## Inactive i,j\n",
    "## Active t,u,v\n",
    "## Virtual a,b\n",
    "\n",
    "## Type 1: IA->AA\n",
    "## Type 2: II->AA (P)\n",
    "## Type 3: II->AA (M)\n",
    "## Type 4: AA->VA\n",
    "## Type 5: IA->VA/AV\n",
    "## Type 6: II->AV (P)\n",
    "## Type 7: II->AV (M)\n",
    "## Type 8: AA->VV (P)\n",
    "## Type 9: AA->VV (M)\n",
    "## Type 10: IA->VV (P)\n",
    "## Type 11: IA->VV (M)\n",
    "## Type 12: II->VV (P)\n",
    "## Type 13: II->VV (M)\n",
    "\n",
    "## A: IA->AA\n",
    "## B: II->AA\n",
    "## C: AA->VA\n",
    "## D: IA->VA/AV\n",
    "## E: II->AV\n",
    "## F: AA->VV\n",
    "## G: IA->VV \n",
    "## H: II->VV\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.arange(106,181,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set precision, we can change this at will\n",
    "np.set_printoptions(precision=4)\n",
    "pd.set_option('precision', 4)\n",
    "\n",
    "# This tells us the number of structures and how theyre labeled\n",
    "# structs=np.arange(106,181,1)\n",
    "structs=np.round(np.arange(0.2,4,0.1), 2)\n",
    "# structs=np.arange(150,171,20)\n",
    "# CASPT2 excitation types\n",
    "excittype=np.arange(1,14,1)\n",
    "# Define molecule\n",
    "typ='FeO'\n",
    "\n",
    "# Find structures\n",
    "struct_name=[i for i in os.listdir() if i.endswith('.xyz') and i.startswith(f'{typ}') and '_' in i]\n",
    "\n",
    "if len(struct_name)==0:\n",
    "    for i in structs:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),'Coords',f'FeO_{i}.xyz')):\n",
    "            struct_name.append(f'FeO_{i}.xyz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(len(structs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete excessive extra files\n",
    "def del_useless():\n",
    "    '''\n",
    "    Delete the extra files\n",
    "    '''\n",
    "    for i in os.listdir():\n",
    "        for j in ['status','GssOrb','LprOrb','LoProp','guessorb','xmldump','RasOrb','SpdOrb']:\n",
    "            if j in i:\n",
    "                os.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When restarting a setr of calculations just clear everyting out\n",
    "def clean_dir():\n",
    "    for entry in os.scandir(path=os.getcwd()):\n",
    "        if entry.is_dir():\n",
    "            if entry.name=='Fock':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if entry.name=='hdf5':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if entry.name=='e2':\n",
    "                shutil.rmtree(entry.name)                \n",
    "            if entry.name=='Labels':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if entry.name=='Coords':\n",
    "                shutil.rmtree(entry.name)\n",
    "            if 'dir' in entry.name:\n",
    "                shutil.rmtree(entry.name)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this before clean_dir, this pulls the xyz files out just to \n",
    "def pull_xyz():\n",
    "    import re\n",
    "    for i in struct_name:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),i))==False and os.path.exists(os.path.join(os.getcwd(),'Coords')):\n",
    "            shutil.copy(os.path.join(os.getcwd(),'/'.join(('Coords',i))),os.path.join(os.getcwd(),i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_gateway(angle):\n",
    "    string=f'''&GATEWAY \n",
    "coord={f'FeO_{angle}.xyz'}\n",
    "Basis = ANO-RCC-MB\n",
    "Group = nosymm\n",
    "End of Input\n",
    "\n",
    "\n",
    "'''\n",
    "    return string\n",
    "def gen_seward():\n",
    "    string=f'''&SEWARD\n",
    "End of Input\n",
    "'''\n",
    "    return string\n",
    "\n",
    "def gen_motra(angle):\n",
    "    string=f'''&MOTRA\n",
    "Frozen=0\n",
    ">>> COPY $WorkDir/GMJ_one_int_indx.csv $CurrDir/{angle}.GMJ_one_int_indx.csv\n",
    ">>> COPY $WorkDir/GMJ_one_int.csv $CurrDir/{angle}.GMJ_one_int.csv\n",
    ">>> COPY $WorkDir/GMJ_AO_INT.csv $CurrDir/{angle}.GMJ_AO_INT.csv\n",
    "\n",
    "'''\n",
    "    return string\n",
    "\n",
    "def gen_scf(angle):\n",
    "    string=f\"\"\"&SCF &END\n",
    ">>> COPY $WorkDir/PT2_iron_oxo_{angle}.scf.h5 $CurrDir/\n",
    "\"\"\"\n",
    "    return string    \n",
    "\n",
    "\n",
    "def gen_rasscf(angle):\n",
    "    string=f\"\"\"&RASSCF &END\n",
    "Title= RASSCF\n",
    "fileorb\n",
    "{fileorb}\n",
    "NACTEL\n",
    "12 0 0\n",
    "Inactive\n",
    "11\n",
    "RAS2\n",
    "9\n",
    "Symmetry\n",
    "1\n",
    "Spin\n",
    "1\n",
    "orblisting\n",
    "all\n",
    "ITERation\n",
    "200 100\n",
    "CIMX\n",
    "200\n",
    "SDAV\n",
    "500\n",
    "PRWF\n",
    "0\n",
    "\n",
    ">>> COPY $WorkDir/PT2_iron_oxo_{angle}.rasscf.h5 $CurrDir/\n",
    ">>> COPY $WorkDir/GMJ_Fock_MO.csv $CurrDir/{angle}.GMJ_Fock_MO.csv\n",
    "\"\"\"\n",
    "    return string    \n",
    "\n",
    "def gen_caspt2():\n",
    "    string=\"\"\"&CASPT2 &END\n",
    "Frozen \n",
    "0\n",
    "Imaginary Shift\n",
    "0.0\n",
    "\n",
    ">>foreach i in (B,E,F,G,H)\n",
    ">>foreach j in (P,M)\n",
    ">>if ( -FILE GMJ_e2_${i}_${j}.csv )\n",
    ">>> COPY $WorkDir/GMJ_RHS_${i}_${j}.csv $CurrDir/GMJ_RHS_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECW_${i}_${j}.csv $CurrDir/GMJ_IVECW_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_e2_${i}_${j}.csv $CurrDir/GMJ_e2_${i}_${j}.csv\n",
    ">>endif\n",
    ">>enddo\n",
    ">>enddo\n",
    "\n",
    ">>foreach i in (A,C,D)\n",
    ">>if ( -FILE GMJ_e2_$i.csv )\n",
    ">>> COPY $WorkDir/GMJ_RHS_$i.csv $CurrDir/GMJ_RHS_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECW_$i.csv $CurrDir/GMJ_IVECW_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_e2_$i.csv $CurrDir/GMJ_e2_$i.csv\n",
    ">>endif\n",
    ">>enddo\n",
    "\n",
    "\"\"\"\n",
    "    return string    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_XYZ(angle):\n",
    "    f=open(f'FeO_{angle}.xyz','w+')\n",
    "#     N        0.0000000000      0.0000000000      0.0000000000                 \n",
    "#     N        1.4485557861      0.0000000000      0.0000000000\n",
    "    Fe=f'Fe {0.0000:.6f} {0.0000:.6f} {0.0000:.6f}'\n",
    "    O=f'O {angle:.6f} {0.0000:.6f} {0.0000:.6f}'    \n",
    "    mylist=[Fe, O]\n",
    "    f.write(str(len(mylist))+'\\n'+'\\n')\n",
    "    [f.write(i+'\\n') for i in mylist]\n",
    "    f.close()\n",
    "    return mylist\n",
    "    \n",
    "\n",
    "def gen_eq_orbs():\n",
    "    angle=1.558\n",
    "    gen_XYZ(angle)\n",
    "    new_input=f'''&GATEWAY \n",
    "coord={f'FeO_{angle}.xyz'}\n",
    "Basis = ANO-RCC-MB\n",
    "Group = nosymm\n",
    "End of Input\n",
    "\n",
    "\n",
    "\n",
    "&SEWARD\n",
    "End of Input\n",
    "\n",
    "&RASSCF &END\n",
    "Title= RASSCF\n",
    "NACTEL\n",
    "12 0 0\n",
    "Inactive\n",
    "11\n",
    "RAS2\n",
    "9\n",
    "Symmetry\n",
    "1\n",
    "Spin\n",
    "1\n",
    "orblisting\n",
    "all\n",
    "ITERation\n",
    "200 100\n",
    "CIMX\n",
    "200\n",
    "SDAV\n",
    "500\n",
    "PRWF\n",
    "0\n",
    "\n",
    "\n",
    "&CASPT2 &END\n",
    "Frozen\n",
    "0\n",
    "Imaginary Shift\n",
    "0.0\n",
    "'''\n",
    "    g=open(f'eq_orbs.input', 'wb')\n",
    "    g.write(new_input.encode())\n",
    "    g.close()\n",
    "    call(['pymolcas', f'eq_orbs.input', '-oe', f'eq_orbs.output'])\n",
    "\n",
    "# ALTEr=3; 1 10 11; 1 9 12; 1 13 13\n",
    "\n",
    "fileorb=os.path.join(os.getcwd(),'eq_orbs.RasOrb')\n",
    "def Gen_Scan():\n",
    "    import re\n",
    "    for angle in structs:\n",
    "        gen_XYZ(angle)\n",
    "        g=open(f'PT2_iron_oxo_{angle}.input', 'wb')\n",
    "        g.write(gen_gateway(angle).encode())\n",
    "        g.write(gen_seward().encode())\n",
    "        g.write(gen_motra(angle).encode())\n",
    "        g.write(gen_scf(angle).encode())        \n",
    "        g.write(gen_rasscf(angle).encode())        \n",
    "        g.write(gen_caspt2().encode())\n",
    "        g.close()\n",
    "        call(['pymolcas','-new','-clean',f'PT2_iron_oxo_{angle}.input', '-oe', f'PT2_iron_oxo_{angle}.output'])\n",
    "        [shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),f'{angle}.{i}')) for i in glob.glob(f'GMJ_RHS_*')]\n",
    "        [shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),f'{angle}.{i}')) for i in glob.glob(f'GMJ_IVECW_*')]        \n",
    "        [shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),f'{angle}.{i}')) for i in glob.glob(f'GMJ_e2_*')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move input and output files to their proper directory\n",
    "def mv_fils():\n",
    "    '''\n",
    "    Move the files to directories named for them\n",
    "    '''\n",
    "    import shutil\n",
    "    import os\n",
    "    for i in structs:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),f'{i}_dir')) is True:\n",
    "            if os.path.exists(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.output'))==True:\n",
    "                shutil.move(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.output'),os.path.join(os.getcwd(),f'{i}_dir',f'PT2_iron_oxo_{i}.output'))\n",
    "            if os.path.exists(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.input'))==True:\n",
    "                shutil.move(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.input'),os.path.join(os.getcwd(),f'{i}_dir',f'PT2_iron_oxo_{i}.input'))\n",
    "        else:\n",
    "            os.mkdir(f'{i}_dir')\n",
    "            if os.path.exists(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.output'))==True:\n",
    "                shutil.move(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.output'),os.path.join(os.getcwd(),f'{i}_dir',f'PT2_iron_oxo_{i}.output'))\n",
    "            if os.path.exists(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.input'))==True:\n",
    "                shutil.move(os.path.join(os.getcwd(),f'PT2_iron_oxo_{i}.input'),os.path.join(os.getcwd(),f'{i}_dir',f'PT2_iron_oxo_{i}.input'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data files to directories\n",
    "def mv_dat():\n",
    "# Move h5 and coord files to dirs\n",
    "    for i in os.listdir():\n",
    "        if i.endswith('h5'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'hdf5')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('hdf5',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'hdf5')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('hdf5',i))))\n",
    "# Move xyz files\n",
    "        if i.endswith('.xyz') and i.startswith(f'{typ}') and '_' in i:\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'Coords')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('Coords',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'Coords')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('Coords',i))))\n",
    "# Move pair energy files\n",
    "        if '_e2' in i and i.endswith('csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'e2')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('e2',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'e2')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('e2',i))))\n",
    "# Move rhs files which tell how the ivvecc2 and ivecw files are indexed\n",
    "        if 'RHS' in i and i.endswith('csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'Labels')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('Labels',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'Labels')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('Labels',i))))\n",
    "        if 'IVECW' in i and i.endswith('csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'IVECW')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('IVECW',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'IVECW')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('IVECW',i))))\n",
    "\n",
    "                    \n",
    "# MO fock matrix\n",
    "        if 'Fock' in i and i.endswith('csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'Fock')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('Fock',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'Fock')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('Fock',i))))\n",
    "        if i.endswith('_one_int_indx.csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'1_int_idx')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('1_int_idx',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'1_int_idx')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('1_int_idx',i))))\n",
    "        if i.endswith('_two_int_indx.csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'2_int_idx')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('2_int_idx',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'2_int_idx')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('2_int_idx',i))))\n",
    "        if i.endswith('GMJ_one_int.csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'1_ints')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('1_ints',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'1_ints')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('1_ints',i))))\n",
    "        if i.endswith('GMJ_two_int.csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'2_ints')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('2_ints',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'2_ints')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('2_ints',i))))\n",
    "        if i.endswith('GMJ_AO_INT.csv'):\n",
    "            if os.path.exists(os.path.join(os.getcwd(),i))==True:\n",
    "                if os.path.exists(os.path.join(os.getcwd(),f'AO_ints')) is True:\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('AO_ints',i))))\n",
    "                else:\n",
    "                    os.mkdir(f'AO_ints')\n",
    "                    shutil.move(os.path.join(os.getcwd(),i),os.path.join(os.getcwd(),'/'.join(('AO_ints',i))))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run():\n",
    "    # Pull xyz structures\n",
    "    pull_xyz()\n",
    "    # The rest follows as labeled above\n",
    "    clean_dir()\n",
    "    gen_eq_orbs()    \n",
    "    Gen_Scan() \n",
    "    mv_fils()\n",
    "    del_useless()\n",
    "    mv_dat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a new run\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab caspt2 energies\n",
    "def caspt2():\n",
    "    PT2=[]\n",
    "    PT2List=[]\n",
    "    PT2labels=[]\n",
    "\n",
    "    for j in structs:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),f'{j}_dir'))==True:\n",
    "            path=os.path.join(os.getcwd(),f'{j}_dir',f'PT2_iron_oxo_{j}.output')\n",
    "            PT2labels.append(j)\n",
    "            PT2.append(float((grep['-i', '::    CASPT2',path] | awk['{print $NF }'])()))\n",
    "    PT2List=np.array(PT2)\n",
    "    PT2Dict=pd.DataFrame({'Label':PT2labels,'PT2':PT2List})\n",
    "    PT2Dict.to_csv('CASPT2.csv')        \n",
    "    return PT2Dict.set_index('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProcessExecutionError",
     "evalue": "Unexpected exit code: 1\nCommand line: | /usr/bin/grep -i '::    CASPT2' /Users/gjonesresearch/DDCASPT2/MolcasProjects/iron_oxo/2.9_dir/PT2_iron_oxo_2.9.output",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mProcessExecutionError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4d/cr5rpmzs5dv4gsmlcvz365zw0000gn/T/ipykernel_18934/3876380889.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_CASPT2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaspt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/4d/cr5rpmzs5dv4gsmlcvz365zw0000gn/T/ipykernel_18934/1526681557.py\u001b[0m in \u001b[0;36mcaspt2\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{j}_dir'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'PT2_iron_oxo_{j}.output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mPT2labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mPT2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'-i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'::    CASPT2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mawk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'{print $NF }'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mPT2List\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPT2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mPT2Dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Label'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPT2labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'PT2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPT2List\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/commands/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;34m\"\"\"A shortcut for `run(args)`, returning only the process' stdout\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/commands/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, args, **kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbgrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_use_modifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/commands/base.py\u001b[0m in \u001b[0;36mrunner\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mwas_run\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mrun_proc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m  \u001b[0;31m# to break cyclic reference p -> cell -> p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/commands/processes.py\u001b[0m in \u001b[0;36mrun_proc\u001b[0;34m(proc, retcode, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcustom_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_check_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/commands/processes.py\u001b[0m in \u001b[0;36m_check_process\u001b[0;34m(proc, retcode, timeout, stdout, stderr)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#===================================================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/commands/base.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(proc, retcode, timeout, stdout, stderr)\u001b[0m\n\u001b[1;32m    401\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     \u001b[0mor_retcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrcproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mor_retcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mdstproc_verify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/plumbum/machines/base.py\u001b[0m in \u001b[0;36mverify\u001b[0;34m(self, retcode, timeout, stdout, stderr)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__contains__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m                     raise ProcessExecutionError(\n\u001b[0m\u001b[1;32m     21\u001b[0m                         \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"argv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                         stderr)\n",
      "\u001b[0;31mProcessExecutionError\u001b[0m: Unexpected exit code: 1\nCommand line: | /usr/bin/grep -i '::    CASPT2' /Users/gjonesresearch/DDCASPT2/MolcasProjects/iron_oxo/2.9_dir/PT2_iron_oxo_2.9.output"
     ]
    }
   ],
   "source": [
    "df_CASPT2=caspt2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_CASPT2-df_CASPT2.max())\n",
    "plt.ylim(-176.25,-176)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to grab the whole row\n",
    "# caspt2().loc[caspt2()['Labels'] =='ethylene_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab casscf energies \n",
    "def casscf():\n",
    "    SCF=[]\n",
    "    SCFList=[]\n",
    "    SCFlabels=[]\n",
    "    for j in structs:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),f'{j}_dir'))==True:\n",
    "            path=os.path.join(os.getcwd(),f'{j}_dir',f'PT2_iron_oxo_{j}.output')\n",
    "            SCFlabels.append(j)\n",
    "            SCF.append(float((grep['-i', '::    RASSCF root number  1',path] | awk['{print $8 }'])()))\n",
    "    SCFList=np.array(SCF)\n",
    "    SCFDict=pd.DataFrame({'Label':SCFlabels,'SCF':SCFList})\n",
    "    SCFDict.to_csv('CASSCF.csv')    \n",
    "    return SCFDict.set_index('Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CASSCF=casscf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CASSCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab PT2 energies \n",
    "def PT2():\n",
    "    E2=[]\n",
    "    E2List=[]\n",
    "    E2labels=[]\n",
    "    ES_E2=[]\n",
    "    ES_E2List=[]\n",
    "    ES_E2labels=[]\n",
    "\n",
    "    for j in structs:\n",
    "        if os.path.exists(os.path.join(os.getcwd(),f'{j}_dir'))==True:\n",
    "            path=os.path.join(os.getcwd(),f'{j}_dir',f'PT2_iron_oxo_{j}.output')\n",
    "            E2labels.append(j)\n",
    "            E2.append(float((grep['-i', 'E2 (Variational):',path] | awk['{print $NF }'])()))\n",
    "    E2List=np.array(E2)\n",
    "    E2Dict=pd.DataFrame({'Label':E2labels,'E2':E2List})\n",
    "    df=E2Dict.set_index('Label')\n",
    "    df.to_csv('E2.csv')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2Dict=PT2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab file paths for the directories\n",
    "# onlyfiles = [f for f in os.listdir(os.getcwd()) if os.path.isdir(os.path.join(os.getcwd(), f))]\n",
    "onlyfiles = (f for f in os.listdir(os.getcwd()) if os.path.isdir(os.path.join(os.getcwd(), f)))\n",
    "for entry in os.scandir(path=os.getcwd()):\n",
    "    if entry.is_dir():\n",
    "        if entry.name=='Fock':\n",
    "            path_to_Focks=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='e2':\n",
    "            path_to_e2=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='Labels':\n",
    "            path_to_Labels=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='IVECW':\n",
    "            path_to_IVECW=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='1_ints':\n",
    "            path_to_1_ints=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='2_ints':\n",
    "            path_to_2_ints=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='1_int_idx':\n",
    "            path_to_1_int_idx=os.path.join(os.getcwd(),entry.name)\n",
    "        if entry.name=='2_int_idx':\n",
    "            path_to_2_int_idx=os.path.join(os.getcwd(),entry.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "typ_exists=sorted(sum(list([j.replace('GMJ_e2_','') for j in i.split('/')[-1].split('.') if 'GMJ' in j] for i in glob.glob(os.path.join(path_to_e2,f'{structs[0]}.GMJ_e2_*'))),[]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exists.pickle', 'wb') as handle:\n",
    "    pickle.dump(typ_exists, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "#   Keep everything at float64\n",
    "DTYPE = np.float_\n",
    "# DTYPE = np.float16\n",
    "\n",
    "#   Create an array with the easy data\n",
    "def createArrray(filename):\n",
    "    files = sorted(glob.glob(filename))\n",
    "    arrayname = []\n",
    "    for i in sorted(files):\n",
    "        arrayname.append(\n",
    "            np.stack(\n",
    "                np.array(pd.read_csv(i, header=None),\n",
    "                         dtype=DTYPE,\n",
    "                         copy=False).flatten()))\n",
    "\n",
    "    arrayname = np.asarray(arrayname, dtype=DTYPE)\n",
    "    return arrayname\n",
    "#   Start transforming the HDF5 files from the data directory\n",
    "h5list = []\n",
    "for i in structs:\n",
    "    h5list.append(os.path.join(os.getcwd(),'hdf5',f'PT2_iron_oxo_{str(i)}.rasscf.h5'))\n",
    "# Grab AO_OVERLAP_MATRIX,MO_ENERGIES,MO_OCCUPATIONS,MO_VECTORS,MO_TYPEINDICES,NACTEL,NBAS from hdf5\n",
    "def h5feats(h5list):\n",
    "    f = h5.File(h5list[0], 'r')\n",
    "    datasetNames = [n for n in f.keys()]\n",
    "    b = []\n",
    "    labels = []\n",
    "    # AO_FOCKINT_MATRIX=[]\n",
    "    # Useful attributes from the hdf5 files\n",
    "    NBAS=[]\n",
    "    NACTEL=[]\n",
    "    for k, elem in enumerate(structs):\n",
    "        for count, ele in enumerate([i for i in f.attrs]):\n",
    "            if ele =='NBAS':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list[k],'r').attrs[ele]).reshape(-1)):\n",
    "                    NBAS.append(elemt)\n",
    "            if ele =='NACTEL':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list[k],'r').attrs[ele]).reshape(-1)):\n",
    "                    NACTEL.append(elemt)\n",
    "\n",
    "\n",
    "    MO_ENERGIES=[]\n",
    "    MO_OCCUPATIONS=[]\n",
    "    MO_TYPEINDICES=[]\n",
    "    MO_VECTORS=[]\n",
    "    t0=time()\n",
    "    #   Eliminate certain features that won't be good for regression\n",
    "    for k, elem in enumerate(structs):\n",
    "        for count, ele in enumerate([n for n in h5.File(h5list[k], 'r').keys()]):\n",
    "            if ele =='MO_TYPEINDICES':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list[k],'r')[ele]).reshape(-1)):\n",
    "                    MO_TYPEINDICES.append(elemt)\n",
    "\n",
    "            if ele =='MO_ENERGIES':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list[k],'r')[ele]).reshape(-1)):\n",
    "                    MO_ENERGIES.append(elemt)\n",
    "\n",
    "            if ele =='MO_OCCUPATIONS':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list[k],'r')[ele]).reshape(-1)):\n",
    "                    MO_OCCUPATIONS.append(elemt)\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "    print(f'time: {time()-t0} s')\n",
    "    # AO_FOCKINT_MATRIX=np.array(AO_FOCKINT_MATRIX).reshape(len(dislist),int(NBAS[0]),int(NBAS[0]))\n",
    "    MO_ENERGIES= np.array(MO_ENERGIES).reshape(len(structs),int(NBAS[0]))\n",
    "    MO_OCCUPATIONS= np.array(MO_OCCUPATIONS).reshape(len(structs),int(NBAS[0]))\n",
    "    MO_TYPEINDICES=np.array(MO_TYPEINDICES).reshape(len(structs),int(NBAS[0]))\n",
    "    \n",
    "    return MO_ENERGIES,MO_OCCUPATIONS,MO_TYPEINDICES,NACTEL,NBAS\n",
    "\n",
    "\n",
    "MO_ENERGIES,MO_OCCUPATIONS,MO_TYPEINDICES,NACTEL,NBAS=h5feats(h5list)\n",
    "\n",
    "\n",
    "h5list_scf = []\n",
    "for i in structs:\n",
    "    h5list_scf.append(os.path.join(os.getcwd(),'hdf5',f'PT2_iron_oxo_{str(i)}.scf.h5'))\n",
    "# Grab AO_OVERLAP_MATRIX,MO_ENERGIES,MO_OCCUPATIONS,MO_VECTORS,MO_TYPEINDICES,NACTEL,NBAS from hdf5\n",
    "def MO_VEC(h5list_scf):\n",
    "    f = h5.File(h5list_scf[0], 'r')\n",
    "    datasetNames = [n for n in f.keys()]\n",
    "    b = []\n",
    "    labels = []\n",
    "    # AO_FOCKINT_MATRIX=[]\n",
    "    # Useful attributes from the hdf5 files\n",
    "    NBAS=[]\n",
    "    NACTEL=[]\n",
    "    for k, elem in enumerate(structs):\n",
    "        for count, ele in enumerate([i for i in f.attrs]):\n",
    "            if ele =='NBAS':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r').attrs[ele]).reshape(-1)):\n",
    "                    NBAS.append(elemt)\n",
    "    MO_VECTORS=[]\n",
    "    MO_ENERGIES=[]  \n",
    "    MO_OCCUPATIONS=[]\n",
    "    t0=time()\n",
    "    #   Eliminate certain features that won't be good for regression\n",
    "    for k, elem in enumerate(structs):\n",
    "        for count, ele in enumerate([n for n in h5.File(h5list_scf[k], 'r').keys()]):\n",
    "            if ele =='MO_VECTORS':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r')[ele]).reshape(-1)):\n",
    "                    MO_VECTORS.append(elemt)\n",
    "            if ele =='MO_ENERGIES':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r')[ele]).reshape(-1)):\n",
    "                    MO_ENERGIES.append(elemt)\n",
    "            if ele =='MO_OCCUPATIONS':\n",
    "                for i, elemt in enumerate(np.array(h5.File(h5list_scf[k],'r')[ele]).reshape(-1)):\n",
    "                    MO_OCCUPATIONS.append(elemt)\n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "                    \n",
    "\n",
    "    print(f'time: {time()-t0} s')\n",
    "    MO_ENERGIES= np.array(MO_ENERGIES).reshape(len(structs),int(NBAS[0]))\n",
    "    MO_OCCUPATIONS= np.array(MO_OCCUPATIONS).reshape(len(structs),int(NBAS[0]))\n",
    "    MO_VECTORS=np.array(MO_VECTORS).reshape(len(structs),int(NBAS[0]),int(NBAS[0]))\n",
    "    \n",
    "    return MO_VECTORS,MO_ENERGIES,MO_OCCUPATIONS\n",
    "\n",
    "\n",
    "MO_VECTORS,scf_F,scf_OCC=MO_VEC(h5list_scf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_indx(list_of_dicts):\n",
    "    indx=[]\n",
    "    for i in list_of_dicts.keys():\n",
    "        if len(list_of_dicts[i])>0:\n",
    "            indx.append(list(list_of_dicts[i].keys()))\n",
    "    return indx[0]\n",
    "\n",
    "\n",
    "path_check=os.path.join(os.getcwd(),f'{structs[0]}_dir',f'PT2_iron_oxo_{structs[0]}.output')\n",
    "\n",
    "# Sanity check...\n",
    "# REMEMBER FROZEN CORE APPROXIMATION\n",
    "# Number of frozen orbitals\n",
    "fro=int(subprocess.Popen(f\"grep -i 'Frozen orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of inactive orbitals\n",
    "inact=int(subprocess.Popen(f\"grep -i 'Inactive orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of active orbitals\n",
    "act=int(subprocess.Popen(f\"grep -i 'Active orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of seconary orbitals\n",
    "virt=int(subprocess.Popen(f\"grep -i 'Secondary orbitals' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "# Number of basis functions for sanity check\n",
    "bas_check=int(subprocess.Popen(f\"grep -i 'Number of basis functions' {path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "\n",
    "Basis_Indices=[]\n",
    "for i in range(fro):\n",
    "    Basis_Indices.append(f'F{i+1}')\n",
    "for i in range(inact):\n",
    "    Basis_Indices.append(f'I{i+1}')\n",
    "for i in range(act):\n",
    "    Basis_Indices.append(f'A{i+1}')\n",
    "for i in range(virt):\n",
    "    Basis_Indices.append(f'S{i+1}')    \n",
    "    \n",
    "print(f'Basis sanity check passed={bas_check==len(Basis_Indices)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the labels that match the IVECW and IVECC2 files\n",
    "def gen_labels(typ):\n",
    "    Labels=[]\n",
    "    Indexes=[]\n",
    "    i=structs[0]\n",
    "    return [j.split()[0].replace('\\n','').replace('00','').replace('S0','S').replace('I0','I').replace(',','') for j in open(os.path.join(path_to_Labels,f'{i}.GMJ_RHS_{typ}.csv'),'r').readlines()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair_labels(typ):\n",
    "    Labels=[]\n",
    "    Indexes=[]\n",
    "    i=structs[0]\n",
    "    return sorted(set(['_'.join(j.split()[0].replace('\\n','').replace('00','').replace('S0','S').replace('I0','I').replace(',','').split('_')[0:2]) for j in open(os.path.join(path_to_Labels,f'{i}.GMJ_RHS_{typ}.csv'),'r').readlines()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(typ,len(gen_labels(typ)),len(gen_pair_labels(typ))) for typ in typ_exists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_dim_dict(typ_exists):\n",
    "    '''    \n",
    "    Dimension check for DDCASPT2: check the ordering of the pair-energies,\n",
    "    this notation follows a mix of the papers and code.\n",
    "    \n",
    "    A (IA->AA): \\n TIUV \\n E_{ti} E_{uv} \\n pqrs=tiuv=0123 \\n    \n",
    "    B_P (II->AA) (P): \\n IJTU \\n E_{ti} E_{uj} \\n pqrs=tiuj=2031 \\n\n",
    "    B_M (II->AA) (M): \\n IJTU \\n E_{ti} E_{uj} \\n pqrs=tiuj=2031 \\n\n",
    "    C (AA->VA): \\n UVAT \\n E_{at} E_{uv} \\n pqrs=atuv=2301 \\n\n",
    "    D (IA->VA/AV): \\n IUAT/IUTA \\n E_{ai} E_{tu}/E_{ti} E_{au} \\n pqrs=(a/t)i(t/a)u=2031 \\n\n",
    "    E_P (II->AV) (P): \\n IJAT \\n E_{ti} E_{aj} \\n pqrs=tiaj=3021 \\n\n",
    "    E_M (II->AV) (M): \\n IJAT \\n E_{ti} E_{aj} \\n pqrs=tiaj=3021 \\n\n",
    "    F_P (AA->VV) (P): \\n TUAB \\n E_{at} E_{bu} \\n pqrs=atbu=2031 \\n\n",
    "    F_M (AA->VV) (M): \\n TUAB \\n E_{at} E_{bu} \\n pqrs=atbu=2031 \\n\n",
    "    G_P (IA->VV) (P): \\n ITAB \\n E_{ai} E_{bt} \\n pqrs=aibt=2031 \\n\n",
    "    G_M (IA->VV) (M): \\n ITAB \\n E_{ai} E_{bt} \\n pqrs=aibt=2031 \\n\n",
    "    H_P (II->VV) (P): \\n IJAB \\n E_{ai} E_{bj} \\n pqrs=aibj=2031 \\n\n",
    "    H_M (II->VV) (M): \\n IJAB \\n E_{ai} E_{bj} \\n pqrs=aibj=2031 \\n\n",
    "    '''    \n",
    "    i=structs[0]\n",
    "    dims=[]\n",
    "    for typ in typ_exists:\n",
    "        dims.append((typ,np.array([i.split('=')[-1].split('x') for i in open(os.path.join(path_to_e2,f'{i}.GMJ_e2_{typ}.csv'),'r').readlines() if 'mat. size =' in i ]).flatten().astype(int)))\n",
    "    return dict(dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_dict=gen_dim_dict(typ_exists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip(lst):   \n",
    "    return '_'.join(i.replace('A00','A').replace('I00','I').replace('S00','S').replace('I0','I').replace('A0','A').replace('S0','S') for i in lst.split('_'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ordered(typ):\n",
    "    '''\n",
    "    Return a dataframe for each type\n",
    "    Index=proper indexing\n",
    "    level_0=row\n",
    "    level_1=column\n",
    "    0=W value\n",
    "    '''\n",
    "    i=structs[0]\n",
    "    ordered=pd.read_csv(os.path.join(path_to_IVECW,f'{i}.GMJ_IVECW_{typ}.csv'),delim_whitespace=True, skiprows=[0],header=None).astype(np.float64).dropna(axis=1)\n",
    "    ordered.columns=list(range(len(ordered.columns)))\n",
    "    ordered=ordered.stack()\n",
    "    df=pd.read_csv(os.path.join(path_to_Labels,f'{i}.GMJ_RHS_{typ}.csv'),header=None,delimiter=',',index_col=0)\n",
    "    df.index=list(map(strip,df.index))\n",
    "    merged=ordered.reset_index().sort_values(by=0).set_index(df.sort_values(by=1).index).sort_values(['level_0','level_1'])    \n",
    "\n",
    "#     print(f'Type {typ} all are correct={(merged[0].values.flatten()==ordered.values.flatten()).all()==True}')\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate IVECW\n",
    "def gen_e2(typ):\n",
    "    e2=[]\n",
    "    proper_labels=gen_labels(typ)\n",
    "    for i in structs:\n",
    "        df=pd.read_csv(os.path.join(path_to_e2,f'{i}.GMJ_e2_{typ}.csv'),delim_whitespace=True, skiprows=[0],header=None).astype(np.float64).dropna(axis=1).stack()\n",
    "        df.index=gen_ordered(typ).index\n",
    "        df=df.to_frame(name=str(i))\n",
    "        e2.append(df)\n",
    "    df1=pd.concat(e2,axis=1).loc[proper_labels]\n",
    "    df1.index=[i for idx,i in enumerate(proper_labels)]\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_pair(typ):\n",
    "    Y=gen_e2(typ).astype(float)\n",
    "# Needs to be qs, we're summing over the occupied orbitals    \n",
    "    Y_pair_set=list(set(['_'.join((i.split('_')[0],i.split('_')[1]))+'_' for i in Y.index.tolist()]))\n",
    "    Y_pair_df=pd.concat([Y[Y.index.str.find(j)==0].sum() for j in Y_pair_set],axis=1)\n",
    "    Y_pair_df.columns=list(set(['_'.join((i.split('_')[0],i.split('_')[1])) for i in Y.index.tolist()]))\n",
    "    return Y_pair_df.T.sort_index().groupby(level=0).sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_label(typ):\n",
    "    if f'{typ}_M' in typ_exists and f'{typ}_P' in typ_exists:\n",
    "        return gen_pair_labels(f'{typ}_P')+gen_pair_labels(f'{typ}_M')\n",
    "    elif f'{typ}_P' in typ_exists:\n",
    "        return gen_pair_labels(f'{typ}_P')\n",
    "    elif f'{typ}_M' in typ_exists:\n",
    "        return gen_pair_labels(f'{typ}_M')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_e2(typ):\n",
    "    if f'{typ}_M' in typ_exists and f'{typ}_P' in typ_exists:\n",
    "        df=pd.concat([gen_pair(f'{typ}_M'),gen_pair(f'{typ}_P')],axis=0).groupby(level=0).sum()\n",
    "#         df.index=[i for idx,i in enumerate(stack_label(typ))]\n",
    "        return df\n",
    "    elif f'{typ}_P' in typ_exists:\n",
    "        return gen_pair(f'{typ}_P').groupby(level=0).sum()\n",
    "    elif f'{typ}_M' in typ_exists:\n",
    "        return gen_pair(f'{typ}_M').groupby(level=0).sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the data\n",
    "for typ in set([i.split('_')[0] for i in typ_exists ]):\n",
    "    if typ=='A':\n",
    "        typA_e2=gen_pair(f'{typ}')        \n",
    "        typA_labels=gen_pair_labels(typ)\n",
    "    if typ=='B':        \n",
    "        typB_e2=stack_e2(typ)\n",
    "        typB_labels=stack_label(typ)        \n",
    "    if typ=='C':\n",
    "        typC_e2=gen_pair(f'{typ}')\n",
    "        typC_labels=gen_pair_labels(f'{typ}')\n",
    "    if typ=='D':        \n",
    "        typD_labels=gen_pair_labels(f'{typ}')\n",
    "        typD_e2=gen_pair(f'{typ}')\n",
    "    if typ=='E':\n",
    "        typE_e2=stack_e2(typ)\n",
    "        typE_labels=stack_label(typ)\n",
    "    if typ=='F':        \n",
    "        typF_e2=stack_e2(typ)\n",
    "        typF_labels=stack_label(typ)\n",
    "    if typ=='G':        \n",
    "        typG_e2=stack_e2(typ)\n",
    "        typG_labels=stack_label(typ)\n",
    "    if typ=='H':  \n",
    "        typH_e2=stack_e2(typ)\n",
    "        typH_labels=stack_label(typ)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(typA_labels+typB_labels+typC_labels+typD_labels+typE_labels+typF_labels+typG_labels+typH_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_e2=pd.concat([gen_e2(typ) for typ in typ_exists]).groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_e2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(E2Dict,stacked_e2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_40=stacked_e2.T.abs().describe().loc['mean'].sort_values(ascending=False).nlargest(500).index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_pairs=pd.concat([typA_e2,typB_e2,typC_e2,typD_e2,typE_e2,typF_e2,typG_e2,typH_e2]).groupby(level=0).sum()\n",
    "pair_labels=stacked_pairs.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typ_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([gen_pair(typ) for typ in typ_exists]).groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_stack=pd.concat([gen_e2(typ) for typ in typ_exists])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab molecular orbital occupations and make it into a dataframe labeled with xyz file name\n",
    "MO_OCC=[]\n",
    "for j in range(len(structs)):\n",
    "    MO_OCC.append(dict(zip(Basis_Indices,[i for i in list(MO_OCCUPATIONS[j])])))\n",
    "MO_OCC_Dict=dict(zip([str(k) for k in structs],MO_OCC))\n",
    "MO_OCC_DF=pd.DataFrame(MO_OCC_Dict)\n",
    "\n",
    "# Dataframe of MO occupation, index=basis indices and columns=structs\n",
    "MO_OCCUPATIONS_DF=pd.DataFrame(MO_OCCUPATIONS,index=structs,columns=Basis_Indices).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Keep in mind HDF5 zeroes out the actrive orbitals... we'll use the Fock matrix to recover these\n",
    "# \n",
    "# Grab molecular orbital energy and make it into a dataframe labeled with xyz file name\n",
    "MO_Energ=[]\n",
    "for j in range(len(structs)):\n",
    "    MO_Energ.append(dict(zip(Basis_Indices,[i for i in list(MO_ENERGIES[j])])))\n",
    "\n",
    "MO_Energ_Dict=dict(zip([str(k) for k in structs],MO_Energ))\n",
    "MO_Energy_DF=pd.DataFrame(MO_Energ_Dict)\n",
    "\n",
    "# Dataframe of MO energies, index=basis indices and columns=structs\n",
    "MO_ENERGIES_DF=pd.DataFrame(MO_ENERGIES,index=structs,columns=Basis_Indices).transpose()\n",
    "\n",
    "# Generate fock matrix\n",
    "Fock_mats=[]\n",
    "for indx,j in enumerate(structs):\n",
    "    fileFock=open(os.path.join(path_to_Focks,f'{j}.GMJ_Fock_MO.csv'),'r').readlines()\n",
    "    shape=[int(k) for k in fileFock[0].split('x')]\n",
    "    Fock_mats.append(np.array([float(i.split()[2]) for i in fileFock[1:]]).reshape([int(k) for k in fileFock[0].split('x')]))\n",
    "Fock_mats=np.array(Fock_mats)    \n",
    "Fock_dict=dict(zip([str(z) for z in structs],Fock_mats))\n",
    "labeled_fock_dict=dict(zip([str(z) for z in structs],[pd.DataFrame(Fock_dict[str(x)],index=Basis_Indices,columns=Basis_Indices) for x in structs]))\n",
    "\n",
    "\n",
    "# List of MOs Energies\n",
    "TEST_New_MO_Energies=[]\n",
    "for i in structs:\n",
    "    for indx,nam in enumerate(Basis_Indices):\n",
    "        if nam[0]=='A':\n",
    "            TEST_New_MO_Energies.append((nam,float(0.5*labeled_fock_dict[str(i)][nam][nam])))\n",
    "        if nam[0]!='A':\n",
    "            TEST_New_MO_Energies.append((nam,float(MO_Energ_Dict[str(i)][nam])))\n",
    "\n",
    "New_MO_Dict=dict(zip([str(z) for z in structs],[dict(np.array(TEST_New_MO_Energies).reshape(len(structs),len(Basis_Indices),-1)[i]) for i in range(len(structs))]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for indx,k in enumerate(structs):\n",
    "    labeled_fock_dict[str(k)]=labeled_fock_dict[str(k)]*0.5\n",
    "    for i in Basis_Indices:\n",
    "        for j in Basis_Indices:\n",
    "            labeled_fock_dict[str(k)][j][i]=labeled_fock_dict[str(k)][i][j]\n",
    "            if i==j and i.startswith('S') and j.startswith('S'):\n",
    "                labeled_fock_dict[str(k)][i][j]=MO_ENERGIES_DF[k].loc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_fock_dict['106.0']['A1']['A1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_MO_Dict['106.0']['A1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_one_int():\n",
    "    one_int=[]\n",
    "    Labels=[]\n",
    "    Indexes=[]\n",
    "    upd_1int_indx=[]\n",
    "    def one_gener(i):\n",
    "        for j in open(os.path.join(path_to_1_ints,f'{i}.GMJ_one_int.csv'),'r').readlines():\n",
    "            yield float(j.replace('\\n',''))\n",
    "    def one_lbl_gen(i):\n",
    "        for j in open(os.path.join(path_to_1_int_idx,f'{i}.GMJ_one_int_indx.csv'),'r').readlines():\n",
    "            yield '_'.join(j.replace('\\n','').split()) \n",
    "\n",
    "    for i in one_lbl_gen(structs[0]):\n",
    "        upd_1int_indx.append(Basis_Indices[int(i.split('_')[0])-1]+'_'+Basis_Indices[int(i.split('_')[1])-1])\n",
    "\n",
    "#     Dict=dict(zip(Indexes,Labels))\n",
    "    return pd.concat([pd.DataFrame(one_gener(str(i)),index=upd_1int_indx,columns=[str(i)]) for ind,i in enumerate(structs)],axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0=time()\n",
    "int1=gen_one_int()\n",
    "print(f'Integrals loaded in {time()-t0:0.4f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix1(g):\n",
    "    II=[]\n",
    "    AA=[]\n",
    "    SS=[]\n",
    "    IA=[]\n",
    "    AS=[]\n",
    "    SI=[]    \n",
    "    ad_df=[]\n",
    "\n",
    "\n",
    "# II\n",
    "    for i in range(len([i for i in Basis_Indices if i.startswith('I')])):\n",
    "        for j in range(i,len([i for i in Basis_Indices if i.startswith('I')])):\n",
    "            if f'I{i+1}'!=f'I{j+1}':\n",
    "                II.append((f'I{i+1}_I{j+1}',int1[str(g)].loc[f'I{j+1}_I{i+1}']))\n",
    "\n",
    "    # AA        \n",
    "    for i in range(len([i for i in Basis_Indices if i.startswith('A')])):\n",
    "        for j in range(i,len([i for i in Basis_Indices if i.startswith('A')])):\n",
    "            if f'A{i+1}'!=f'A{j+1}':\n",
    "                AA.append((f'A{i+1}_A{j+1}',int1[str(g)].loc[f'A{j+1}_A{i+1}']))\n",
    "\n",
    "    # SS    \n",
    "    for i in range(len([i for i in Basis_Indices if i.startswith('S')])):\n",
    "        for j in range(i,len([i for i in Basis_Indices if i.startswith('S')])):\n",
    "            if f'S{i+1}'!=f'S{j+1}':\n",
    "                SS.append((f'S{i+1}_S{j+1}',int1[str(g)].loc[f'S{j+1}_S{i+1}']))\n",
    "\n",
    "# Off diagonal        \n",
    "\n",
    "# IA\n",
    "    for i in range(len([i for i in Basis_Indices if i.startswith('I')])):\n",
    "        for j in range(len([i for i in Basis_Indices if i.startswith('A')])):\n",
    "            IA.append((f'I{i+1}_A{j+1}',int1[str(g)].loc[f'A{j+1}_I{i+1}']))\n",
    "\n",
    "\n",
    "# SA\n",
    "    for i in range(len([i for i in Basis_Indices if i.startswith('A')])):\n",
    "        for j in range(len([i for i in Basis_Indices if i.startswith('S')])):\n",
    "            AS.append((f'A{i+1}_S{j+1}',int1[str(g)].loc[f'S{j+1}_A{i+1}']))\n",
    "           \n",
    "# SI\n",
    "    for i in range(len([i for i in Basis_Indices if i.startswith('I')])):\n",
    "        for j in range(len([i for i in Basis_Indices if i.startswith('S')])):\n",
    "            SI.append((f'I{i+1}_S{j+1}',int1[str(g)].loc[f'S{j+1}_I{i+1}']))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    return pd.concat([pd.DataFrame(int1[str(g)],columns=[str(g)]),pd.DataFrame(II,columns=[0,str(g)]).set_index(0),pd.DataFrame(AA,columns=[0,str(g)]).set_index(0),pd.DataFrame(SS,columns=[0,str(g)]).set_index(0),pd.DataFrame(IA,columns=[0,str(g)]).set_index(0),pd.DataFrame(AS,columns=[0,str(g)]).set_index(0),pd.DataFrame(SI,columns=[0,str(g)]).set_index(0)],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fxd_1ints=pd.concat([fix1(str(i)) for i in structs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option(\"precision\", 2)\n",
    "# np.set_printoptions(precision=2)\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "\n",
    "\n",
    "nmo=len(Basis_Indices)\n",
    "indice=[]\n",
    "ad_ind=[]\n",
    "for ind,i in enumerate(range(nmo)):\n",
    "    for indx,j in enumerate(range(nmo)):\n",
    "        ad_ind.append(f'{i+1}_{j+1}')\n",
    "        if j<=i:\n",
    "            indice.append(f'{i+1}_{j+1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(indice),len(ad_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def gen_MO(k):\n",
    "    if os.path.exists(os.path.join(os.getcwd(),f'AO_ints/{k}.GMJ_AO_INT.csv'))==True:\n",
    "        AO_ints=np.genfromtxt(fname=f'AO_ints/{k}.GMJ_AO_INT.csv', dtype='float').reshape(len(indice),nmo*nmo)\n",
    "        AO_DF=pd.DataFrame(AO_ints,index=indice)\n",
    "        for ind,i in enumerate(range(nmo)):\n",
    "            for indx,j in enumerate(range(nmo)):\n",
    "                if j<=i and i!=j:\n",
    "                    AO_DF.loc[f'{j+1}_{i+1}']=AO_DF.loc[f'{i+1}_{j+1}']\n",
    "        AO_DF=AO_DF.sort_index()\n",
    "        AO_ints=AO_DF.values.reshape(nmo,nmo,nmo,nmo)    \n",
    "# Use molecular orbital coefficients from hdf5        \n",
    "        CMO=dict(zip(structs.astype(str),MO_VECTORS))[k].T\n",
    "#         CMO=pd.read_csv(f'CMO/{k}.GMJ_CMO.csv',header=None).values.reshape(nmo,nmo).T\n",
    "# Kill Brute force einsum is 100xs faster\n",
    "        MO=np.einsum(\"iqrs,ip->pqrs\",np.einsum(\"ijrs,jq->iqrs\",np.einsum(\"ijks,kr->ijrs\",np.einsum(\"ijkl,ls->ijks\",AO_ints,CMO),CMO),CMO),CMO)\n",
    "        # physicist notation\n",
    "        MO=MO.swapaxes(1, 2)\n",
    "#     return pd.DataFrame(MO.reshape(nmo**2,nmo**2),index=ad_ind,columns=ad_ind)\n",
    "    return MO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "froz=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('F')]\n",
    "inact=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('I')]\n",
    "act=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('A')]\n",
    "virt=[indx for indx,i in enumerate(Basis_Indices) if i.startswith('S')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_F=dict(zip(structs.astype(str),scf_F))\n",
    "gen_occ=dict(zip(structs.astype(str),scf_OCC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(scf_OCC[0]==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scf_OCC[0])-(scf_OCC[0]==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_set=sorted(set(sum([gen_pair_labels(typ) for typ in typ_exists],[])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occcc=len(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']!=0])\n",
    "virttt=len(MO_OCC_DF.T.describe().loc['mean'][MO_OCC_DF.T.describe().loc['mean']==0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class gen_two_ints(object):\n",
    "# Some of the D_{ij}^{ab}=f_{ii}+f_{jj}-f_{aa}-f_{bb}=e_{ii}+e_{jj}-e_{aa}-e_{bb} elements \n",
    "# will be 0 since ij and ab overlap for CASPT2\n",
    "# ij \\in {I,A}\n",
    "# ab \\in {A,V}\n",
    "# So ignore the warnings since they'll only be 0 when ijab \\in {A} only\n",
    "    import warnings\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    def get_MO(self, string):\n",
    "        return self.MO[self.slice_dict[string[0]], self.slice_dict[string[1]],self.slice_dict[string[2]], self.slice_dict[string[3]]]\n",
    "\n",
    "    def get_F(self, string):\n",
    "        return self.F[self.slice_dict[string[0]], self.slice_dict[string[1]]] \n",
    "    \n",
    "    def compute_pairmatrix(self,selft2start,selfdoublecheck):\n",
    "        test = 2*selft2start*selfdoublecheck\n",
    "        test -= np.swapaxes(selft2start,2,3)*selft2start\n",
    "        c=np.sum(test,axis=(2,3))\n",
    "        return c    \n",
    "    \n",
    "    def build_tau(self,t2,t1):\n",
    "        ttau = t2.copy()\n",
    "        tmp = np.einsum('ia,jb->ijab', t1, t1,optimize=True)\n",
    "        ttau += tmp\n",
    "        return ttau    \n",
    "    \n",
    "    def __init__(self):\n",
    "        nocc=occcc\n",
    "        nvirt=virttt\n",
    "#         nocc=(scf_OCC[0]==2).sum()\n",
    "#         nvirt=(len(scf_OCC[0])-(scf_OCC[0]==2).sum())\n",
    "        self.nfzc=len(froz)\n",
    "        self.nocc=nocc\n",
    "        self.nvirt=nvirt\n",
    "        self.nmo=nocc+nvirt\n",
    "#         all_nmo=act+virt\n",
    "        nmo=nocc+nvirt\n",
    "        self.slice_o = slice(0,nocc)\n",
    "        self.slice_v = slice(nocc,nocc+nvirt)\n",
    "        self.slice_a = slice(0,nmo)    \n",
    "\n",
    "        self.slice_dict = {\n",
    "            'o': self.slice_o,\n",
    "            'v': self.slice_v,\n",
    "            'a': self.slice_a\n",
    "        }\n",
    "        \n",
    "        featurelist=list()\n",
    "        def gen_feat(k):\n",
    "            \n",
    "            values=4\n",
    "            self.empty=np.zeros((nvirt,))\n",
    "            self.occupado=np.zeros((nocc,))\n",
    "            self.MO=gen_MO(k)\n",
    "            self.F=gen_F[k]\n",
    "            self.t1=np.zeros((nocc,nvirt))\n",
    "            \n",
    "            Focc = self.F[self.slice_o]\n",
    "            Fvir = self.F[self.slice_v]  \n",
    "            self.orbocc=Focc\n",
    "            self.orbvirt=Fvir\n",
    "\n",
    "            self.Dia = Focc.reshape(-1, 1) - Fvir\n",
    "            self.Dijab = Focc.reshape(-1, 1, 1, 1) + Focc.reshape(-1, 1, 1) - Fvir.reshape(-1, 1) - Fvir \n",
    "# Clean up AA block to get rid of infinities, we do not need this anyway              \n",
    "\n",
    "            self.t2start=self.MO[self.slice_o, self.slice_o, self.slice_v,self.slice_v] / self.Dijab\n",
    "            self.t2start[np.isinf(self.t2start)]=0\n",
    "        \n",
    "            self.triplecheck=2*self.t2start*self.get_MO('oovv')\n",
    "            self.triplecheck -=  np.swapaxes(self.get_MO('oovv'),2,3)*self.t2start \n",
    "            \n",
    "            \n",
    "            self.doublecheck = self.MO[self.slice_o, self.slice_o, self.slice_v, self.slice_v]   \n",
    "# Pair energy and pairs is not reasonable            \n",
    "            self.pairenergy=(np.zeros(self.doublecheck.shape)+self.compute_pairmatrix(self.t2start,self.doublecheck)[:,:,np.newaxis,np.newaxis])\n",
    "#             print(self.pairenergy,np.einsum('ijab->',self.pairenergy))\n",
    "            tmp_tau = self.build_tau(self.t2start,self.t1)\n",
    "            self.pairs=2*tmp_tau*self.get_MO('oovv')\n",
    "            self.pairs-= np.swapaxes(self.get_MO('oovv'),2,3)*tmp_tau\n",
    "            self.pairs = np.sum(self.pairs,axis=(2,3))\n",
    "            \n",
    "#             print(self.pairs,np.einsum('ij->',self.pairs))\n",
    "\n",
    "            \n",
    "            \n",
    "            test=np.zeros(self.t2start.shape)\n",
    "            self.diag=test\n",
    "            for i in range (0,self.nocc):\n",
    "                for j in range (0,self.nocc):\n",
    "                    np.fill_diagonal(self.diag[i,j,:,:],1)\n",
    "                    \n",
    "           #I think those features are not great, try <ii,aa>\n",
    "            temp=np.zeros((self.nocc,self.nvirt))\n",
    "            for i in range (0,self.nocc):\n",
    "                for j in range (0,self.nvirt):\n",
    "                    temp[i,j]=self.doublecheck[i,i,j,j]\n",
    "            test1=np.zeros((self.t2start.shape))\n",
    "            self.screen1=test1+temp[:,np.newaxis,:,np.newaxis]\n",
    "            self.screen2=test1+temp[np.newaxis,:,np.newaxis,:]\n",
    "# nfzc=# frozen core\n",
    "            val=self.nmo-self.nfzc\n",
    "            temp=np.zeros((val,val))        \n",
    "            for i in range (0,val):\n",
    "                for j in range (0,val):\n",
    "                    temp[i,j]=self.MO[i,i,j,j]\n",
    "            temp =temp[self.slice_v,self.slice_v]\n",
    "            self.screenvirt=test1+temp[np.newaxis,np.newaxis,:,:]\n",
    "\n",
    "            b=self.triplecheck\n",
    "            diag_indx=[]\n",
    "            off_diag_indx=[]      \n",
    "\n",
    "            for i in range(b.shape[0]):\n",
    "                for j in range (b.shape[1]):\n",
    "                    featurelist.clear()                    \n",
    "                    ind=np.argsort(b[i,j].flatten(),axis=0)\n",
    "                    new=np.sum(b[i,j])#0\n",
    "                    \n",
    "                    featurelist.append('Pair_Energy')\n",
    "                    new=np.hstack((new,self.MO[i,i,j,j]))\n",
    "                    \n",
    "                    featurelist.append('coulomb_ij')\n",
    "                    new=np.hstack((new,np.take_along_axis(self.screen1[i,j].flatten(), ind, axis=0)[:values]))#1,2,3,4\n",
    "                    \n",
    "                    featurelist.append('i_screen1')\n",
    "                    new=np.hstack((new,np.take_along_axis(self.screen2[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "                    \n",
    "                    featurelist.append('j_screen1')\n",
    "                    new=np.hstack((new,np.take_along_axis(self.screenvirt[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "                    \n",
    "                    featurelist.append('triplecheck1')                    \n",
    "                    new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values]))#17,18,19,20\n",
    "                    if i==j:\n",
    "#                         print(Basis_Indices[i],Basis_Indices[j])\n",
    "                        ind=np.argsort(b[i,j].flatten(),axis=0)\n",
    "                        \n",
    "# Eij:dim(1)            \n",
    "                        featurelist.append('MP2_Pair_Energy')\n",
    "                        new=np.sum(b[i,j])#0\n",
    "# <ii||jj>:dim(1)        \n",
    "                        new=np.hstack((new,self.MO[i,i,j,j]))\n",
    "                        featurelist.append('coulomb_ij')    \n",
    "# e_ij^ab:dim(4)                  \n",
    "                        featurelist.append('coulomb_ij')\n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen1[i,j].flatten(), ind, axis=0)[:values]))#1,2,3,4\n",
    "# <ij||ab>:dim(4)\n",
    "                        featurelist.append('i_screen1')\n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen2[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "# <ii||aa>:dim(4)                       \n",
    "                        featurelist.append('j_screen1')\n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen1[i,j].flatten(), ind, axis=0)[-values:]))#1,2,3,4\n",
    "# <jj||bb>:dim(4)                      \n",
    "                        featurelist.append('i_screen1')\n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen2[i,j].flatten(), ind, axis=0)[-values:]))#9,10,11,12\n",
    "# <aa||bb>:dim(4)                      \n",
    "                        featurelist.append('j_screen1')\n",
    "                        new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values]))#17,18,19,20\n",
    "# t2 matrix:dim(4)                      \n",
    "                        new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:]))#17,18,19,20\n",
    "# missing Eij:dim(1)                      \n",
    "                        one=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:])\n",
    "                        two=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values])\n",
    "                        new=np.hstack((new, np.sum(b[i,j])-one-two))\n",
    "                        featurelist.append('triplecheck1')\n",
    "\n",
    "\n",
    "                    else:\n",
    "#                         print(Basis_Indices[i],Basis_Indices[j])\n",
    "                        ind=np.argsort(b[i,j].flatten(),axis=0)\n",
    "# Eij:dim(1)                        \n",
    "                        new=np.sum(b[i,j])#0\n",
    "                        featurelist.append('Pair_Energy')\n",
    "# <ii||jj>:dim(1)        \n",
    "                        new=np.hstack((new,self.MO[i,i,j,j]))\n",
    "                        featurelist.append('coulomb_ij')\n",
    "# e_ij^ab:dim(4)                          \n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen1[i,j].flatten(), ind, axis=0)[:values]))#1,2,3,4\n",
    "                        featurelist.append('i_screen1')\n",
    "# <ij||ab>:dim(4)        \n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen2[i,j].flatten(), ind, axis=0)[:values]))#9,10,11,12\n",
    "                        featurelist.append('j_screen1')\n",
    "                        featurelist.append('triplecheck1')\n",
    "# <ii||aa>:dim(4)            \n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen1[i,j].flatten(), ind, axis=0)[-values:]))#1,2,3,4\n",
    "                        featurelist.append('i_screen1')\n",
    "# <jj||bb>:dim(4)                              \n",
    "                        new=np.hstack((new,np.take_along_axis(self.screen2[i,j].flatten(), ind, axis=0)[-values:]))#9,10,11,12\n",
    "                        featurelist.append('j_screen1')\n",
    "# <aa||bb>:dim(4)                        \n",
    "                        new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values]))#17,18,19,20\n",
    "# t2 matrix:dim(4)    \n",
    "                        new=np.hstack((new,np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:]))#17,18,19,20\n",
    "                        one=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[-values:])\n",
    "                        two=np.sum(np.take_along_axis(b[i,j].flatten(), ind, axis=0)[:values])\n",
    "# missing Eij:dim(1)            \n",
    "                        new=np.hstack((new, np.sum(b[i,j])-one-two))\n",
    "                        featurelist.append('triplecheck1')\n",
    "\n",
    "          \n",
    "                    if ((i==0) and (j==0)):\n",
    "                        diag_indx.append(Basis_Indices[i]+'_'+Basis_Indices[j])\n",
    "                        self.a=new.copy()\n",
    "                    elif ((i==0) and (j==1)):\n",
    "                        off_diag_indx.append(Basis_Indices[i]+'_'+Basis_Indices[j])\n",
    "                        self.g=new.copy()\n",
    "                    elif (i==j):\n",
    "                        diag_indx.append(Basis_Indices[i]+'_'+Basis_Indices[j])\n",
    "                        self.a=np.vstack((self.a,new))#41\n",
    "                    elif i!=j:  \n",
    "                        off_diag_indx.append(Basis_Indices[i]+'_'+Basis_Indices[j])        \n",
    "                        self.g=np.vstack((self.g,new))#41\n",
    "\n",
    "\n",
    "            \n",
    "            return pd.concat([pd.DataFrame(self.a,index=diag_indx),pd.DataFrame(self.g,index=off_diag_indx)]).loc[full_set]\n",
    "\n",
    "        \n",
    "        self.dict=dict([(k,gen_feat(k))for k in structs.astype(str)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elements(x):\n",
    "    '''\n",
    "    Takes an integer, x, and returns the number of off-diagonal elements of an upper triangular matrix\n",
    "    f(x)=(x*(x-1))/2\n",
    "    '''\n",
    "    return (x*(x-1))/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gen_two_el():\n",
    "# Eij:dim(1)                        \n",
    "# <ii||jj>:dim(1)        \n",
    "# e_ij^ab:dim(4)                          \n",
    "# <ij||ab>:dim(4)        \n",
    "# <ii||aa>:dim(4)            \n",
    "# <jj||bb>:dim(4)                              \n",
    "# <aa||bb>:dim(4)                        \n",
    "# t2 matrix:dim(4)    \n",
    "# missing Eij:dim(1)            \n",
    "    return gen_two_ints().dict\n",
    "\n",
    "\n",
    "def gen_one_diag_int():\n",
    "    keys=[] \n",
    "    featind=[]\n",
    "    h_qq=[]\n",
    "    h_ss=[]\n",
    "    for i in structs:\n",
    "        k=str(i)\n",
    "        keys.append(k)\n",
    "        ints=fxd_1ints[k]\n",
    "    # Epq Ers\n",
    "    # # e_q+e_s-e_p-e_r\n",
    "    # TIUV       \n",
    "    #'A'+g[0]+'_I'+g[1]+''+g[2]+''+g[3]\n",
    "    # Eti Euv (E01 E23)\n",
    "    # e_i+e_v-e_u-e_t\n",
    "    # e[0] + e[3] - e[1] - e[2]\n",
    "        for ind,g in enumerate(full_set):\n",
    "            featind.append(g)            \n",
    "            idx=g.split('_')\n",
    "            q=idx[0]\n",
    "            s=idx[1]\n",
    "            h_qq.append(ints.loc[str(q+'_'+q)])\n",
    "            h_ss.append(ints.loc[str(s+'_'+s)])            \n",
    "    return dict([(z,pd.DataFrame({'h_qq':np.array(h_qq).reshape(len(structs),-1)[idx],'h_ss':np.array(h_ss).reshape(len(structs),-1)[idx]},index=np.array(featind).reshape(len(structs),-1)[idx])) for idx,z in enumerate(keys)])                          \n",
    "\n",
    "def gen_one_off_diag_int():\n",
    "    keys=[] \n",
    "    featind=[]\n",
    "    h_qs=[]\n",
    "    for i in structs:\n",
    "        k=str(i)\n",
    "        keys.append(k)\n",
    "        ints=fxd_1ints[k]\n",
    "    # Epq Ers\n",
    "    # # e_q+e_s-e_p-e_r\n",
    "    # TIUV       \n",
    "    #'A'+g[0]+'_I'+g[1]+''+g[2]+''+g[3]\n",
    "    # Eti Euv (E01 E23)\n",
    "    # e_i+e_v-e_u-e_t\n",
    "    # e[0] + e[3] - e[1] - e[2]\n",
    "        for ind,g in enumerate(full_set):\n",
    "            featind.append(g)            \n",
    "            idx=g.split('_')\n",
    "            q=idx[0]\n",
    "            s=idx[1]\n",
    "            h_qs.append(ints.loc[str(q+'_'+s)]) \n",
    "                        \n",
    "    return dict([(z,pd.DataFrame({'h_qs':np.array(h_qs).reshape(len(structs),-1)[idx]},index=np.array(featind).reshape(len(structs),-1)[idx])) for idx,z in enumerate(keys)])                          \n",
    "\n",
    "def gen_bin():\n",
    "    # FSO=From same orbital\n",
    "    FSO=[]\n",
    "    # Indexing\n",
    "    featind=[]\n",
    "    # Keys=Structs in string format\n",
    "    keys=[]\n",
    "    for i in structs:\n",
    "        k=str(i)\n",
    "        keys.append(k)\n",
    "        for ind,g in enumerate(full_set):\n",
    "# Epq Ers\n",
    "# # e_q+e_s-e_p-e_r\n",
    "# TIUV\n",
    "#'A'+g[0]+'_I'+g[1]+''+g[2]+''+g[3]\n",
    "# Eti Euv (E01 E23)\n",
    "# e_i+e_v-e_u-e_t\n",
    "# e[0] + e[3] - e[1] - e[2]\n",
    "            featind.append(g)\n",
    "            idx=g.split('_')\n",
    "            q=idx[0]\n",
    "            s=idx[1]\n",
    "# Since I!=A just append 0 since they'll never both come from the same orbital                \n",
    "            if q==s:\n",
    "                FSO.append(1)\n",
    "            else:\n",
    "                FSO.append(0)\n",
    "    return dict([(z,pd.DataFrame({'From_Same_Orbital':np.array(FSO).reshape(len(structs),-1)[idx]},index=np.array(featind).reshape(len(structs),-1)[idx])) for idx,z in enumerate(keys)])               \n",
    "\n",
    "def gen_dbl_index():\n",
    "    MO_Fock_Mat_Q_Q=[]\n",
    "    MO_Fock_Mat_S_S=[]\n",
    "    MO_Fock_Mat_Q_S=[]\n",
    "    featind=[]\n",
    "    keys=[]\n",
    "    for i in structs:\n",
    "        k=str(i)\n",
    "        keys.append(k)\n",
    "        for ind,g in enumerate(full_set):\n",
    "# Epq Ers\n",
    "# # e_q+e_s-e_p-e_r\n",
    "# TIUV\n",
    "#'A'+g[0]+'_I'+g[1]+''+g[2]+''+g[3]\n",
    "# Eti Euv (E01 E23)\n",
    "# e_i+e_v-e_u-e_t\n",
    "# e[0] + e[3] - e[1] - e[2]\n",
    "            featind.append(g)\n",
    "            idx=g.split('_')\n",
    "            q=idx[0]\n",
    "            s=idx[1]\n",
    "            MO_Fock_Mat_Q_Q.append(labeled_fock_dict[k][q][q])            \n",
    "            MO_Fock_Mat_S_S.append(labeled_fock_dict[k][s][s])\n",
    "            MO_Fock_Mat_Q_S.append(labeled_fock_dict[k][q][s])\n",
    "    return dict([(z,pd.DataFrame({'MO_Fock_Mat_Q_Q':np.array(MO_Fock_Mat_Q_Q).reshape(len(structs),-1)[idx],'MO_Fock_Mat_S_S':np.array(MO_Fock_Mat_S_S).reshape(len(structs),-1)[idx],'MO_Fock_Mat_Q_S':np.array(MO_Fock_Mat_Q_S).reshape(len(structs),-1)[idx]},index=np.array(featind).reshape(len(structs),-1)[idx])) for idx,z in enumerate(keys)])                                       \n",
    "\n",
    "def gen_sif():\n",
    "    MO_Energy_Q=[]\n",
    "    MO_Energy_S=[]\n",
    "    MO_OCC_Q=[]\n",
    "    MO_OCC_S=[]\n",
    "    featind=[]\n",
    "    # Keys=Structs in string format\n",
    "    keys=[]\n",
    "    for i in structs:\n",
    "        k=str(i)\n",
    "        keys.append(k)\n",
    "        for ind,g in enumerate(full_set):\n",
    "# Epq Ers\n",
    "# # e_q+e_s-e_p-e_r\n",
    "# TIUV\n",
    "#'A'+g[0]+'_I'+g[1]+''+g[2]+''+g[3]\n",
    "# Eti Euv (E01 E23)\n",
    "# e_i+e_v-e_u-e_t\n",
    "# e[0] + e[3] - e[1] - e[2]\n",
    "            featind.append(g)\n",
    "            idx=g.split('_')\n",
    "            q=idx[0]\n",
    "            s=idx[1]\n",
    "            MO_Energy_Q.append(float(New_MO_Dict[k][q]))\n",
    "            MO_Energy_S.append(float(New_MO_Dict[k][s]))\n",
    "            MO_OCC_Q.append(float(MO_OCC_DF[k][q]))\n",
    "            MO_OCC_S.append(float(MO_OCC_DF[k][s]))\n",
    "            \n",
    "    return dict([(z,pd.DataFrame({'MO_Energy_Q':np.array(MO_Energy_Q).reshape(len(structs),-1)[idx],'MO_Energy_S':np.array(MO_Energy_S).reshape(len(structs),-1)[idx],'MO_OCC_Q':np.array(MO_OCC_Q).reshape(len(structs),-1)[idx],'MO_OCC_S':np.array(MO_OCC_S).reshape(len(structs),-1)[idx]},index=np.array(featind).reshape(len(structs),-1)[idx])) for idx,z in enumerate(keys)]) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# gen_names=['MP2_pair', 'MP2_Denom', \n",
    "#            'MP2_amp', 'MP2_amp_mag', 'MP2_amp_sign',\n",
    "#            'From_Same_Orbital', 'To_Same_Orbital', \n",
    "#            'Jia1', 'Jia2', 'Kia1', 'Kia2', \n",
    "#            'two_el',  \n",
    "#            'Jia1mag', 'Jia2mag', 'Kia1mag', 'Kia2mag', \n",
    "#            'Jpp', 'Jqq', 'Jrr', 'Jss', \n",
    "#            'Kpp', 'Kqq', 'Krr', 'Kss', \n",
    "#            'h_pp', 'h_qq', 'h_rr', 'h_ss', \n",
    "#            'h_qp', 'h_sr', 'h_qr', 'h_sp', \n",
    "#            'MO_Fock_Mat_P_P', 'MO_Fock_Mat_Q_Q', 'MO_Fock_Mat_S_S', 'MO_Fock_Mat_R_R', \n",
    "#            'MO_Fock_Mat_Q_P', 'MO_Fock_Mat_S_R', 'MO_Fock_Mat_Q_R', 'MO_Fock_Mat_S_P', \n",
    "#            'MO_Energy_P', 'MO_Energy_Q', 'MO_Energy_R', 'MO_Energy_S', \n",
    "#            'MO_OCC_P', 'MO_OCC_Q', 'MO_OCC_R', 'MO_OCC_S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keys.pickle', 'wb') as handle:\n",
    "    pickle.dump([str(i) for i in structs], handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# First Filter Step: Just the contributers\n",
    "# '''\n",
    "\n",
    "# # eq_dict=dict(zip(list([str(i) for i in np.arange(1,14,1)]),[i.split()[1] for i in (grep['-i','-A 14', 'Correlation energy /Case, /Symm, and sums:','/'.join((os.getcwd(),'120_dir/PT2_iron_oxo_120.output'))])().split('\\n')[1:-2]]))\n",
    "# eq_dict=dict(zip(list([str(i) for i in np.arange(1,14,1)]),[i.split()[1] for i in (grep['-i','-A 14', 'Correlation energy /Case, /Symm, and sums:','/'.join((os.getcwd(),f'eq_orbs.output'))])().split('\\n')[1:-2]]))\n",
    "\n",
    "# type_drop=[]\n",
    "# if float(eq_dict['1'])==0:\n",
    "#     type_drop.append('A')\n",
    "# if float(eq_dict['2'])+float(eq_dict['3'])==0:\n",
    "#     type_drop.append('B')    \n",
    "# if float(eq_dict['4'])==0:\n",
    "#     type_drop.append('C')    \n",
    "# if float(eq_dict['5'])==0:\n",
    "#     type_drop.append('D')    \n",
    "# if float(eq_dict['6'])+float(eq_dict['7'])==0:\n",
    "#     type_drop.append('E')    \n",
    "# if float(eq_dict['8'])+float(eq_dict['9'])==0:\n",
    "#     type_drop.append('F')    \n",
    "# if float(eq_dict['10'])+float(eq_dict['11'])==0:\n",
    "#     type_drop.append('G')    \n",
    "# if float(eq_dict['12'])+float(eq_dict['13'])==0:\n",
    "#     type_drop.append('H')    \n",
    "    \n",
    "# dummytyp=sorted([i for i in list(set([i.split('_')[0] for i in typ_exists])-set(type_drop))])\n",
    "\n",
    "# with open('type_drop.pickle', 'wb') as handle:\n",
    "#     pickle.dump(dummytyp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Big_Data_GS():\n",
    "    t0=time()\n",
    "    with open('feats.pickle', 'wb') as handle:\n",
    "        pickle.dump(pd.concat([pd.concat({k: v for k,v in gen_bin().items()},axis=0),pd.concat({k: v for k,v in gen_two_el().items()},axis=0),pd.concat({k: v for k,v in gen_one_diag_int().items()},axis=0),pd.concat({k: v for k,v in gen_one_off_diag_int().items()},axis=0),pd.concat({k: v for k,v in gen_dbl_index().items()},axis=0),pd.concat({k: v for k,v in gen_sif().items()},axis=0)],axis=1), handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    with open('targets.pickle', 'wb') as handle:\n",
    "        pickle.dump(stacked_pairs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(time()-t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_Data_GS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_pickle(f'typH_feats.pickle'),\n",
    "# pd.read_pickle(f'typH_targets.pickle').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
