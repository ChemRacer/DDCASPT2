{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data generation\n",
    "import sys\n",
    "# !{sys.executable} -m pip install matplotlib --upgrade\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#random\n",
    "from time import perf_counter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score,root_mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=np.DeprecationWarning) \n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2e8569-2d81-4deb-b91c-324e49b2d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.path.expanduser('~'),'DDCASPT2/drop.txt'),'r') as d:\n",
    "    dropfeat = [i.replace('\\n','') for i in d.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('test_ind.pickle', 'rb') as handle:\n",
    "#     test_ind = pickle.load(handle)\n",
    "\n",
    "# with open('train_ind.pickle', 'rb') as handle:\n",
    "#     train_ind = pickle.load(handle)\n",
    "    \n",
    "# print(len(train_ind),len(test_ind))    \n",
    "# train_ind,test_ind = train_test_split(train_ind+test_ind, test_size=0.3, random_state=42)\n",
    "\n",
    "radius_range_dirs = []\n",
    "for i in glob('cluster/*.*'):\n",
    "    try:\n",
    "        radstr = float(os.path.basename(i))\n",
    "        # if radstr>=1.4:\n",
    "        radius_range_dirs.append(os.path.basename(i))\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "radius_range = sorted(radius_range_dirs)\n",
    "\n",
    "train_ind,test_ind=radius_range[0::2],radius_range[1::2]\n",
    "\n",
    "train_ind = list(map(float,train_ind))\n",
    "test_ind = list(map(float,test_ind))\n",
    "train_ind, test_ind = train_test_split(train_ind+test_ind, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2069ad6-33fb-453f-82bb-b2f314c24d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_ind),len(test_ind))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7c2d2-72fb-4e1e-b2d1-b99a8e65139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {'h$_{qq}^{0}$':'h$_{q}$',\n",
    "'$(F_{q})_{0}$':'$F_{q}$',\n",
    "'$(F_{q}^{\\\\text{SCF}})_{0}$':'$F_{q}^{\\\\text{SCF}}$',\n",
    "'$(\\\\eta_{q})_{0}$':'$\\\\eta_{q}$',\n",
    "'$(\\\\omega_{q})_{0}$':'$\\\\omega_{q}$',\n",
    "'$(\\\\eta_{s})_{0}$':'$\\\\eta_{s}$',\n",
    "'h$_{ss}^{0}$':'h$_{s}$',\n",
    "'$(F_{s}^{\\\\text{SCF}})_{0}$':'$F_{s}^{\\\\text{SCF}}$',\n",
    "'$(F_{s})_{0}$':'$F_{s}$',\n",
    "'$(\\\\omega_{s})_{0}$':'$\\\\omega_{s}$',\n",
    "'$(\\\\langle ss \\\\vert ss \\\\rangle)_{0}$':\"$\\\\langle ss \\\\vert ss \\\\rangle$\",\n",
    "'$(\\\\langle qq \\\\vert qq \\\\rangle)_{0}$':\"$\\langle qq \\\\vert qq \\\\rangle$\",\n",
    "'h$_{pp}^{0}$': 'h$_{p}^{0}$',\n",
    "'h$_{pp}^{1}$': 'h$_{p}^{1}$',\n",
    "'h$_{pp}^{2}$': 'h$_{p}^{2}$',\n",
    "'h$_{pp}^{3}$': 'h$_{p}^{3}$',\n",
    "'h$_{rr}^{0}$': 'h$_{r}^{0}$',\n",
    "'h$_{rr}^{1}$': 'h$_{r}^{1}$',\n",
    "'h$_{rr}^{2}$': 'h$_{r}^{2}$',\n",
    "'h$_{rr}^{3}$': 'h$_{r}^{3}$'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe9a7f2-d48e-478f-816f-45f962b200c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "\n",
    "\n",
    "\n",
    "recover_train = []\n",
    "recover_test = []\n",
    "\n",
    "traincnt = 0\n",
    "testcnt = 0\n",
    "\n",
    "check_pairs = []\n",
    "for k in train_ind:\n",
    "    rad = f\"{k:.2f}\"\n",
    "    traindf = pd.read_csv(os.path.join('cluster',rad,f'{rad}.csv'),compression='zip',index_col=0).drop(columns=dropfeat).rename(columns=rename)\n",
    "    # traindf = traindf.loc[[i for i in traindf.index if i.split('_')[0]!=i.split('_')[1]]]\n",
    "    # traindf = traindf[traindf['Pair_Energies'].abs()>=1e-6]\n",
    "    check_pairs.append(traindf.reset_index()[['index','Pair_Energies']])\n",
    "    train.append(traindf)\n",
    "    recover_train.append((rad,traincnt,len(traindf)))\n",
    "    traincnt+=1\n",
    "        \n",
    "for l in test_ind:\n",
    "    rad = f\"{l:.2f}\"\n",
    "    testdf = pd.read_csv(os.path.join('cluster',rad,f'{rad}.csv'),compression='zip',index_col=0).drop(columns=dropfeat).rename(columns=rename)\n",
    "    # testdf = testdf.loc[[i for i in testdf.index if i.split('_')[0]!=i.split('_')[1]]]\n",
    "    # testdf = testdf[testdf['Pair_Energies'].abs()>=1e-6]\n",
    "    check_pairs.append(testdf.reset_index()[['index','Pair_Energies']])\n",
    "    test.append(testdf)                    \n",
    "    recover_test.append((rad,testcnt,len(testdf)))\n",
    "    testcnt+=1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda40cf8-7688-4812-8f71-9beb67868943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34c7015-dc46-4bed-9293-795692fb5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# torch.tensor(, dtype=torch.float32).to(device)\n",
    "\n",
    "\n",
    "X_train = np.array([i.drop(columns='Pair_Energies').values for i in train])\n",
    "X_test = np.array([i.drop(columns='Pair_Energies').values for i in test])\n",
    "\n",
    "y_train = np.array([i['Pair_Energies'].values for i in train])\n",
    "y_test = np.array([i['Pair_Energies'].values for i in test])\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc6169-e410-4a40-8843-002324b5a2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# # Standardize features and target\n",
    "# scaler_X = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "\n",
    "# X_train = scaler_X.fit_transform(X_train)\n",
    "# X_test = scaler_X.transform(X_test)\n",
    "\n",
    "# y_train = scaler_y.fit_transform(y_train.reshape(-1,1))\n",
    "# y_test = scaler_y.transform(y_test.reshape(-1,1))\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53b635e-4884-4484-86f8-dbfd9a793816",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor.shape,y_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407a85e-7da5-4916-92e4-33fe8b5bed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(y_train_tensor,axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c05d9-a027-4620-8433-25dff97a0ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the regression model\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(102, 102 * 2),  # Input layer to first hidden layer\n",
    "            nn.ReLU(),               # Activation function\n",
    "            nn.Linear(102 * 2, 102 * 2),  # Hidden layers\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(102 * 2, 102 * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(102 * 2, 102 * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(102 * 2, 102 * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(102 * 2, 102 * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(102 * 2, 102),  # Hidden to output layer\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(102, 1)        # Output layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = RegressionModel().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# Create DataLoader for training\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Train the model with mini-batches\n",
    "num_epochs = 5000\n",
    "losslist = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Move data to the appropriate device\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X).reshape(*batch_y.shape)\n",
    "        # loss = criterion(torch.sum(outputs, axis=1), torch.sum(batch_y, axis=1))\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Accumulate loss for the current batch\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate average loss for the epoch and store it\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    losslist.append(epoch_loss)\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d8184-334b-42aa-87e1-c7c35cf767e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(losslist))\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f953d-151e-4d73-afa6-76b5b36139c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred_test = model(X_test_tensor)\n",
    "    y_pred_train = model(X_train_tensor)\n",
    "\n",
    "# De-standardize the predictions for interpretability\n",
    "# y_pred_test = scaler_y.inverse_transform(y_pred.cpu().numpy())\n",
    "# y_test_original = scaler_y.inverse_transform(y_test_tensor.cpu().numpy())\n",
    "\n",
    "y_pred_test = y_pred_test.cpu().numpy().flatten()\n",
    "y_test_original = y_test_tensor.cpu().numpy().flatten()\n",
    "\n",
    "y_pred_train = y_pred_train.cpu().numpy().flatten()\n",
    "y_train_original = y_train_tensor.cpu().numpy().flatten()\n",
    "\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(y_test_original, y_pred_test, label=f\"Test R2={r2_score(y_test_original, y_pred_test):.4f}\")\n",
    "plt.scatter(y_train_original, y_pred_train, label=f\"Train R2={r2_score(y_train_original, y_pred_train):.4f}\")\n",
    "plt.legend()\n",
    "plt.title(\"Regression Model Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3780131f-fc5d-4e70-a1b0-aec6cceeeaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tss = np.sum((y_train-np.mean(y_train))**2)*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef6682a-22ce-4847-ae86-9fe357ebb9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tss = np.sum((y_test-np.mean(y_test))**2)*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d4abf2-6c37-40b3-9218-93595178e4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.flatten()\n",
    "y_pred_train = y_pred_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "y_pred_test = y_pred_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd07ebb4-4040-46d7-be04-c8d6524d95ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_train =np.array([(i, 1 - (i / train_tss)) for i in np.linspace(train_tss,0,100)])\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,sharey=True,figsize=(10,5))\n",
    "ax1.plot(*example_train.T)\n",
    "ax1.scatter(np.sum((y_train-y_pred_train)**2)*1e3,r2_score(y_train,y_pred_train),color='red',label=f\"RSS={np.sum((y_train-y_pred_train)**2)*1e3:.4f}\"+\" mE$_{h}$\\n\"+f\"TSS={np.sum((y_train-np.mean(y_train))**2)*1e3:.4f}\"+\" mE$_{h}$\\n\"+\"R$^{2}$=\"+f\"{r2_score(y_train,y_pred_train):.4f}\")\n",
    "ax1.set_xlabel('Residual Sum of Squares (mE$_{h}$)')\n",
    "ax1.set_ylabel('R$^{2}$')\n",
    "ax1.set_ylim(0,1)\n",
    "ax1.set_xlim(0,train_tss)\n",
    "ax1.legend()\n",
    "\n",
    "example_test =np.array([(i, 1 - (i / test_tss)) for i in np.linspace(test_tss,0,100)])\n",
    "ax2.plot(*example_test.T)\n",
    "ax2.scatter(np.sum((y_test-y_pred_test)**2)*1e3,r2_score(y_test,y_pred_test),color='red',label=f\"RSS={np.sum((y_test-y_pred_test)**2)*1e3:.4f}\"+\" mE$_{h}$\\n\"+f\"TSS={np.sum((y_test-np.mean(y_test))**2)*1e3:.4f}\"+\" mE$_{h}$\\n\"+\"R$^{2}$=\"+f\"{r2_score(y_test,y_pred_test):.4f}\")\n",
    "ax2.set_xlabel('Residual Sum of Squares (mE$_{h}$)')\n",
    "ax2.set_ylabel('R$^{2}$')\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_xlim(0,test_tss)\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/RSS_vs_R2_original.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bfbe7-26b3-4e59-9967-492a9267e947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pal = sns.color_palette(\"Paired\")\n",
    "font=12\n",
    "plt.rc('font', size=font)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=font)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=font)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=font)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=font)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=font)    # legend fontsize\n",
    "plt.rc('figure', titlesize=font)  # fontsize of the figure title\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(13,6))\n",
    "scale=1e-1\n",
    "ax1.set_title('Train')\n",
    "ax1.scatter(1e3*y_train,1e3*y_pred_train,label=\"R$^{2}$=\"+f'{r2_score(y_train,y_pred_train):.4f}\\nMAE={1e3*mean_absolute_error(y_train,y_pred_train):.4f}'+\" mE$_{h}$\",color=pal[8],edgecolors='k')\n",
    "ax1.plot(np.arange(-1e3,1e3),np.arange(-1e3,1e3),'k-')\n",
    "LMIN,LMAX = -19, 10\n",
    "ax1.set_xlim(LMIN,LMAX)\n",
    "ax1.set_ylim(LMIN,LMAX)\n",
    "ax1.set_xlabel('Calculated Pair-Energies (mE$_{h}$)')\n",
    "ax1.set_ylabel('Predicted Pair-Energies (mE$_{h}$)')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.set_title('Test')\n",
    "ax2.scatter(1e3*y_test,1e3*y_pred_test,label=\"R$^{2}$=\"+f'{r2_score(y_test,y_pred_test):.4f}\\nMAE={1e3*mean_absolute_error(y_test,y_pred_test):.4f}'+\" mE$_{h}$\",color=pal[9],edgecolors='k')\n",
    "ax2.plot(np.arange(-1e3,1e3),np.arange(-1e3,1e3),'k-')\n",
    "ax2.set_xlim(LMIN,LMAX)\n",
    "ax2.set_ylim(LMIN,LMAX)\n",
    "ax2.set_xlabel('Calculated Pair-Energies (mE$_{h}$)')\n",
    "ax2.set_ylabel('Predicted Pair-Energies (mE$_{h}$)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/iron_VDZP_parity.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce5ef9-9a21-47d1-9f6d-a8748046f438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testcntrcvr = 0\n",
    "recover_test_list = []\n",
    "recover_test_E2 = []\n",
    "for j,k,l in recover_test:\n",
    "    init_test = testcntrcvr\n",
    "    testcntrcvr+=l\n",
    "    recover_test_list.append((j,y_test[init_test:testcntrcvr],y_pred_test[init_test:testcntrcvr]))\n",
    "    recover_test_E2.append((j,np.sum(y_test[init_test:testcntrcvr]),np.sum(y_pred_test[init_test:testcntrcvr])))\n",
    "\n",
    "\n",
    "traincntrcvr = 0\n",
    "recover_train_list = []\n",
    "recover_train_E2 = []\n",
    "for j,k,l in recover_train:\n",
    "    init_train = traincntrcvr\n",
    "    traincntrcvr+=l\n",
    "    recover_train_list.append((j,y_train[init_train:traincntrcvr],y_pred_train[init_train:traincntrcvr]))\n",
    "    recover_train_E2.append((j,np.sum(y_train[init_train:traincntrcvr]),np.sum(y_pred_train[init_train:traincntrcvr])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b352604-8315-4330-86ad-4e6d8d285f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincorrE2 = pd.DataFrame(recover_train_E2).rename(columns={0:'Radius ($\\AA$)',1:'E$_{2}^{\\text{Calculated}}$',2:'E$_{2}^{\\text{Predicted}}$'}).set_index('Radius ($\\AA$)')\n",
    "#.astype({\"basis set\":str,'Radius ($\\AA$)':float,'E$_{2}^{\\text{Calculated}}$':float,'E$_{2}^{\\text{Predicted}}$':float})\n",
    "testcorrE2 = pd.DataFrame(recover_test_E2).rename(columns={0:'Radius ($\\AA$)',1:'E$_{2}^{\\text{Calculated}}$',2:'E$_{2}^{\\text{Predicted}}$'}).set_index('Radius ($\\AA$)')\n",
    "#.astype({\"basis set\":str,'Radius ($\\AA$)':float,'E$_{2}^{\\text{Calculated}}$':float,'E$_{2}^{\\text{Predicted}}$':float})\n",
    "\n",
    "\n",
    "\n",
    "traincorrE2['CASPT2_E']=np.zeros(len(traincorrE2))\n",
    "traincorrE2['CASSCF_E']=np.zeros(len(traincorrE2))\n",
    "traincorrE2['E2']=np.zeros(len(traincorrE2))\n",
    "\n",
    "\n",
    "\n",
    "for i in traincorrE2.index:\n",
    "    energy_df = pd.read_excel(f\"cluster/{i}/{i}_energies.xlsx\",index_col=0)\n",
    "    traincorrE2.loc[i,'CASPT2_E']=energy_df.loc['CASPT2_E'].values\n",
    "    traincorrE2.loc[i,'CASSCF_E']=energy_df.loc['CASSCF_E'].values\n",
    "    # traincorrE2.loc[i,'E2']=energy_df.loc['E2'].values\n",
    "\n",
    "traincorrE2['E$_{\\text{CASPT2}}^{\\text{Predicted}}$'] = traincorrE2['CASSCF_E']+traincorrE2['E$_{2}^{\\text{Predicted}}$']\n",
    "\n",
    "traincorrE2.rename(columns = {'CASPT2_E':'E$_{\\text{CASPT2}}^{\\text{Calculated}}$','CASSCF_E':'E$_{\\text{CASSCF}}^{\\text{Calculated}}$'},inplace=True)\n",
    "\n",
    "\n",
    "testcorrE2['CASPT2_E']=np.zeros(len(testcorrE2))\n",
    "testcorrE2['CASSCF_E']=np.zeros(len(testcorrE2))\n",
    "testcorrE2['E2']=np.zeros(len(testcorrE2))\n",
    "\n",
    "\n",
    "\n",
    "for i in testcorrE2.index:\n",
    "    energy_df = pd.read_excel(f\"cluster/{i}/{i}_energies.xlsx\",index_col=0)\n",
    "    testcorrE2.loc[i,'CASPT2_E']=energy_df.loc['CASPT2_E'].values\n",
    "    testcorrE2.loc[i,'CASSCF_E']=energy_df.loc['CASSCF_E'].values\n",
    "    # testcorrE2.loc[i,'E2']=energy_df.loc['E2'].values\n",
    "\n",
    "testcorrE2['E$_{\\text{CASPT2}}^{\\text{Predicted}}$'] = testcorrE2['CASSCF_E']+testcorrE2['E$_{2}^{\\text{Predicted}}$']\n",
    "\n",
    "testcorrE2.rename(columns = {'CASPT2_E':'E$_{\\text{CASPT2}}^{\\text{Calculated}}$','CASSCF_E':'E$_{\\text{CASSCF}}^{\\text{Calculated}}$'},inplace=True)\n",
    "\n",
    "testcorrE2.reset_index(inplace=True)\n",
    "traincorrE2.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06745306-816e-4b0b-a6d0-ba96e0cd4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincaspt2melt = traincorrE2.reset_index().melt(id_vars=['Radius ($\\AA$)'], value_vars=['E$_{\\text{CASPT2}}^{\\text{Calculated}}$','E$_{\\text{CASPT2}}^{\\text{Predicted}}$']).astype({'Radius ($\\AA$)':float,'value':float})\n",
    "testcaspt2melt = testcorrE2.reset_index().melt(id_vars=['Radius ($\\AA$)'], value_vars=['E$_{\\text{CASPT2}}^{\\text{Calculated}}$','E$_{\\text{CASPT2}}^{\\text{Predicted}}$']).astype({'Radius ($\\AA$)':float,'value':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0f9a3-19c9-455a-8b75-02213e0e85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trueE2=pd.concat([traincorrE2.reset_index(),testcorrE2.reset_index()]).astype({'Radius ($\\AA$)':float,'E$_{\\text{CASPT2}}^{\\text{Calculated}}$':float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a8187-a49c-44b1-b092-895461e782ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcorrE2['E$_{\\text{CASPT2}}^{\\text{Calculated}}$'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a310dd6a-3aff-4b3a-bd1b-2efa9c7f7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(testcorrE2['E$_{\\text{CASPT2}}^{\\text{Calculated}}$'],testcorrE2['E$_{\\text{CASPT2}}^{\\text{Predicted}}$'])*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8a0b3-d4cb-4637-8f19-e7a8b8e5e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(traincorrE2['E$_{\\text{CASPT2}}^{\\text{Calculated}}$'],traincorrE2['E$_{\\text{CASPT2}}^{\\text{Predicted}}$'])*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairedcp=sns.color_palette('Paired')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be78c734-d439-4ac6-96a0-08c4530fa9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(traincorrE2['E$_{2}^{\\text{Calculated}}$'],traincorrE2['E$_{2}^{\\text{Predicted}}$'])*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664770e8-0b05-4e07-a248-0a247c56e1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(testcorrE2['E$_{2}^{\\text{Calculated}}$'],testcorrE2['E$_{2}^{\\text{Predicted}}$'])*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c2180a-751e-4f7c-9cae-ce74a37663d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb25471-ac94-447c-b01e-ea5c27e2166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincorrerr = {}\n",
    "\n",
    "fig,((ax1,ax2),(ax3,ax4))=plt.subplots(2,2,figsize=(10,10),sharey=False)\n",
    "\n",
    "\n",
    "\n",
    "pred_train,true_train = traincorrE2['E$_{2}^{\\text{Predicted}}$'],traincorrE2['E$_{2}^{\\text{Calculated}}$']\n",
    "pred_test,true_test = testcorrE2['E$_{2}^{\\text{Predicted}}$'],testcorrE2['E$_{2}^{\\text{Calculated}}$']\n",
    "testrad = testcorrE2['Radius ($\\AA$)']    \n",
    "train_r2_corr = r2_score(true_train,pred_train)\n",
    "test_r2_corr = r2_score(true_test,pred_test)\n",
    "test_mae_corr = 1e3*mean_absolute_error(true_test,pred_test)\n",
    "train_mae_corr = 1e3*mean_absolute_error(true_train,pred_train)\n",
    "print(pred_train.min(),true_train.min())\n",
    "print(pred_train.max(),true_train.max())\n",
    "traincorrerr = {\"r2_train\":train_r2_corr,\"r2_test\":test_r2_corr,\"mae_train\":train_mae_corr,\"mae_test\":test_mae_corr}\n",
    "trainrad = traincorrE2['Radius ($\\AA$)']\n",
    "ax1.scatter(true_train,pred_train,label='R$^{2}$='+f'{train_r2_corr:.4f}\\nMAE={train_mae_corr:.2e}'+\" mE$_{h}$\",color=pairedcp[8],edgecolors='k')\n",
    "\n",
    "ax1.set_xlabel('Calculated CASPT2 Correlation Energy (E$_{h}$)')\n",
    "ax1.set_ylabel('Predicted CASPT2 Correlation Energy (E$_{h}$)')\n",
    "ax1.set_title('Train')\n",
    "ax1.plot(np.arange(-1000,1000),np.arange(-1000,1000),'k')\n",
    "ax1.legend(loc=4)\n",
    "\n",
    "\n",
    "ax2.scatter(true_test,pred_test,label='R$^{2}$='+f'{test_r2_corr:.4f}\\nMAE={test_mae_corr:.2e}'+\" mE$_{h}$\",color=pairedcp[9],edgecolors='k')\n",
    "# ax2.plot(true_test,true_test,'k')\n",
    "ax2.plot(np.arange(-1000,1000),np.arange(-1000,1000),'k')\n",
    "ax2.set_xlabel('Calculated CASPT2 Correlation Energy (E$_{h}$)')\n",
    "ax2.set_ylabel('Predicted CASPT2 Correlation Energy (E$_{h}$)')\n",
    "ax2.set_title('Test')    \n",
    "ax2.legend(loc=4)\n",
    "\n",
    "bottom, top = -0.44, -0.36\n",
    "ax1.set_xlim(bottom, top)\n",
    "ax1.set_ylim(bottom, top)\n",
    "ax2.set_xlim(bottom, top)\n",
    "ax2.set_ylim(bottom, top)\n",
    "ax1.set_xticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])\n",
    "ax1.set_yticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])    \n",
    "ax2.set_xticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])    \n",
    "ax2.set_yticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])    \n",
    "\n",
    "pred_train,true_train = traincorrE2['E$_{\\text{CASPT2}}^{\\text{Predicted}}$'],traincorrE2['E$_{\\text{CASPT2}}^{\\text{Calculated}}$']\n",
    "pred_test,true_test = testcorrE2['E$_{\\text{CASPT2}}^{\\text{Predicted}}$'],testcorrE2['E$_{\\text{CASPT2}}^{\\text{Calculated}}$']\n",
    "testrad = testcorrE2['Radius ($\\AA$)']    \n",
    "\n",
    "print(pred_train.min(),true_train.min())\n",
    "print(pred_train.max(),true_train.max())\n",
    "traincorrerr = {\"r2_train\":train_r2_corr,\"r2_test\":test_r2_corr,\"mae_train\":train_mae_corr,\"mae_test\":test_mae_corr}\n",
    "trainrad = traincorrE2['Radius ($\\AA$)']\n",
    "ax3.scatter(np.array(trainrad,dtype=float),pred_train,color=pairedcp[8],edgecolors='k')\n",
    "ax3.plot(trueE2.sort_values(by='Radius ($\\AA$)')['Radius ($\\AA$)'],trueE2.sort_values(by='Radius ($\\AA$)')['E$_{\\text{CASPT2}}^{\\text{Calculated}}$'],'k')\n",
    "ax3.set_xlabel('Radius ($\\AA$)')\n",
    "ax3.set_ylabel('CASPT2 Energy (E$_{h}$)')\n",
    "ax3.set_title('Train')\n",
    "# ax3.legend()\n",
    "\n",
    "ax4.scatter(np.array(testrad,dtype=float),pred_test,color=pairedcp[9],edgecolors='k')\n",
    "ax4.plot(trueE2.sort_values(by='Radius ($\\AA$)')['Radius ($\\AA$)'],trueE2.sort_values(by='Radius ($\\AA$)')['E$_{\\text{CASPT2}}^{\\text{Calculated}}$'],'k')\n",
    "ax4.set_xlabel('Radius ($\\AA$)')\n",
    "ax4.set_ylabel('CASPT2 Energy (E$_{h}$)')\n",
    "ax4.set_title('Test') \n",
    "# ax4.legend()\n",
    "\n",
    "minpt2, maxpt2= pd.concat([true_train,true_test]).min(), pd.concat([true_train,true_test]).max()\n",
    "pct=0.01\n",
    "bufferbot, buffertop = minpt2*pct, maxpt2*pct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bottom, top = -1345.9, -1345.8\n",
    "ax3.set_ylim(bottom,top)\n",
    "ax3.set_yticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)]) \n",
    "ax4.set_ylim(bottom,top)\n",
    "ax4.set_yticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)]) \n",
    "\n",
    "fig.suptitle(\"Fe(IV)O$^{2+}$ ANO-RCC-VDZP\")\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'images/iron_VDZPCASPT2.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227676e3-3584-48ec-8957-afbb757d23ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpairdf = pd.DataFrame(recover_train_list)\n",
    "testpairdf = pd.DataFrame(recover_test_list)\n",
    "pairerr={}\n",
    "\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "\n",
    "truetrainpair, predtrainpair = np.hstack(trainpairdf[1]),np.hstack(trainpairdf[2])\n",
    "train_r2_pair = r2_score(truetrainpair, predtrainpair)\n",
    "train_mae_pair = 1e3*mean_absolute_error(truetrainpair, predtrainpair)\n",
    "ax1.scatter(truetrainpair, predtrainpair,label='R$^{2}$='+f'{train_r2_pair:.4f}\\nMAE={train_mae_pair:.2e}'+\" mE$_{h}$\",color=pairedcp[8],edgecolors='k')\n",
    "ax1.plot(np.arange(-1000,1000),np.arange(-1000,1000),'k')\n",
    "ax1.set_xlabel('Calculated E$_2$ Energy (E$_{h}$)')\n",
    "ax1.set_ylabel('Predicted E$_2$ Energy (E$_{h}$)')\n",
    "ax1.set_title('Train')    \n",
    "ax1.legend()  \n",
    "\n",
    "truetestpair, predtestpair = np.hstack(testpairdf[1]),np.hstack(testpairdf[2])\n",
    "test_r2_pair = r2_score(truetestpair, predtestpair)\n",
    "test_mae_pair = 1e3*mean_absolute_error(truetestpair, predtestpair)\n",
    "ax2.scatter(truetestpair, predtestpair,label='R$^{2}$='+f'{test_r2_pair:.4f}\\nMAE={test_mae_pair:.2e}'+\" mE$_{h}$\",color=pairedcp[9],edgecolors='k')\n",
    "ax2.plot(np.arange(-1000,1000),np.arange(-1000,1000),'k')\n",
    "ax2.set_xlabel('Calculated E$_2$ Energy (E$_{h}$)')\n",
    "ax2.set_ylabel('Predicted E$_2$ Energy (E$_{h}$)')\n",
    "ax2.set_title('Test')    \n",
    "ax2.legend()    \n",
    "\n",
    "mincorr, maxcorr= np.hstack([truetrainpair,truetestpair]).min(), np.hstack([truetrainpair,truetestpair]).max()\n",
    "pct=0.50\n",
    "bufferbot, buffertop = mincorr*pct, maxcorr*pct\n",
    "\n",
    "# if 'H' in n:\n",
    "bottom, top = mincorr-buffertop, maxcorr+buffertop\n",
    "\n",
    "# else:\n",
    "#     bottom, top = mincorr+-0.1, maxcorr+0.05\n",
    "\n",
    "ax1.set_xlim(bottom,top)\n",
    "ax1.set_xticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])\n",
    "ax1.set_ylim(bottom,top)\n",
    "ax1.set_yticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])    \n",
    "ax2.set_xlim(bottom,top)\n",
    "ax2.set_xticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])    \n",
    "ax2.set_ylim(bottom,top)\n",
    "ax2.set_yticks(np.linspace(bottom,top,4),[f\"{i:.2f}\" for i in np.linspace(bottom,top,4)])    \n",
    "\n",
    "fig.suptitle(\"Fe(IV)O$^{2+}$ ANO-RCC-VDZP\")\n",
    "plt.tight_layout()\n",
    "#plt.savefig(f'images/iron_VDZPE2.png',dpi=300,bbox_inches='tight')    \n",
    "plt.show()\n",
    "pairerr = {\"r2_train\":train_r2_pair,\"r2_test\":test_r2_pair,\"mae_train\":train_mae_pair,\"mae_test\":test_mae_pair}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee64171f-35c7-4fc0-a9ca-f977f7fcfbaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea4ae21-3a0d-4cb6-8b77-05c89208b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stackeddata ={'Pair-Energies':{'Train':mean_absolute_error(truetrainpair, predtrainpair)*1e3,'Test':mean_absolute_error(truetestpair, predtestpair)*1e3},\n",
    "\"Correlation Energies\":{'Train':mean_absolute_error(true_train,pred_train)*1e3,'Test':mean_absolute_error(pred_test,true_test)*1e3}}\n",
    "#pd.DataFrame(stackeddata).to_excel(\"MAE_stacked.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b4937d-64cd-4048-ace5-4f68c4c52f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0963d6fb-f03a-426d-aced-aea34654790d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
