{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687a23f-96ba-4c36-9a86-3dbdf206b6da",
   "metadata": {
    "papermill": {
     "duration": 6.7925,
     "end_time": "2022-12-06T08:38:53.905684",
     "exception": false,
     "start_time": "2022-12-06T08:38:47.113184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sys\n",
    "import sys\n",
    "# !{sys.executable} --version\n",
    "\n",
    "# !{sys.executable} -m pip uninstall -y torch torchvision torchaudio\n",
    "# !mamba uninstall --yes --prefix {sys.prefix} pytorch torchvision torchaudio cudatoolkit=11.3\n",
    "# !mamba uninstall --yes --prefix {sys.prefix} dgl dgl-cuda11.3\n",
    "\n",
    "\n",
    "# !mamba install --yes --prefix {sys.prefix} logzero\n",
    "# !conda uninstall --yes pytorch torchvision torchaudio\n",
    "# !mamba install --yes --prefix {sys.prefix} -c rapidsai-nightly -c nvidia -c numba -c conda-forge cudf cudatoolkit\n",
    "\n",
    "\n",
    "# !{sys.executable} -m pip install imag\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import scipy as sp\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Loading bar\n",
    "from tqdm import trange\n",
    "\n",
    "# Logger\n",
    "from logzero import logger\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "\n",
    "from itertools import permutations, combinations,combinations_with_replacement\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#random\n",
    "from time import perf_counter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbea94d0",
   "metadata": {
    "papermill": {
     "duration": 0.240882,
     "end_time": "2022-12-06T08:38:54.184907",
     "exception": false,
     "start_time": "2022-12-06T08:38:53.944025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ecc3e4-7268-420f-82c9-2147c8ca2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_path = \"../hydrogen_comps/minimal_2e_2o/chains/even/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbd106-494c-439c-b064-0c37e71476bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(H_path,'test_ind.pickle'), 'rb') as handle:\n",
    "    test_ind = pickle.load(handle)\n",
    "\n",
    "with open(os.path.join(H_path,'train_ind.pickle'), 'rb') as handle:\n",
    "    train_ind = pickle.load(handle)\n",
    "    \n",
    "print(len(train_ind),len(test_ind))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63b2a1-9469-44c7-b40c-93a0d4c3bcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name=['From_Same_Orbital', 'pair_energy', 'coulomb', 'screen1_1', 'screen1_2',\n",
    "       'screen1_3', 'screen1_4', 'screen2_1', 'screen2_2', 'screen2_3',\n",
    "       'screen2_4', 'eijab_1', 'eijab_2', 'eijab_3', 'eijab_4', 'screenvirt_1',\n",
    "       'screenvirt_2', 'screenvirt_3', 'screenvirt_4', 'Fr1', 'Fr2', 'Fr3',\n",
    "       'Fr4', 'Fs1', 'Fs2', 'Fs3', 'Fs4', 'occr1', 'occr2', 'occr3', 'occr4',\n",
    "       'occs1', 'occs2', 'occs3', 'occs4', 'SCFFr1', 'SCFFr2', 'SCFFr3',\n",
    "       'SCFFr4', 'SCFFs1', 'SCFFs2', 'SCFFs3', 'SCFFs4', 'SCFOCCr1',\n",
    "       'SCFOCCr2', 'SCFOCCr3', 'SCFOCCr4', 'SCFOCCs1', 'SCFOCCs2', 'SCFOCCs3',\n",
    "       'SCFOCCs4', 'hrr1', 'hrr2', 'hrr3', 'hrr4', 'hss1', 'hss2', 'hss3',\n",
    "       'hss4', 'hpp', 'hqq', 'Fp', 'Fq', 'occp', 'occq', 'SCFFp', 'SCFFq',\n",
    "       'SCFOCCp', 'SCFOCCq']\n",
    "\n",
    "# feat_name=['occs3',\n",
    "#  'SCFOCCs2',\n",
    "#  'SCFOCCs1',\n",
    "#  'screen2_1',\n",
    "#  'SCFOCCp',\n",
    "#  'hss4',\n",
    "#  'hrr1',\n",
    "#  'Fs2',\n",
    "#  'occq',\n",
    "#  'screenvirt_4',\n",
    "#  'SCFFs2',\n",
    "#  'hrr3',\n",
    "#  'SCFFr1',\n",
    "#  'screenvirt_2',\n",
    "#  'screenvirt_3',\n",
    "#  'SCFFs4',\n",
    "#  'hss2',\n",
    "#  'screen1_2',\n",
    "#  'hrr4',\n",
    "#  'screen1_3',\n",
    "#  'Fp',\n",
    "#  'Fr1',\n",
    "#  'screenvirt_1',\n",
    "#  'occs4',\n",
    "#  'screen2_4',\n",
    "#  'SCFFr2',\n",
    "#  'eijab_2',\n",
    "#  'screen2_3',\n",
    "#  'SCFFs1',\n",
    "#  'eijab_4',\n",
    "#  'Fq',\n",
    "#  'hss1',\n",
    "#  'SCFFr4',\n",
    "#  'occs2',\n",
    "#  'occp',\n",
    "#  'screen1_4',\n",
    "#  'eijab_1',\n",
    "#  'hpp',\n",
    "#  'pair_energy',\n",
    "#  'hrr2',\n",
    "#  'hqq',\n",
    "#  'SCFFr3',\n",
    "#  'occs1',\n",
    "#  'Fr2',\n",
    "#  'eijab_3',\n",
    "#  'SCFOCCq',\n",
    "#  'SCFOCCs4',\n",
    "#  'Fs3',\n",
    "#  'Fs1',\n",
    "#  'From_Same_Orbital',\n",
    "#  'hss3',\n",
    "#  'Fs4',\n",
    "#  'SCFOCCs3',\n",
    "#  'Fr4',\n",
    "#  'screen2_2',\n",
    "#  'screen1_1',\n",
    "#  'Fr3',\n",
    "#  'SCFFs3']\n",
    "\n",
    "feat_name=['SCFFs3',\n",
    " 'hrr3',\n",
    " 'screen1_1',\n",
    " 'SCFOCCs2',\n",
    " 'hpp',\n",
    " 'SCFOCCs3',\n",
    " 'hss4',\n",
    " 'screen2_2',\n",
    " 'SCFOCCq',\n",
    " 'hss1',\n",
    " 'screenvirt_3',\n",
    " 'SCFFs4',\n",
    " 'SCFFr4',\n",
    " 'SCFOCCs1',\n",
    " 'SCFFr3',\n",
    " 'hss2',\n",
    " 'screen2_4',\n",
    " 'screenvirt_2',\n",
    " 'SCFFs2',\n",
    " 'hss3',\n",
    " 'hqq',\n",
    " 'hrr4',\n",
    " 'hrr1',\n",
    " 'screen1_3',\n",
    " 'SCFOCCs4',\n",
    " 'SCFFr1',\n",
    " 'SCFFs1',\n",
    " 'hrr2',\n",
    " 'SCFFr2',\n",
    " 'screen1_4',\n",
    " 'screen2_1',\n",
    " 'screenvirt_1',\n",
    " 'screen1_2',\n",
    " 'SCFOCCp',\n",
    " 'screen2_3',\n",
    " 'screenvirt_4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90e3500-05c5-4dd9-a52d-334394cace61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279fcd9-dce7-4079-9083-0e9122bc6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=[]\n",
    "train_y = []\n",
    "\n",
    "test_X=[]\n",
    "test_y = []\n",
    "# for nam in sorted(glob('*/fixed_feats.pickle'),key=lambda x: int(x.split('_')[0].strip('H')))[2:]:\n",
    "for nam in glob(os.path.join(H_path,'*/fixed_feats.pickle')):\n",
    "    trydf=pd.read_pickle(nam).astype(float)[feat_name]    \n",
    "    Hnam=os.path.basename(os.path.dirname(nam)).split('_')[0]\n",
    "    for i in train_ind:\n",
    "        # try:\n",
    "        #     print(\"TOP\",Hnam,i)\n",
    "        #     print(trydf.loc[f'{Hnam}_chain/{Hnam}_{i:.2f}'].values.shape)\n",
    "        #     train_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{i:.2f}'].values)\n",
    "        # except:\n",
    "        #     print(\"Bottom\",Hnam,i)\n",
    "        #     print(trydf.loc[f'{Hnam}_chain/{Hnam}_{i:.2f}/'].values.shape)\n",
    "        train_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{i:.2f}/'].values)\n",
    "    for j in test_ind: \n",
    "        # try:\n",
    "        #     test_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{j:.2f}'].values)\n",
    "        # except:\n",
    "        test_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{j:.2f}/'].values)\n",
    "    \n",
    "# This recover is wrong... did not account for the # of pair-energies     \n",
    "recover_train=[]    \n",
    "recover_test=[]    \n",
    "tst_idx=0\n",
    "tr_idx=0\n",
    "for nidx,nam in enumerate(glob(os.path.join(H_path,'*/fixed_targets.pickle'))):\n",
    "    trydf=pd.read_pickle(nam).astype(float)\n",
    "    Hnam=os.path.basename(os.path.dirname(nam)).split('_')[0]\n",
    "    for tridx,i in enumerate(train_ind):\n",
    "        pairdf=trydf[f'{i:.2f}'].values\n",
    "        train_y.append(pairdf)\n",
    "        for k in range(len(pairdf)):\n",
    "            recover_train.append((nam.split('_')[0],tridx,tr_idx))\n",
    "            tr_idx+=1\n",
    "        \n",
    "    for teidx,j in enumerate(test_ind): \n",
    "        pairdf=trydf[f'{j:.2f}'].values\n",
    "        test_y.append(pairdf)        \n",
    "        \n",
    "        for k in range(len(pairdf)):\n",
    "            recover_test.append((nam.split('_')[0],teidx,tst_idx))\n",
    "            tst_idx+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5704494f-5ee9-49c3-93c6-01bab4634ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test=np.vstack(train_X).astype(float),np.vstack(test_X).astype(float)\n",
    "y_train,y_test=np.hstack(train_y).astype(float),np.hstack(test_y).astype(float)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)\n",
    "for u,v in np.argwhere(np.isnan(X_train)):\n",
    "    X_train[u,v]=0\n",
    "    \n",
    "for u,v in np.argwhere(np.isnan(X_test)):\n",
    "    X_test[u,v]=0   \n",
    "\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce55f0-9986-4b35-9260-f423d679292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom Dataset\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.X = torch.from_numpy(features).float()\n",
    "        self.y = torch.from_numpy(targets).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff50c0e4-5299-4e42-9507-ae1012606902",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "if device.type == 'cuda':\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f'Device {i}')\n",
    "            print(torch.cuda.get_device_name(i))\n",
    "            print('Memory Usage:')\n",
    "            print('Allocated:', round(torch.cuda.memory_allocated(i)/1024**3,1), 'GB')\n",
    "            print('Cached:   ', round(torch.cuda.memory_reserved(i)/1024**3,1), 'GB')\n",
    "    else:\n",
    "        print(torch.cuda.get_device_name(0))\n",
    "        print('Memory Usage:')\n",
    "        print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "        print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26888b02-88df-447b-bdd4-7d6a7a6c4daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[0] // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a982472-9d5e-462e-bcb4-5d1a5d6551bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "796 // 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b94588-bcf4-48de-84b9-740e57d06042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 32 * 24\n",
    "train_dataset = RegressionDataset(X_train, y_train)\n",
    "test_dataset = RegressionDataset(X_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41496596-f829-41c9-9cb1-aa6644812fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self,featdim,depth=10):\n",
    "        super().__init__()\n",
    "        self.inputlayer = torch.nn.Linear(featdim, featdim)\n",
    "        self.middlelayer =  self.middlelayers = nn.ModuleList([nn.Linear(featdim, featdim) for _ in range(depth)])\n",
    "        self.outlayer = torch.nn.Linear(featdim, 1)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.inputlayer(x))\n",
    "        for layer in self.middlelayers:\n",
    "            x = F.relu(layer(x))\n",
    "        return self.outlayer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e80eb8-b37d-45aa-b829-5864fdb674ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(y_train),np.max(y_train),np.mean(y_train),np.median(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f840c67-5dfe-4a72-92dc-e75a62fda3ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Model(len(feat_name)).to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.L1Loss() #nn.MSELoss()\n",
    "learning_rate = 1e-6\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate,weight_decay=1e-3)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "epochs = 1000\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "# for epoch in tqdm(range(epochs)):\n",
    "for epoch in range(epochs):    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "    # for batch_X, batch_y in tqdm(train_loader, desc=\"Train\"):\n",
    "        optimizer.zero_grad()\n",
    "        batch_X=batch_X.to(device)\n",
    "        batch_y=batch_y.to(device)\n",
    "        outputs = model(batch_X).flatten()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        # print(outputs.shape, batch_y.shape)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()/batch_X.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss #/ len(train_loader.dataset)\n",
    "    train_losses.append(epoch_loss)\n",
    "    \n",
    "    # Evaluation on test set\n",
    "    model.eval()\n",
    "    test_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in test_loader:\n",
    "        # for batch_X, batch_y in tqdm(test_loader, desc=\"Test\"):\n",
    "            batch_X=batch_X.to(device)\n",
    "            batch_y=batch_y.to(device)            \n",
    "            outputs = model(batch_X).flatten()\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            test_running_loss += loss.item()/batch_X.size(0)\n",
    "    test_epoch_loss = test_running_loss #/ len(test_loader.dataset)\n",
    "    test_losses.append(test_epoch_loss)\n",
    "    \n",
    "    if (epoch+1) % 100 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {epoch_loss:.4e} - Test Loss: {test_epoch_loss:.4e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X=batch_X.to(device)\n",
    "        batch_y=batch_y.to(device)\n",
    "        outputs = model(batch_X).flatten()\n",
    "        predictions.extend(outputs.squeeze().tolist())\n",
    "        actuals.extend(batch_y.squeeze().tolist())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e7651-de66-4cf8-9f5e-801ab0f9db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(actuals, predictions)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "print(f\"\\nTest MSE: {mse:.4e}\")\n",
    "print(f\"Test MAE: {mae:.4e}\")\n",
    "print(f\"Test R$^2$: {r2:.4f}\")\n",
    "plt.scatter(actuals, predictions)\n",
    "plt.plot(actuals,actuals)\n",
    "plt.hlines(np.median(y_train),np.min(y_train),np.max(y_train),color='r')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae333b-7d26-4de3-9546-7642c472275f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555eb20-c2f9-4c0e-8b57-3264076065db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =experimental(featdim)\n",
    "# if 'lustre' in os.getcwd():\n",
    "#     model.load_state_dict(torch.load('/lustre/isaac/proj/UTK0022/GMJ/DDGNN/learningcurves/learningcurves/PairNetGCFF/save_model/PairNet_GC_0.75_0.25_cc-pdvz_GDBmix.pth'))\n",
    "# else:\n",
    "#     model.load_state_dict(torch.load('/home/grierjones/DDGNN/BigModel/PairNetGCFF/save_model/PairNet_GC_0.80_0.20_cc-pdvz_GDBmix.pth'))\n",
    "\n",
    "#     # model.load_state_dict(torch.load('/home/grierjones/DDGNN/learningcurves/learningcurves/PairNetGCFF/save_model/PairNet_GC_0.75_0.25_cc-pdvz_GDBmix.pth'))\n",
    "\n",
    "# num_feats=model.layers[-1].in_features\n",
    "# model.layers[-1]=torch.nn.Linear(num_feats,1,bias=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "DDGNN",
   "language": "python",
   "name": "ddgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22892.416332,
   "end_time": "2022-12-06T15:00:17.229050",
   "environment_variables": {},
   "exception": null,
   "input_path": "GCN_gridGDBdataloader.ipynb",
   "output_path": "GCN_gridGDBdataloader.ipynb",
   "parameters": {},
   "start_time": "2022-12-06T08:38:44.812718",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
