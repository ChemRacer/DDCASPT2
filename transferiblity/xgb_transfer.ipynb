{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For data generation\n",
    "import sys\n",
    "# cupy-cuda12x\n",
    "# !{sys.executable} -m  pip install shap numba --force-reinstall\n",
    "# !{sys.executable} -m  pip install seaborn matplotlib tqdm\n",
    "#-m  pip install --upgrade  shap mendeleev scikit-learn scipy numpy joblib  --force-reinstall\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "# import cupy as cp\n",
    "from glob import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "#random\n",
    "from time import perf_counter\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics import r2_score,root_mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Plotting\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "import warnings\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "# from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eddb425-cc6d-4b4f-a328-71191aef6626",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_name=['From_Same_Orbital', 'pair_energy', 'coulomb', 'screen1_1', 'screen1_2',\n",
    "       'screen1_3', 'screen1_4', 'screen2_1', 'screen2_2', 'screen2_3',\n",
    "       'screen2_4', 'eijab_1', 'eijab_2', 'eijab_3', 'eijab_4', 'screenvirt_1',\n",
    "       'screenvirt_2', 'screenvirt_3', 'screenvirt_4', 'Fr1', 'Fr2', 'Fr3',\n",
    "       'Fr4', 'Fs1', 'Fs2', 'Fs3', 'Fs4', 'occr1', 'occr2', 'occr3', 'occr4',\n",
    "       'occs1', 'occs2', 'occs3', 'occs4', 'SCFFr1', 'SCFFr2', 'SCFFr3',\n",
    "       'SCFFr4', 'SCFFs1', 'SCFFs2', 'SCFFs3', 'SCFFs4', 'SCFOCCr1',\n",
    "       'SCFOCCr2', 'SCFOCCr3', 'SCFOCCr4', 'SCFOCCs1', 'SCFOCCs2', 'SCFOCCs3',\n",
    "       'SCFOCCs4', 'hrr1', 'hrr2', 'hrr3', 'hrr4', 'hss1', 'hss2', 'hss3',\n",
    "       'hss4', 'hpp', 'hqq', 'Fp', 'Fq', 'occp', 'occq', 'SCFFp', 'SCFFq',\n",
    "       'SCFOCCp', 'SCFOCCq']\n",
    "\n",
    "\n",
    "\n",
    "# feat_name=['screen1_1', 'screen1_2', 'screen1_3', 'screen1_4', 'screen2_1',\n",
    "#            'screen2_2', 'screen2_3', 'screen2_4', 'eijab_1', 'eijab_2','eijab_3', 'screenvirt_1', 'screenvirt_2', 'screenvirt_3',\n",
    "#            'screenvirt_4', 'Fr1', 'Fr2', 'Fr3', 'Fr4', 'Fs1', 'Fs2', 'Fs3',\n",
    "#            'Fs4', 'SCFFr2', 'SCFFs1', 'SCFFs2', 'SCFFs3', 'SCFFs4', 'hrr1',\n",
    "#            'hrr2', 'hrr3', 'hrr4', 'hss1', 'hss2', 'hss3', 'hss4', 'hpp',\n",
    "#            'Fp', 'Fq', 'occq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd90b09-d2d7-43e7-a53b-dec428304888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(os.path.join(path,'test_ind.pickle'), 'rb') as handle:\n",
    "        test_ind = pickle.load(handle)\n",
    "    \n",
    "    with open(os.path.join(path,'train_ind.pickle'), 'rb') as handle:\n",
    "        train_ind = pickle.load(handle)\n",
    "        \n",
    "    print(len(train_ind),len(test_ind))    \n",
    "    \n",
    "    train_X=[]\n",
    "    train_y = []\n",
    "    \n",
    "    test_X=[]\n",
    "    test_y = []\n",
    "    # for nam in sorted(glob('*/fixed_feats.pickle'),key=lambda x: int(x.split('_')[0].strip('H')))[2:]:\n",
    "    for nam in glob(os.path.join(path,'*/fixed_feats.pickle')):\n",
    "        trydf=pd.read_pickle(nam).astype(float)[feat_name]    \n",
    "        Hnam=os.path.basename(os.path.dirname(nam)).split('_')[0]\n",
    "        for i in train_ind:\n",
    "            train_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{i:.2f}/'].values)\n",
    "        for j in test_ind: \n",
    "            test_X.append(trydf.loc[f'{Hnam}_chain/{Hnam}_{j:.2f}/'].values)\n",
    "        \n",
    "    recover_train=[]    \n",
    "    recover_test=[]    \n",
    "    tst_idx=0\n",
    "    tr_idx=0\n",
    "    for nidx,nam in enumerate(glob(os.path.join(path,'*/fixed_targets.pickle'))):\n",
    "        trydf=pd.read_pickle(nam).astype(float)\n",
    "        Hnam=os.path.basename(os.path.dirname(nam)).split('_')[0]\n",
    "        for tridx,i in enumerate(train_ind):\n",
    "            pairdf=trydf[f'{i:.2f}'].values\n",
    "            train_y.append(pairdf)\n",
    "            for k in range(len(pairdf)):\n",
    "                recover_train.append((Hnam,tridx,tr_idx))\n",
    "                tr_idx+=1\n",
    "            \n",
    "        for teidx,j in enumerate(test_ind): \n",
    "            pairdf=trydf[f'{j:.2f}'].values\n",
    "            test_y.append(pairdf)        \n",
    "            \n",
    "            for k in range(len(pairdf)):\n",
    "                recover_test.append((Hnam,teidx,tst_idx))\n",
    "                tst_idx+=1\n",
    "                \n",
    "    X_train, X_test=np.vstack(train_X).astype(float),np.vstack(test_X).astype(float)\n",
    "    y_train,y_test=np.hstack(train_y).astype(float),np.hstack(test_y).astype(float)\n",
    "    print(X_train.shape,X_test.shape)\n",
    "    print(y_train.shape,y_test.shape)\n",
    "    for u,v in np.argwhere(np.isnan(X_train)):\n",
    "        X_train[u,v]=0\n",
    "        \n",
    "    for u,v in np.argwhere(np.isnan(X_test)):\n",
    "        X_test[u,v]=0    \n",
    "    \n",
    "    for u,v in np.argwhere(np.isinf(X_train)):\n",
    "        X_train[u,v]=0\n",
    "        \n",
    "    for u,v in np.argwhere(np.isinf(X_test)):\n",
    "        X_test[u,v]=0         \n",
    "\n",
    "    scaler=MinMaxScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test, recover_train, recover_test, train_ind, test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fd72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_path = \"../hydrogen_comps/minimal_2e_2o/chains/even/\"\n",
    "\n",
    "X_train, X_test, y_train, y_test, recover_train, recover_test, train_ind, test_ind = load_data(H_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33b6610-2a11-4ac4-9c8d-4c7df2e7510c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# model=XGBRegressor(reg_lambda=0.3,max_depth=100,min_child_weight=5)\n",
    "model=XGBRegressor(max_depth=100,min_child_weight=1,n_estimators=100, reg_alpha=0.001, reg_lambda=0.001,n_jobs=-1)\n",
    "model.fit(X_train,y_train)\n",
    "y_pred_train=model.predict(X_train)\n",
    "y_pred_test=model.predict(X_test)\n",
    "print(f\"R2: {r2_score(y_train,y_pred_train):.4f},{r2_score(y_test,y_pred_test):.4f}\")\n",
    "print(f\"RMSE (mEh): {root_mean_squared_error(y_train,y_pred_train)*1e3:.4f},{root_mean_squared_error(y_test,y_pred_test)*1e3:.4f}\")\n",
    "\n",
    "# params = {'max_depth': [1, 10, 100],\n",
    "# #           'n_estimators': [100, 500, 1000],\n",
    "#           'reg_lambda': [1e-6, 1e-3,1e-1],\n",
    "#           'reg_alpha': [1e-6, 1e-3,1e-1]}\n",
    "\n",
    "# model = XGBRegressor()\n",
    "# grid = GridSearchCV(estimator=model, \n",
    "#                    param_grid=params,\n",
    "#                    scoring='r2', \n",
    "#                    verbose=1000,n_jobs=12).fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# gmodel=grid.best_estimator_\n",
    "# y_pred_train=gmodel.predict(X_train)\n",
    "# y_pred_test=gmodel.predict(X_test)\n",
    "# print(f\"R2: {r2_score(y_train,y_pred_train):.4f},{r2_score(y_test,y_pred_test):.4f}\")\n",
    "# print(f\"RMSE (mEh): {root_mean_squared_error(y_train,y_pred_train)*1e3:.4f},{root_mean_squared_error(y_test,y_pred_test)*1e3:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503fb4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(\"reduced_hmodel.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0e934-e076-4404-a806-4dbb6c6de4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bfbe7-26b3-4e59-9967-492a9267e947",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "font=12\n",
    "plt.rc('font', size=font)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=font)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=font)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=font)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=font)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=font)    # legend fontsize\n",
    "plt.rc('figure', titlesize=font)  # fontsize of the figure title\n",
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(13,6))\n",
    "scale=1e-1\n",
    "ax1.set_title('Train')\n",
    "ax1.scatter(1e3*y_train,1e3*y_pred_train,label=\"R$^{2}$=\"+f'{r2_score(y_train,y_pred_train):.2f}\\nMAE={1e3*mean_absolute_error(y_train,y_pred_train):.4f}'+\" mE$_{h}$\")\n",
    "ax1.plot(1e3*y_train,1e3*y_train,'k-')\n",
    "ax1.set_xlim(1e3*min(y_train)-scale,1e3*max(y_train)+scale)\n",
    "ax1.set_ylim(1e3*min(y_train)-scale,1e3*max(y_train)+scale)\n",
    "ax1.set_xlabel('Calculated Pair-Energies (mE$_{h}$)')\n",
    "ax1.set_ylabel('Predicted Pair-Energies (mE$_{h}$)')\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "ax2.set_title('Test')\n",
    "ax2.scatter(1e3*y_test,1e3*y_pred_test,label=\"R$^{2}$=\"+f'{r2_score(y_test,y_pred_test):.2f}\\nMAE={1e3*mean_absolute_error(y_test,y_pred_test):.4f}'+\" mE$_{h}$\",color='orange')\n",
    "ax2.plot(1e3*y_test,1e3*y_test,'k-')\n",
    "ax2.set_xlim(1e3*min(y_test)-scale,1e3*max(y_test)+scale)\n",
    "ax2.set_ylim(1e3*min(y_test)-scale,1e3*max(y_test)+scale)\n",
    "ax2.set_xlabel('Calculated Pair-Energies (mE$_{h}$)')\n",
    "ax2.set_ylabel('Predicted Pair-Energies (mE$_{h}$)')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/reduced_H2n_parity.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507573f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdct={}\n",
    "for n in np.arange(2,14,2):\n",
    "    index=np.array(recover_test)[np.array(recover_test)[:,0]==f'H{n}'][:,2].astype(int)\n",
    "    testdct[f'H{n}']=np.vstack([y_test[index],y_pred_test[index]])\n",
    "    \n",
    "test_errors={}    \n",
    "for k,v in sorted(testdct.items(),key=lambda x: int(x[0].strip('H'))):\n",
    "    test_errors[k]=1e3*mean_absolute_error(v[0],v[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad4b4c-12eb-44b5-98c1-65552232e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindct={}\n",
    "for n in np.arange(2,14,2):\n",
    "    index=np.array(recover_train)[np.array(recover_train)[:,0]==f'H{n}'][:,2].astype(int)\n",
    "    traindct[f'H{n}']=np.vstack([y_train[index],y_pred_train[index]])\n",
    "    \n",
    "train_errors={}    \n",
    "for k,v in sorted(traindct.items(),key=lambda x: int(x[0].strip('H'))):\n",
    "    train_errors[k]=1e3*mean_absolute_error(v[0],v[1])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf=pd.DataFrame.from_dict(test_errors,orient='index').rename(columns={0:'test'})\n",
    "traindf=pd.DataFrame.from_dict(train_errors,orient='index').rename(columns={0:'train'})\n",
    "errormelt=pd.concat([traindf,testdf],axis=1).reset_index().melt(id_vars='index')\n",
    "errormelt['index']=[i.split('_')[0] for i in errormelt['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10a548a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CASSCF=pd.concat([pd.read_csv(i,index_col=1).drop(columns=['Unnamed: 0']).rename(columns={'energy':os.path.basename(os.path.dirname(i)).split('_')[0]}) for i in glob(os.path.join(H_path,'*/CASSCF.csv'))],axis=1)\n",
    "CASPT2=pd.concat([pd.read_csv(i,index_col=1).drop(columns=['Unnamed: 0']).rename(columns={'energy':os.path.basename(os.path.dirname(i)).split('_')[0]}) for i in glob(os.path.join(H_path,'*/CASPT2.csv'))],axis=1)\n",
    "E2=pd.concat([pd.read_csv(i,index_col=1).drop(columns=['Unnamed: 0']).rename(columns={'energy':os.path.basename(os.path.dirname(i)).split('_')[0]}) for i in glob(os.path.join(H_path,'*/E2.csv'))],axis=1)    \n",
    "\n",
    "CASSCF.index=[f'{i:.2f}' for i in CASSCF.index]\n",
    "CASPT2.index=[f'{i:.2f}' for i in CASPT2.index]\n",
    "E2.index=[f'{i:.2f}' for i in E2.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f81fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairedcp=sns.color_palette('Paired',len(E2.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,5),sharey=False)\n",
    "# for idx,(k,v) in enumerate(testdct.items()):\n",
    "#     sns.histplot(np.hstack([v[0],traindct[k][0]]),label=k,color=pairedcp[idx],kde=True,stat='probability',ax=ax1)\n",
    "\n",
    "#     # sns.histplot(np.hstack([np.hstack([v[0],traindct[k][0]]) for idx,(k,v) in enumerate(testdct.items())]),label='all',color=pairedcp[idx],kde=True,stat='probability',ax=ax1)\n",
    "# ax1.set_xlim(-1.2e-2,3e-3)\n",
    "# ax1.set_xticks(np.linspace(-1.2e-2,3e-3,5))\n",
    "# ax1.set_xticklabels([f'{i:.2e}' for i in np.linspace(-1.2e-2,3e-3,5)])\n",
    "# ax1.legend(loc=2)\n",
    "# ax1.set_xlabel('Pair-Energies')\n",
    "\n",
    "# sns.histplot(data=E2[sorted(E2.columns,key=lambda x: int(x.strip('H')))].melt(),x='value',hue='variable',kde=True,stat='probability',palette=sns.color_palette('Paired'), multiple=\"stack\",ax=ax2)\n",
    "\n",
    "# ax2.set_xlabel('Correlation Energies')\n",
    "# plt.tight_layout()\n",
    "# ##plt.savefig('images/reduced_dist.png',dpi=300,bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09541b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "traincorrdict={}\n",
    "for n in np.arange(2,14,2):\n",
    "    dat=np.array(recover_train)[np.array(recover_train)[:,0]==f'H{n}']\n",
    "    corrdf=[]\n",
    "    for idr,r in enumerate(train_ind):\n",
    "        chunked=dat[dat[:,1].astype(int)==idr]\n",
    "        index=chunked[:,2].astype(int)\n",
    "        dfcorr=pd.DataFrame([y_train[index].sum(),y_pred_train[index].sum()],index=['train','pred'])\n",
    "        corrdf.append(dfcorr)\n",
    "    \n",
    "    df=pd.concat(corrdf,axis=1).T\n",
    "    df.index=[f'{i:.2f}' for i in train_ind]\n",
    "    traincorrdict[f'H{n}']=df\n",
    "    \n",
    "traincorr_err={}\n",
    "for k,v in traincorrdict.items():\n",
    "    traincorr_err[k]=1e3*mean_absolute_error(v['train'],v['pred'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51455dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcorrdict={}\n",
    "for n in np.arange(2,14,2):\n",
    "    dat=np.array(recover_test)[np.array(recover_test)[:,0]==f'H{n}']\n",
    "    corrdf=[]\n",
    "    for idr,r in enumerate(test_ind):\n",
    "        chunked=dat[dat[:,1].astype(int)==idr]\n",
    "        index=chunked[:,2].astype(int)\n",
    "        dfcorr=pd.DataFrame([y_test[index].sum(),y_pred_test[index].sum()],index=['test','pred'])\n",
    "        corrdf.append(dfcorr)\n",
    "    \n",
    "    df=pd.concat(corrdf,axis=1).T\n",
    "    df.index=[f'{i:.2f}' for i in test_ind]\n",
    "    testcorrdict[f'H{n}']=df\n",
    "    \n",
    "testcorr_err={}\n",
    "for k,v in testcorrdict.items():\n",
    "    testcorr_err[k]=1e3*mean_absolute_error(v['test'],v['pred'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_CASPT2=pd.DataFrame.from_dict({k:CASSCF[k].loc[v['pred'].index]+v['pred'] for k,v in testcorrdict.items()},orient='index').T\n",
    "train_CASPT2=pd.DataFrame.from_dict({k:CASSCF[k].loc[v['pred'].index]+v['pred'] for k,v in traincorrdict.items()},orient='index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b0ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairedcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95f08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in test_CASPT2.columns:\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "    train,test=traincorrdict[n],testcorrdict[n]\n",
    "    true_train,pred_train=train['train'],train['pred']\n",
    "    true_test,pred_test=test['test'],test['pred']\n",
    "    \n",
    "    ax1.scatter(train.index.astype(float),pred_train*1e3,label='R$^{2}$='+f'{r2_score(true_train,pred_train):.4f}\\nMAE={1e3*mean_absolute_error(true_train,pred_train):.2e}'+\" mE$_{h}$\",color=pairedcp[4])\n",
    "    ax1.plot(E2[n].index.astype(float),E2[n]*1e3,'k')\n",
    "    ax1.set_xlabel('Radius (Å)')\n",
    "    ax1.set_ylabel('Correlation Energy (mE$_{h}$)')\n",
    "    ax1.set_title('Train')\n",
    "    ax1.legend()\n",
    "    \n",
    "    ax2.scatter(test.index.astype(float),pred_test*1e3,label='R$^{2}$='+f'{r2_score(true_test,pred_test):.4f}\\nMAE={1e3*mean_absolute_error(true_test,pred_test):.2e}'+\" mE$_{h}$\",color=pairedcp[5])\n",
    "    ax2.plot(E2[n].index.astype(float),E2[n]*1e3,'k')\n",
    "    ax2.set_xlabel('Radius (Å)')\n",
    "    ax2.set_title('Test')\n",
    "    ax2.legend()\n",
    "    \n",
    "    fig.suptitle(n)\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0,wspace=0)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'images/reduced_{n}_E2.png',dpi=300,bbox_inches='tight')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee3ff99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in test_CASPT2.columns:\n",
    "    fig,((ax1,ax2),(ax3,ax4))=plt.subplots(2,2,figsize=(10,10),sharey=True)\n",
    "    pt2=CASPT2[n]\n",
    "    true_train,pred_train=pt2.loc[train_CASPT2.index],train_CASPT2[n]\n",
    "    true_test,pred_test=pt2.loc[test_CASPT2.index],test_CASPT2[n]\n",
    "    ax1.scatter(true_train,pred_train,label='R$^{2}$='+f'{r2_score(true_train,pred_train):.4f}\\nMAE={1e3*mean_absolute_error(true_train,pred_train):.2e}'+\" mE$_{h}$\",color=pairedcp[4])\n",
    "    ax1.plot(true_train,true_train,'k')\n",
    "    ax1.set_xlabel('Calculated CASPT2 Energy (E$_{h}$)')\n",
    "    ax1.set_ylabel('Predicted CASPT2 Energy (E$_{h}$)')\n",
    "    ax1.set_title('Train')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.scatter(true_test,pred_test,label='R$^{2}$='+f'{r2_score(true_test,pred_test):.4f}\\nMAE={1e3*mean_absolute_error(true_test,pred_test):.2e}'+\" mE$_{h}$\",color=pairedcp[5])\n",
    "    ax2.plot(true_test,true_test,'k')\n",
    "    ax2.set_xlabel('Calculated CASPT2 Energy (E$_{h}$)')\n",
    "    ax2.set_ylabel('Predicted CASPT2 Energy (E$_{h}$)')\n",
    "    ax2.set_title('Test')    \n",
    "    ax2.legend()\n",
    "    \n",
    "    ax3.scatter(np.array(pred_train.index,dtype=float),pred_train,color=pairedcp[4])\n",
    "    ax3.plot(np.array(pt2.index,dtype=float),pt2.values,'k')\n",
    "    ax3.set_xlabel('Radius (Å)')\n",
    "    ax3.set_ylabel('CASPT2 Energy (E$_{h}$)')\n",
    "    ax3.set_title('Train')\n",
    "    \n",
    "    ax4.scatter(np.array(pred_test.index,dtype=float),pred_test,color=pairedcp[5])\n",
    "    ax4.plot(np.array(pt2.index,dtype=float),pt2.values,'k')\n",
    "    ax4.set_xlabel('Radius (Å)')\n",
    "    ax4.set_ylabel('CASPT2 Energy (E$_{h}$)')\n",
    "    ax4.set_title('Test')\n",
    "    \n",
    "    fig.suptitle(n)\n",
    "    \n",
    "    plt.subplots_adjust(wspace=0.05)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f'images/reduced_{n}_CASPT2.png',dpi=300,bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdad1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdfcorr=pd.DataFrame.from_dict(testcorr_err,orient='index').rename(columns={0:'test'})\n",
    "traindfcorr=pd.DataFrame.from_dict(traincorr_err,orient='index').rename(columns={0:'train'})\n",
    "errormeltcorr=pd.concat([traindfcorr,testdfcorr],axis=1).reset_index().melt(id_vars='index')\n",
    "errormeltcorr['index']=[i.split('_')[0] for i in errormeltcorr['index']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=pd.concat([CASPT2[i]-CASSCF[i] for i in sorted(CASSCF.columns,key=lambda x: int(x.strip('H')))],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4dfe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errormelt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c751b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5),sharey=True)\n",
    "\n",
    "sns.barplot(data=errormelt,x='index',y='value',hue='variable',palette=sns.color_palette('Paired'),ax=ax1)\n",
    "ax1.set_ylabel('Mean Absolute Error (mE$_{h}$)')\n",
    "ax1.set_xlabel('Structures')\n",
    "ax1.set_title('Pair-Energies')\n",
    "\n",
    "sns.barplot(data=errormeltcorr,x='index',y='value',hue='variable',palette=sns.color_palette('Paired'),ax=ax2)\n",
    "# ax2.set_ylabel('Mean Absolute Error (mE$_{h}$)')\n",
    "ax2.set_ylabel('')\n",
    "ax2.set_xlabel('Structures')\n",
    "ax2.set_title('Correlation Energies')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/reduced_MAE_bar.png',dpi=300,bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9fb58-0e25-4511-a90d-ac65572d63a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd92490-b5ad-4e0b-a2f9-c16f9b82b742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(os.path.join(path,'test_ind.pickle'), 'rb') as handle:\n",
    "        test_ind = pickle.load(handle)\n",
    "    \n",
    "    with open(os.path.join(path,'train_ind.pickle'), 'rb') as handle:\n",
    "        train_ind = pickle.load(handle)\n",
    "        \n",
    "    print(len(train_ind),len(test_ind))    \n",
    "    \n",
    "    train_X=[]\n",
    "    train_y = []\n",
    "    \n",
    "    test_X=[]\n",
    "    test_y = []\n",
    "    # for nam in sorted(glob('*/fixed_feats.pickle'),key=lambda x: int(x.split('_')[0].strip('H')))[2:]:\n",
    "    for nam in glob(os.path.join(path,'*/fixed_feats.pickle')):\n",
    "        trydf=pd.read_pickle(nam).astype(float)[feat_name]    \n",
    "        Hnam=os.path.basename(os.path.dirname(nam)).split('_')[0]\n",
    "        for i in train_ind:\n",
    "            train_X.append(trydf.loc[f'{i:.2f}'].values)\n",
    "        for j in test_ind: \n",
    "            test_X.append(trydf.loc[f'{i:.2f}'].values)\n",
    "        \n",
    "    recover_train=[]    \n",
    "    recover_test=[]    \n",
    "    tst_idx=0\n",
    "    tr_idx=0\n",
    "    for nidx,nam in enumerate(glob(os.path.join(path,'*/fixed_targets.pickle'))):\n",
    "        trydf=pd.read_pickle(nam).astype(float)\n",
    "        Hnam=os.path.basename(os.path.dirname(nam)).split('_')[0]\n",
    "        for tridx,i in enumerate(train_ind):\n",
    "            pairdf=trydf[f'{i:.2f}'].values\n",
    "            train_y.append(pairdf)\n",
    "            for k in range(len(pairdf)):\n",
    "                recover_train.append((Hnam,tridx,tr_idx))\n",
    "                tr_idx+=1\n",
    "            \n",
    "        for teidx,j in enumerate(test_ind): \n",
    "            pairdf=trydf[f'{j:.2f}'].values\n",
    "            test_y.append(pairdf)        \n",
    "            \n",
    "            for k in range(len(pairdf)):\n",
    "                recover_test.append((Hnam,teidx,tst_idx))\n",
    "                tst_idx+=1\n",
    "                \n",
    "    X_train, X_test=np.vstack(train_X).astype(float),np.vstack(test_X).astype(float)\n",
    "    y_train,y_test=np.hstack(train_y).astype(float),np.hstack(test_y).astype(float)\n",
    "    print(X_train.shape,X_test.shape)\n",
    "    print(y_train.shape,y_test.shape)\n",
    "    for u,v in np.argwhere(np.isnan(X_train)):\n",
    "        X_train[u,v]=0\n",
    "        \n",
    "    for u,v in np.argwhere(np.isnan(X_test)):\n",
    "        X_test[u,v]=0    \n",
    "    \n",
    "    for u,v in np.argwhere(np.isinf(X_train)):\n",
    "        X_train[u,v]=0\n",
    "        \n",
    "    for u,v in np.argwhere(np.isinf(X_test)):\n",
    "        X_test[u,v]=0         \n",
    "\n",
    "    scaler=MinMaxScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_test=scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test, recover_train, recover_test, train_ind, test_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d1c07-a1d9-4d32-979f-baf428f439a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, recover_train, recover_test, train_ind, test_ind = load_data('../ozone/basis_sets/VDZP/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a031f-50c5-4157-953f-d4340a8d616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model=XGBRegressor(max_depth=1000,min_child_weight=10,n_estimators=100, reg_alpha=0.001,reg_lambda=0.001,n_jobs=-1)\n",
    "# model.fit(X_train, y_train, verbose=True)\n",
    "# Continue training (fine-tuning) the existing model\n",
    "# model.load_model('hmodel.json')\n",
    "model.fit(X_train, y_train, xgb_model=model.get_booster(), verbose=True)\n",
    "\n",
    "# Evaluate after fine-tuning\n",
    "y_pred_train=model.predict(X_train)\n",
    "y_pred_test=model.predict(X_test)\n",
    "print(f\"R2: {r2_score(y_train,y_pred_train):.4f},{r2_score(y_test,y_pred_test):.4f}\")\n",
    "print(f\"RMSE (mEh): {root_mean_squared_error(y_train,y_pred_train)*1e3:.4f},{root_mean_squared_error(y_test,y_pred_test)*1e3:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d8f4d4-acb1-4ab7-859a-294739df908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_train,y_pred_train,color='g')\n",
    "plt.scatter(y_test,y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3e49d-7000-43db-ae3b-8372ff005797",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34f8f52-0b39-40aa-9a44-b2b8673d4a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r = np.array(recover_train)[:,1:].astype(int)\n",
    "test_r = np.array(recover_test)[:,1:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6ad219-7d59-4ad9-a4e9-11514325413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_E2 = np.sum(y_pred_train.reshape(len(set(train_r[:,0])),-1),axis=1)\n",
    "test_E2 = np.sum(y_pred_test.reshape(len(set(test_r[:,0])),-1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a363258-062e-4b6e-9430-867bdc60c386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd5344-5456-4278-a886-e1735ce73617",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_E2=pd.concat([pd.DataFrame.from_dict({'radius':train_ind,'energy':train_E2,\"set\":['train']*len(train_E2)}),\n",
    "pd.DataFrame.from_dict({'radius':test_ind,'energy':test_E2,\"set\":['test']*len(test_E2)})]).sort_index().rename(columns={0:'energy'}).set_index('radius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177de72-1a2f-4d67-9a23-fcbda639bd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_E2=pd.read_csv('../ozone/basis_sets/VDZP/O3/E2.csv',index_col=0).set_index('radius')\n",
    "CASPT2=pd.read_csv('../ozone/basis_sets/VDZP/O3/CASPT2.csv',index_col=0).set_index('radius')\n",
    "CASSCF=pd.read_csv('../ozone/basis_sets/VDZP/O3/CASSCF.csv',index_col=0).set_index('radius')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485fa069-61fc-45dd-b2bf-f7c2ad4a5754",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_E2['DDCASPT2']=CASSCF['energy']+ml_E2['energy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9addb38-05f6-4f86-a73f-dd0aec6ec8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(ml_E2['DDCASPT2'],CASPT2),root_mean_squared_error(ml_E2['DDCASPT2'],CASPT2)*627.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96db81-8af9-4590-a253-e6b4322d8af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=ml_E2.reset_index(),x='radius',y='DDCASPT2',hue='set')\n",
    "sns.lineplot(data=CASPT2.reset_index(),x='radius',y='energy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf1ddd7-b504-438a-bddd-1b0497f78793",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(train_ind,train_E2,label='Train')\n",
    "plt.scatter(test_ind,test_E2,label='Test')\n",
    "sns.lineplot(data=og_E2,x='radius',y='energy',label='True',color='k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e287c0b3-8e4e-4442-be2e-8190db99ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "explainer = shap.Explainer(model.predict, X_test)\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec98a6-bdb8-48cc-b802-c177520f8b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dffeat=pd.DataFrame(shap_values.abs.values.mean(axis=0),index=feat_name,columns=['shap']).reset_index().rename(columns={'index':'feat'})\n",
    "\n",
    "plt.figure(figsize=(8,12))\n",
    "color_map=sns.color_palette('rocket',6)\n",
    "fontsize = 12\n",
    "ax=dffeat.sort_values('shap').plot.barh(x='feat',y='shap',figsize=(9,12),legend=False,color=color_map[3],fontsize=fontsize)\n",
    "ax.bar_label(ax.containers[0], fmt='%.4e',fontsize=12,padding=1)\n",
    "plt.xticks(np.linspace(0,6e-3,4))\n",
    "plt.xlim(0,3e-4)\n",
    "plt.xlabel('mean(|SHAP value|)',fontsize=fontsize)\n",
    "plt.ylabel('Features',fontsize=fontsize)\n",
    "plt.tight_layout()\n",
    "# os.mkdir('images')\n",
    "#plt.savefig('images/Hn_shap_bar.png',dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# dffeat.sort_values('shap').to_excel('all_Hn_shap.xlsx')\n",
    "# keepidx=np.where(np.log10(dffeat['shap'])>-5)[0]\n",
    "# dffeat.iloc[keepidx].to_excel('keep_Hn_shap.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f699b3-049a-4fb1-9853-877b30c923e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
