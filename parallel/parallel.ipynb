{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bafaef-922b-469c-b2b1-100bb4dbf134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install --upgrade  xeus-python notebook\n",
    "# !{sys.executable} -m pip install memory-profiler\n",
    "#######################################################\n",
    "#Import packages\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import re\n",
    "from math import sin, cos, pi\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import pickle\n",
    "from subprocess import call, check_output\n",
    "import pandas as pd\n",
    "# import psi4\n",
    "from joblib import Parallel,effective_n_jobs,delayed\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from plumbum.cmd import grep, awk\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import random\n",
    "import sklearn\n",
    "from shutil import copy\n",
    "import csv\n",
    "import h5py as h5\n",
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67777916-0f59-4197-a0e2-28a5887b281c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "# Obital labels\n",
    "## Inactive i,j\n",
    "## Active t,u,v\n",
    "## Virtual a,b\n",
    "\n",
    "## Type 1: IA->AA\n",
    "## Type 2: II->AA (P)\n",
    "## Type 3: II->AA (M)\n",
    "## Type 4: AA->VA\n",
    "## Type 5: IA->VA/AV\n",
    "## Type 6: II->AV (P)\n",
    "## Type 7: II->AV (M)\n",
    "## Type 8: AA->VV (P)\n",
    "## Type 9: AA->VV (M)\n",
    "## Type 10: IA->VV (P)\n",
    "## Type 11: IA->VV (M)\n",
    "## Type 12: II->VV (P)\n",
    "## Type 13: II->VV (M)\n",
    "\n",
    "## A: IA->AA\n",
    "## B: II->AA\n",
    "## C: AA->VA\n",
    "## D: IA->VA/AV\n",
    "## E: II->AV\n",
    "## F: AA->VV\n",
    "## G: IA->VV \n",
    "## H: II->VV\n",
    "#######################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b87f04-7564-42d4-867a-4cd8be078a6d",
   "metadata": {},
   "source": [
    "\n",
    "Dimension check for DDCASPT2: check the ordering of the pair-energies,\n",
    "this notation follows a mix of the papers and code.\n",
    "\n",
    "A (IA->AA): \\ TIUV \\ E$_{ti}$ E$_{uv}$ \\ pqrs=tiuv=0123 \\    \n",
    "B_P (II->AA) (P): \\ IJTU \\ E$_{ti}$ E$_{uj}$ \\ pqrs=tiuj=2031 \\\n",
    "B_M (II->AA) (M): \\ IJTU \\ E$_{ti}$ E$_{uj}$ \\ pqrs=tiuj=2031 \\\n",
    "C (AA->VA): \\ UVAT \\ E$_{at}$ E$_{uv}$ \\ pqrs=atuv=2301 \\\n",
    "D (IA->VA/AV): \\ IUAT/IUTA \\ E$_{ai}$ E$_{tu}$/E$_{ti}$ E$_{au}$ \\ pqrs=(a/t)i(t/a)u=2031 \\\n",
    "E_P (II->AV) (P): \\ IJAT \\ E$_{ti}$ E$_{aj}$ \\ pqrs=tiaj=3021 \\\n",
    "E_M (II->AV) (M): \\ IJAT \\ E$_{ti}$ E$_{aj}$ \\ pqrs=tiaj=3021 \\\n",
    "F_P (AA->VV) (P): \\ TUAB \\ E$_{at}$ E$_{bu}$ \\ pqrs=atbu=2031 \\\n",
    "F_M (AA->VV) (M): \\ TUAB \\ E$_{at}$ E$_{bu}$ \\ pqrs=atbu=2031 \\\n",
    "G_P (IA->VV) (P): \\ ITAB \\ E$_{ai}$ E$_{bt}$ \\ pqrs=aibt=2031 \\\n",
    "G_M (IA->VV) (M): \\ ITAB \\ E$_{ai}$ E$_{bt}$ \\ pqrs=aibt=2031 \\\n",
    "H_P (II->VV) (P): \\ IJAB \\ E$_{ai}$ E$_{bj}$ \\ pqrs=aibj=2031 \\\n",
    "H_M (II->VV) (M): \\ IJAB \\ E$_{ai}$ E$_{bj}$ \\ pqrs=aibj=2031 \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e3226-5187-461c-a732-238ebc9e8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "\n",
    "def print_memory(fn):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        process = psutil.Process(os.getpid())\n",
    "        startmemproc = process.memory_info()\n",
    "        start_rss, start_vms = startmemproc.rss, startmemproc.vms\n",
    "        try:\n",
    "            return fn(*args, **kwargs)\n",
    "        finally:\n",
    "            endmemproc = process.memory_info()\n",
    "            end_rss, end_vms = endmemproc.rss, endmemproc.vms\n",
    "            print(f\"Resident Set Size: {(end_rss - start_rss)*(10**-6):.2f} MB\", f\"Virtual Memory Size: {(end_vms - start_vms)*(10**-6):.2f} MB\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f082723-78c7-492c-8bc5-aaca961a527a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDCASPT2:\n",
    "    def __init__(self,path,basis_set,name,electrons,occupied,inactive,previous=None,symmetry=1,spin=0,UHF=False,charge=0,clean=False,n_jobs=None):\n",
    "        '''\n",
    "        Initialize\n",
    "        '''\n",
    "        self.path=path\n",
    "        self.basis_set=basis_set\n",
    "        self.name=name\n",
    "        self.electrons=electrons\n",
    "        self.occupied=occupied\n",
    "        self.inactive=inactive\n",
    "        self.previous=previous\n",
    "        self.symmetry=symmetry\n",
    "        self.spin=spin      \n",
    "        self.UHF=UHF\n",
    "        self.charge=charge\n",
    "        self.clean=clean\n",
    "        self.n_jobs=n_jobs\n",
    "\n",
    "        print(f\"Running on {self.n_jobs} cores\")\n",
    "        \n",
    "        if 'grierjones' in os.getcwd():\n",
    "            os.environ['MOLCAS']='/home/grierjones/Test/build'\n",
    "            os.environ['MOLCAS_WORKDIR']='/tmp'\n",
    "        elif 'isaac' in os.getcwd():\n",
    "            os.environ['MOLCAS']=\"/lustre/isaac/proj/UTK0022/GMJ/Test/build\"\n",
    "            os.environ['MOLCAS_WORKDIR']='/lustre/isaac/scratch/gjones39/'\n",
    "\n",
    "        print(f\"Found a valid MOLCAS installation at {os.environ['MOLCAS']}\")\n",
    "        print(f\"MOLCAS_WORKDIR is set to {os.environ['MOLCAS_WORKDIR']}\")\n",
    "\n",
    "    def del_useless(self):\n",
    "        '''\n",
    "        Delete the extra files\n",
    "        '''\n",
    "        for root, dirs, files in os.walk(self.path):\n",
    "            for file in files:\n",
    "                for j in ['status','GssOrb','LprOrb','LoProp','guessorb','xmldump','RasOrb','SpdOrb','ScfOrb']:\n",
    "                    if j in file:\n",
    "                        os.remove(os.path.join(root,file))   \n",
    "                        \n",
    "        for i in glob(\"GMJ*csv\")+glob(\"*GMJ*int*csv\")+glob('*h5'):\n",
    "            os.remove(i)\n",
    "\n",
    "\n",
    "    def _gen_gateway(self):\n",
    "        string=f'''&GATEWAY \n",
    "coord={f'{self.name}.xyz'}\n",
    "Basis = {self.basis_set}\n",
    "Group = nosymm\n",
    "Expert\n",
    "End of Input\n",
    "\n",
    "'''\n",
    "        return string\n",
    "    \n",
    "    def _gen_seward(self):\n",
    "        string=f'''&SEWARD\n",
    "End of Input\n",
    "\n",
    "'''\n",
    "        return string\n",
    "    \n",
    "    def _gen_motra(self):\n",
    "        string=f'''&MOTRA\n",
    "Frozen=0\n",
    "LUMORB\n",
    ">>> COPY $WorkDir/GMJ_one_int_indx.csv $CurrDir/{self.name}.GMJ_one_int_indx.csv\n",
    ">>> COPY $WorkDir/GMJ_one_int.csv $CurrDir/{self.name}.GMJ_one_int.csv\n",
    ">>> COPY $WorkDir/GMJ_two_int_indx.csv $CurrDir/{self.name}.GMJ_two_int_indx.csv\n",
    ">>> COPY $WorkDir/GMJ_two_int.csv $CurrDir/{self.name}.GMJ_two_int.csv\n",
    "\n",
    "'''\n",
    "        return string\n",
    "    \n",
    "    def _gen_scf(self):\n",
    "        if self.UHF:\n",
    "            string=f\"\"\"&SCF &END\n",
    "UHF\n",
    "charge\n",
    "{self.charge}\n",
    "spin\n",
    "{self.spin + 1}            \n",
    ">>> COPY $WorkDir/{self.name}.scf.h5 $CurrDir/\n",
    "\n",
    "\"\"\"            \n",
    "        else:\n",
    "            string=f\"\"\"&SCF &END\n",
    ">>> COPY $WorkDir/{self.name}.scf.h5 $CurrDir/\n",
    "\n",
    "\"\"\"\n",
    "        return string    \n",
    "    \n",
    "    \n",
    "    def _gen_rasscf(self):\n",
    "        start_string=\"\"\"&RASSCF &END\n",
    "Title= RASSCF\n",
    "\"\"\"\n",
    "        if self.previous!=None:\n",
    "            fileorb=f\"\"\"FileOrb\n",
    "{self.previous}\n",
    "\"\"\"\n",
    "        else:\n",
    "            fileorb=''\n",
    "\n",
    "        if self.inactive==None:\n",
    "            end_string=f\"\"\"NACTEL\n",
    "{self.electrons} 0 0\n",
    "RAS2\n",
    "{self.occupied}\n",
    "Symmetry\n",
    "{self.symmetry}\n",
    "Spin\n",
    "{self.spin + 1}\n",
    "charge\n",
    "{self.charge}\n",
    "orblisting\n",
    "all\n",
    "ITERation\n",
    "300 200\n",
    "\n",
    "\n",
    ">>> COPY $WorkDir/{self.name}.rasscf.h5 $CurrDir/\n",
    ">>> COPY $WorkDir/GMJ_Fock_MO.csv $CurrDir/{self.name}.GMJ_Fock_MO.csv\n",
    ">>> COPY $WorkDir/GMJ_PT2_Fock_MO.csv $CurrDir/{self.name}.GMJ_PT2_Fock_MO.csv\n",
    "\n",
    "\"\"\"\n",
    "        else:\n",
    "            end_string=f\"\"\"NACTEL\n",
    "{self.electrons} 0 0\n",
    "Inactive\n",
    "{self.inactive}\n",
    "RAS2\n",
    "{self.occupied}\n",
    "Symmetry\n",
    "{self.symmetry}\n",
    "Spin\n",
    "{self.spin + 1}\n",
    "orblisting\n",
    "all\n",
    "ITERation\n",
    "300 200\n",
    "\n",
    "\n",
    ">>> COPY $WorkDir/{self.name}.rasscf.h5 $CurrDir/\n",
    ">>> COPY $WorkDir/GMJ_Fock_MO.csv $CurrDir/{self.name}.GMJ_Fock_MO.csv\n",
    ">>> COPY $WorkDir/GMJ_PT2_Fock_MO.csv $CurrDir/{self.name}.GMJ_PT2_Fock_MO.csv\n",
    "\n",
    "\"\"\"\n",
    "        return start_string+fileorb+end_string \n",
    "    \n",
    "    def _gen_caspt2(self):\n",
    "        string=\"\"\"&CASPT2 &END\n",
    "Frozen \n",
    "0\n",
    "MAXITER\n",
    "50\n",
    "\n",
    ">>foreach i in (B,E,F,G,H)\n",
    ">>foreach j in (P,M)\n",
    ">>if ( -FILE GMJ_e2_${i}_${j}.csv )\n",
    ">>> COPY $WorkDir/GMJ_RHS_${i}_${j}.csv $CurrDir/GMJ_RHS_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECW_${i}_${j}.csv $CurrDir/GMJ_IVECW_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECX_${i}_${j}.csv $CurrDir/GMJ_IVECX_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECC2_${i}_${j}.csv $CurrDir/GMJ_IVECC2_${i}_${j}.csv\n",
    ">>> COPY $WorkDir/GMJ_e2_${i}_${j}.csv $CurrDir/GMJ_e2_${i}_${j}.csv\n",
    ">>endif\n",
    ">>enddo\n",
    ">>enddo\n",
    "\n",
    ">>foreach i in (A,C,D)\n",
    ">>if ( -FILE GMJ_e2_$i.csv )\n",
    ">>> COPY $WorkDir/GMJ_RHS_$i.csv $CurrDir/GMJ_RHS_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECW_$i.csv $CurrDir/GMJ_IVECW_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECX_$i.csv $CurrDir/GMJ_IVECX_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_IVECC2_$i.csv $CurrDir/GMJ_IVECC2_$i.csv\n",
    ">>> COPY $WorkDir/GMJ_e2_$i.csv $CurrDir/GMJ_e2_$i.csv\n",
    ">>endif\n",
    ">>enddo\n",
    "\"\"\"\n",
    "        return string    \n",
    "        \n",
    "    def write_input(self):\n",
    "       # Write input\n",
    "        with open(os.path.join(self.path,f'{self.name}.input'),'wb') as g:\n",
    "            g.write(self._gen_gateway().encode())\n",
    "            g.write(self._gen_seward().encode())\n",
    "            g.write(self._gen_scf().encode())   \n",
    "            g.write(self._gen_rasscf().encode())\n",
    "            g.write(self._gen_motra().encode())\n",
    "            g.write(self._gen_caspt2().encode())    \n",
    "\n",
    "    def write_energies(self):\n",
    "        # Grab energies\n",
    "        self.path_check = os.path.join(self.path,f'{self.name}.output')\n",
    "\n",
    "        self.E2 = float((grep['-i', 'E2 (Variational):',self.path_check] | awk['{print $NF }'])())\n",
    "        self.CASSCF_E = float((grep['-i', '::    RASSCF root number  1',self.path_check] | awk['{print $8 }'])())\n",
    "        self.CASPT2_E = float((grep['-i', '::    CASPT2',self.path_check] | awk['{print $NF }'])())   \n",
    "\n",
    "        pd.DataFrame.from_dict({\"E2\":self.E2,\"CASSCF_E\":self.CASSCF_E,\"CASPT2_E\":self.CASPT2_E},orient='index').rename(columns={0:self.name}).to_excel(os.path.join(self.path,f\"{self.name}_energies.xlsx\"))\n",
    "\n",
    "    def orbitals(self):\n",
    "        #Grab basis information\n",
    "        self.fro=int(subprocess.Popen(f\"grep -i 'Frozen orbitals' {self.path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "        # Number of inactive orbitals\n",
    "        self.inact=int(subprocess.Popen(f\"grep -i 'Inactive orbitals' {self.path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "        # Number of active orbitals\n",
    "        self.act=int(subprocess.Popen(f\"grep -i 'Active orbitals' {self.path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "        # Number of seconary orbitals\n",
    "        self.virt=int(subprocess.Popen(f\"grep -i 'Secondary orbitals' {self.path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "        # Number of basis functions for sanity check\n",
    "        self.bas_check=int(subprocess.Popen(f\"grep -i 'Number of basis functions' {self.path_check} | tail -n 1\",shell=True,stdout=subprocess.PIPE,stderr=subprocess.STDOUT).communicate()[0].split()[-1])\n",
    "        \n",
    "        Basis_Indices=[]\n",
    "        for i in range(self.fro):\n",
    "            Basis_Indices.append(f'F{i+1}')\n",
    "        for i in range(self.inact):\n",
    "            Basis_Indices.append(f'I{i+1}')\n",
    "        for i in range(self.act):\n",
    "            Basis_Indices.append(f'A{i+1}')\n",
    "        for i in range(self.virt):\n",
    "            Basis_Indices.append(f'S{i+1}')   \n",
    "        \n",
    "        self.Basis_Indices = Basis_Indices\n",
    "        self.basis_dict = {v:k for k,v in dict(enumerate(Basis_Indices)).items()}        \n",
    "\n",
    "    def strip(self,lst):   \n",
    "        '''\n",
    "        Strips preceeding 0s in indexing files\n",
    "        '''\n",
    "        return '_'.join(re.sub(r'(?<!\\d)0+(\\d+)', r'\\1', i) for i in lst.split('_'))\n",
    "\n",
    "\n",
    "    def caspt2_fock_indexing(self,u,v):\n",
    "        '''\n",
    "        Fast way to generate feature labels for the CASPT2 style Fock featues\n",
    "        '''\n",
    "        return [\"F$_{\"+f\"{u}{v}\"+\"}$\",\"FI$_{\"+f\"{u}{v}\"+\"}$\",\"FA$_{\"+f\"{u}{v}\"+\"}$\",\"D$_{\"+f\"{u}{v}\"+\"}$\"]\n",
    "        \n",
    "    def eightfold(self,i,j,k,l,integrals):\n",
    "        '''\n",
    "        Generate the permutational symmetries of the two-electron integrals \n",
    "        Parameters\n",
    "        ----------\n",
    "        idx: Int\n",
    "            Index of the sorted two-electron excitations\n",
    "        i: Int\n",
    "            Index of orbital i\n",
    "        j: Int\n",
    "            Index of orbital j\n",
    "        k: Int\n",
    "            Index of orbital k\n",
    "        l: Int\n",
    "            Index of orbital l\n",
    "        integrals: np.ndarray\n",
    "            Integral array with format [i,j,k,l,value]\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        outint: np.ndarray\n",
    "            Integral array with format [i,j,k,l,value]\n",
    "        \n",
    "        '''\n",
    "        permutations = [[i,j,k,l], [j,i,l,k], [k,l,i,j], [l,k,j,i], [k,j,i,l], [l,i,j,k], [i,l,k,j], [j,k,l,i]]\n",
    "        r_integrals=[]\n",
    "        for p,q,r,s in permutations:\n",
    "            ints = integrals[(integrals[:,0]==p)&(integrals[:,1]==q)&(integrals[:,2]==r)&(integrals[:,3]==s)]\n",
    "            if len(ints)>0:\n",
    "                r_integrals.append(ints)\n",
    "        outint = np.unique(np.array(r_integrals).reshape(-1,5),axis=0).flatten()\n",
    "        if len(outint)>0:\n",
    "            return outint[-1]\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    \n",
    "    def Coulomb(self,i,j,integrals):\n",
    "        '''\n",
    "        Generate the permutational symmetries of the Coulomb integrals \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        i: Int\n",
    "            Index of orbital i\n",
    "        q: Int\n",
    "            Index of orbital q\n",
    "        integrals: np.ndarray\n",
    "            Integral array with format [p,q,r,s,value]\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        eightfold: function\n",
    "            help(eightfold)    \n",
    "        '''    \n",
    "        return self.eightfold(i,j,i,j,integrals)\n",
    "    \n",
    "    def Exchange(self,i,j,integrals):\n",
    "        '''\n",
    "        Generate the permutational symmetries of the Coulomb integrals \n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        i: Int\n",
    "            Index of orbital i\n",
    "        q: Int\n",
    "            Index of orbital q\n",
    "        integrals: np.ndarray\n",
    "            Integral array with format [p,q,r,s,value]\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        eightfold: function\n",
    "            help(eightfold)\n",
    "        '''        \n",
    "        return self.eightfold(i,j,j,i,integrals)\n",
    "    \n",
    "    \n",
    "    def find_integrals(self,idx,p,q,r,s,integrals):\n",
    "        '''\n",
    "        Simplify returning the integrals\n",
    "        \n",
    "        cases:\n",
    "        ijkl\n",
    "        ijlk\n",
    "        Jii\n",
    "        Jjj\n",
    "        Jkk\n",
    "        Jll\n",
    "        Jij\n",
    "        Jkl\n",
    "        Kij\n",
    "        Kkl\n",
    "    \n",
    "        Parameters\n",
    "        ----------\n",
    "        idx: Int\n",
    "            Index of the sorted two-electron excitations\n",
    "        p: Int\n",
    "            Index of orbital p\n",
    "        q: Int\n",
    "            Index of orbital q\n",
    "        r: Int\n",
    "            Index of orbital r\n",
    "        s: Int\n",
    "            Index of orbital s\n",
    "        integrals: np.ndarray\n",
    "            Integral array with format [p,q,r,s,value]\n",
    "    \n",
    "        Returns\n",
    "        -------\n",
    "        intdict: dict\n",
    "            Dictionary with the integrals. Keys are the LaTeX formatted features names and the values should be the integrals\n",
    "        '''\n",
    "        intdict = {}\n",
    "        # Find <pq|rs>\n",
    "        intdict[r\"$(\\langle pq \\vert rs \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.eightfold(p,q,r,s,integrals)\n",
    "        # Find <pq|sr>\n",
    "        intdict[r\"$(\\langle pq \\vert sr \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.eightfold(p,q,r,s,integrals)\n",
    "        \n",
    "        # Find Jpp <pp|pp>\n",
    "        intdict[r\"$(\\langle pp \\vert pp \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Coulomb(p,p,integrals)\n",
    "        # Find Jqq <qq|qq>\n",
    "        intdict[r\"$(\\langle qq \\vert qq \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Coulomb(q,q,integrals)\n",
    "        # Find Jrr <rr|rr>\n",
    "        intdict[r\"$(\\langle rr \\vert rr \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Coulomb(r,r,integrals)\n",
    "        # Find Jss <ss|ss>\n",
    "        intdict[r\"$(\\langle ss \\vert ss \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Coulomb(s,s,integrals)\n",
    "        \n",
    "        # Find Jpq <pq|pq>\n",
    "        intdict[r\"$(\\langle pq \\vert pq \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Coulomb(p,q,integrals)\n",
    "        # Find Kpq <pq|qp>\n",
    "        intdict[r\"$(\\langle pq \\vert qp \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Exchange(p,q,integrals)\n",
    "    \n",
    "        # Find Jrs <rs|rs>\n",
    "        intdict[r\"$(\\langle rs\\vert rs \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Coulomb(r,s,integrals)\n",
    "        # Find Krs <rs|sr>\n",
    "        intdict[r\"$(\\langle rs \\vert sr \\rangle)_{\"+f\"{idx}\"+\"}$\"] = self.Exchange(r,s,integrals)\n",
    "        return intdict    \n",
    "            \n",
    "    def parallel_feat(self,uniquepair):\n",
    "        '''\n",
    "        This is a helper function to create the features\n",
    "\n",
    "        parameters\n",
    "        ----------\n",
    "        uniquepair: str\n",
    "            Unique pair-energy label XX_YY\n",
    "        '''\n",
    "        q,s = uniquepair.split('_')\n",
    "        qidx = self.basis_dict[q]\n",
    "        sidx = self.basis_dict[s]\n",
    "    \n",
    "        # From same orbital = 1, else 0\n",
    "        if q==s:\n",
    "            self.binary_feat.append((uniquepair,1))\n",
    "        else:\n",
    "            self.binary_feat.append((uniquepair,0))\n",
    "    \n",
    "        # CASPT2 style Fock features\n",
    "        if qidx>=sidx:\n",
    "            self.CASPT2Fockfeatures.append((uniquepair,dict(zip(self.caspt2_fock_indexing('q','s'),self.pt2fock_stacked[:,2:][(self.pt2fock_stacked[:,0]==qidx)&(self.pt2fock_stacked[:,1]==sidx)].flatten()))))\n",
    "        else:\n",
    "            self.CASPT2Fockfeatures.append((uniquepair,dict(zip(self.caspt2_fock_indexing('q','s'),self.pt2fock_stacked[:,2:][(self.pt2fock_stacked[:,0]==sidx)&(self.pt2fock_stacked[:,1]==qidx)].flatten()))))\n",
    "    \n",
    "        # Get the pair-energies that share the same qs\n",
    "        subpairs = self.pairs[self.pairs[:,3]==uniquepair]\n",
    "        \n",
    "        # Grab the largest 4 two-electron contributers\n",
    "        best4 = subpairs[np.argsort(abs(subpairs[:,-1].astype(float)))][-4:]\n",
    "    \n",
    "        # Loop over best four \n",
    "        for b4idx, (typ, pq, rs) in enumerate(best4[:,0:3]):\n",
    "            self.b4_type.append((uniquepair,f\"typ_{b4idx}\",self.typedict[typ]))\n",
    "            p,q = pq.split('_')\n",
    "            r,s = rs.split('_')\n",
    "            pidx = self.basis_dict[p]\n",
    "            qidx = self.basis_dict[q]\n",
    "            ridx = self.basis_dict[r]\n",
    "            sidx = self.basis_dict[s]\n",
    "            self.two_el_feats.append((uniquepair,self.find_integrals(b4idx,pidx,qidx,ridx,sidx,self.twostacked)))\n",
    "                \n",
    "            \n",
    "            # MO features for each index\n",
    "            pMOdf,qMOdf,rMOdf,sMOdf =  self.MO_df.loc[p].to_frame(), self.MO_df.loc[q].to_frame(), self.MO_df.loc[r].to_frame(), self.MO_df.loc[s].to_frame()\n",
    "            \n",
    "            pMOdf.rename(index={'MO_ENERGIES_SCF':r'$(F_{p}^{\\text{SCF}})_{'+f\"{b4idx}\"+\"}$\", 'MO_OCCUPATIONS_SCF':r\"$(\\omega_{p})_{\"+f\"{b4idx}\"+\"}$\",'MO_ENERGIES':r\"$(F_{p})_{\"+f\"{b4idx}\"+\"}$\",'MO_OCCUPATIONS':r\"$(\\eta_{p})_{\"+f\"{b4idx}\"+\"}$\"},inplace=True)\n",
    "            qMOdf.rename(index={'MO_ENERGIES_SCF':r'$(F_{q}^{\\text{SCF}})_{'+f\"{b4idx}\"+\"}$\", 'MO_OCCUPATIONS_SCF':r\"$(\\omega_{q})_{\"+f\"{b4idx}\"+\"}$\",'MO_ENERGIES':r'$(F_{q})_{'+f\"{b4idx}\"+\"}$\",'MO_OCCUPATIONS':r\"$(\\eta_{q})_{\"+f\"{b4idx}\"+\"}$\"},inplace=True)       \n",
    "            rMOdf.rename(index={'MO_ENERGIES_SCF':r'$(F_{r}^{\\text{SCF}})_{'+f\"{b4idx}\"+\"}$\", 'MO_OCCUPATIONS_SCF':r\"$(\\omega_{r})_{\"+f\"{b4idx}\"+\"}$\",'MO_ENERGIES':r'$(F_{r})_{'+f\"{b4idx}\"+\"}$\",'MO_OCCUPATIONS':r\"$(\\eta_{r})_{\"+f\"{b4idx}\"+\"}$\"},inplace=True) \n",
    "            sMOdf.rename(index={'MO_ENERGIES_SCF':r'$(F_{s}^{\\text{SCF}})_{'+f\"{b4idx}\"+\"}$\", 'MO_OCCUPATIONS_SCF':r\"$(\\omega_{s})_{\"+f\"{b4idx}\"+\"}$\",'MO_ENERGIES':r'$(F_{s})_{'+f\"{b4idx}\"+\"}$\",'MO_OCCUPATIONS':r\"$(\\eta_{s})_{\"+f\"{b4idx}\"+\"}$\"},inplace=True)\n",
    "    \n",
    "            self.MO_feat.append((uniquepair,pMOdf,qMOdf,rMOdf,sMOdf))\n",
    "            \n",
    "            # Set of label index pairs\n",
    "            pqrsindex_dict = {\"p\":[p,pidx],\"q\":[q,qidx],\"r\":[r,ridx],\"s\":[s,sidx]}\n",
    "    \n",
    "            # All possible two-index pairs\n",
    "            twoidxpairs = [['p','q'],['r','s'],['p','r'],['q','s'],['p','p'],['q','q'],['r','r'],['s','s']]\n",
    "            # h_{ij} features\n",
    "            for u,v in twoidxpairs:\n",
    "                u_item, u_idx = pqrsindex_dict[u]\n",
    "                v_item, v_idx = pqrsindex_dict[v]\n",
    "                if u_idx>=v_idx:\n",
    "                    self.h_features.append((uniquepair,\"h$_{\"+f\"{u}{v}\"+\"}^{\"+f\"{b4idx}\"+\"}$\",self.h_stacked[(self.oneelint_idx[:,0]==u_idx)&(self.oneelint_idx[:,1]==v_idx)].flatten()[-1]))     \n",
    "                else:\n",
    "                    self.h_features.append((uniquepair,\"h$_{\"+f\"{u}{v}\"+\"}^{\"+f\"{b4idx}\"+\"}$\",self.h_stacked[(self.oneelint_idx[:,0]==v_idx)&(self.oneelint_idx[:,1]==u_idx)].flatten()[-1]))\n",
    "    \n",
    "        \n",
    "        # Pair-energies\n",
    "        pairenergy = np.sum(subpairs[:,-1].astype(float))\n",
    "        self.pairenergylist.append((uniquepair,pairenergy))\n",
    "        self.checkE2 += pairenergy\n",
    "\n",
    "        # local_vars = list(locals().items())\n",
    "        # bytez=0\n",
    "        # for var, obj in local_vars:\n",
    "        #     print(var, sys.getsizeof(obj))\n",
    "        #     bytez+=sys.getsizeof(obj)\n",
    "        # print(bytez * 1e-6)\n",
    "        return self.checkE2, self.h_features, self.CASPT2Fockfeatures, self.b4_type, self.binary_feat, self.MO_feat, self.two_el_feats, self.pairenergylist  \n",
    "    \n",
    "    \n",
    "    def gen_df(self):\n",
    "        '''\n",
    "        Generate feature dataframe\n",
    "        '''\n",
    "        # IT,IU,F(global index),FI(global index),fa(global index),d(global index\n",
    "        caspt2fockdf = pd.concat([pd.DataFrame.from_dict(vals,orient='index',columns=[idx]) for idx, vals in self.CASPT2Fockfeatures],axis=1).T\n",
    "        \n",
    "        # binary feature df\n",
    "        bindf = pd.DataFrame(self.binary_feat).set_index(0).rename(columns={0:'binary'})\n",
    "        \n",
    "        # one-electron dataframe\n",
    "        h_df = pd.DataFrame(self.h_features).pivot(index=0, columns=1)\n",
    "        h_df.columns=h_df.columns.droplevel()\n",
    "        h_df.drop(columns=[\"h$_{qs}^{3}$\",\"h$_{qs}^{1}$\",\"h$_{qs}^{2}$\"],inplace=True)\n",
    "        h_df.rename(columns={\"h$_{qs}^{0}$\":\"h$_{qs}$\"},inplace=True)\n",
    "        \n",
    "        # Important 4 types\n",
    "        important2e = pd.DataFrame(self.b4_type).pivot(index=0, columns=1)\n",
    "        important2e.columns=important2e.columns.droplevel()\n",
    "        \n",
    "        \n",
    "        # two-electron data frame \n",
    "        two_el_df = pd.concat([pd.concat([pd.DataFrame.from_dict(i[1],orient='index').rename(columns={0:i[0]}) for i in self.two_el_feats if i[0]==j]) for j in self.uniquepairs],axis=1).T\n",
    "        \n",
    "        \n",
    "        listconcatmo = []\n",
    "        \n",
    "        for i in self.MO_feat:\n",
    "        \n",
    "            concatMO = pd.concat([j.rename(columns={j.columns[0]:i[0]}) for idx,j in enumerate(i) if idx>0])\n",
    "            # print(concatMO)\n",
    "            listconcatmo.append(concatMO)\n",
    "\n",
    "        allMO_feats = pd.concat([pd.concat([i for i in listconcatmo if i.columns[0]==j]) for j in self.uniquepairs],axis=1).T\n",
    "\n",
    "        pairenergy_df = pd.DataFrame(self.pairenergylist,columns=['index','Pair_Energies']).set_index('index').astype({'Pair_Energies':float})\n",
    "        # Everything together so far\n",
    "        concatdf = pd.concat([h_df,important2e,bindf,caspt2fockdf,allMO_feats,two_el_df,pairenergy_df],axis=1)\n",
    "        concatdf.to_csv(os.path.join(self.path,f\"{self.name}.csv\"),compression='zip') \n",
    "    \n",
    "    def gen_pairs(self,i):\n",
    "        '''\n",
    "        Generate pairs in a parallel manner\n",
    "        '''\n",
    "        pairs = []\n",
    "        typ = os.path.basename(i).split('.')[0].replace('GMJ_e2_','')\n",
    "        # print(typ)\n",
    "        \n",
    "        IVEC = pd.read_csv(os.path.join(self.path,f'GMJ_IVECW_{typ}.csv'),sep='\\s+',header=None,skiprows=[0])\n",
    "        RHS = pd.read_csv(os.path.join(self.path,f'GMJ_RHS_{typ}.csv'),sep=',',header=None,index_col=0)\n",
    "        RHS.index = list(map(self.strip,RHS.index))\n",
    "        RHS = np.array(RHS.index).reshape(IVEC.shape)\n",
    "        e2 = np.genfromtxt(os.path.join(self.path,f'GMJ_e2_{typ}.csv'),skip_header=True).reshape(RHS.shape)\n",
    "        IVECX = pd.read_csv(os.path.join(self.path,f'GMJ_IVECX_{typ}.csv'),sep='\\s+',header=None,skiprows=[0])\n",
    "\n",
    "        IVECC2 = pd.read_csv(os.path.join(self.path,f'GMJ_IVECC2_{typ}.csv'),sep='\\s+',header=None,skiprows=[0])    \n",
    "        for idxi,i in enumerate(RHS):\n",
    "            for idxj,j in enumerate(i):\n",
    "                # Split the index and enforce a standardization of p,q,r,s \n",
    "                split_index = j.split('_')\n",
    "                type_idx = self.index_dict[typ]\n",
    "                p,q,r,s = split_index[type_idx['p']],split_index[type_idx['q']],split_index[type_idx['r']],split_index[type_idx['s']]\n",
    "                # typ, pq,rs,qs,e2\n",
    "                pairs.append((typ,'_'.join((p,q)),'_'.join((r,s)),'_'.join((q,s)),e2[idxi,idxj])) \n",
    "        self.pairs = np.array(pairs)\n",
    "        return self.pairs\n",
    "\n",
    "    @print_memory\n",
    "    def gen_feats(self):\n",
    "        '''\n",
    "        Generate features\n",
    "        '''\n",
    "        self.orbitals()\n",
    "        # Load the PT2 Fock elements\n",
    "        # Columns are as follows:\n",
    "        # IT,IU,F(global index),FI(global index),fa(global index),d(global index)\n",
    "        pt2fock = os.path.join(self.path,f\"{self.name}.GMJ_PT2_Fock_MO.csv\")\n",
    "        \n",
    "        pt2fock_values = np.nan_to_num(np.fromfile(pt2fock,dtype=float).reshape(-1,6)[:,3:])\n",
    "        pt2fock_idx = np.fromfile(pt2fock,dtype=int).reshape(-1,6)[:,0:3]-1\n",
    "        self.pt2fock_stacked = np.hstack([pt2fock_idx,pt2fock_values])\n",
    "        \n",
    "        \n",
    "        # Read CASSCF Fock from file\n",
    "        CASSCF_fock = np.fromfile(os.path.join(self.path,f\"{self.name}.GMJ_Fock_MO.csv\"))\n",
    "        \n",
    "        # Load one-electron integrals\n",
    "        oneelint = np.fromfile(os.path.join(self.path,f\"{self.name}.GMJ_one_int.csv\")).reshape(-1,1)\n",
    "        self.oneelint_idx = np.fromfile(os.path.join(self.path,f\"{self.name}.GMJ_one_int_indx.csv\"),dtype=int).reshape(-1,4)[:,0:2]-1\n",
    "        self.h_stacked = np.hstack([self.oneelint_idx,oneelint])\n",
    "        \n",
    "        # Load two-electron integrals (they're in physicist notation by default!) ijkl are indeed <ik|jl>\n",
    "        twoelint = np.fromfile(os.path.join(self.path,f\"{self.name}.GMJ_two_int.csv\")).reshape(-1,1)\n",
    "        twoelint_idx_chemist = np.fromfile(os.path.join(self.path,f\"{self.name}.GMJ_two_int_indx.csv\"),dtype=int).reshape(-1,4)-1\n",
    "        \n",
    "        twoelint_idx_physicist = twoelint_idx_chemist.copy()\n",
    "        # <ij|kl>\n",
    "        twoelint_idx_physicist[:,1] = twoelint_idx_chemist[:,2]\n",
    "        twoelint_idx_physicist[:,2] = twoelint_idx_chemist[:,1]\n",
    "        # del twoelint_idx_chemist\n",
    "        self.twostacked = np.hstack([twoelint_idx_physicist,twoelint])\n",
    "        \n",
    "        # Grab rasscf and scf hdf5 data\n",
    "        rasscf_h5 = h5.File(os.path.join(self.path,f\"{self.name}.rasscf.h5\"), 'r')\n",
    "        scf_h5 = h5.File(os.path.join(self.path,f\"{self.name}.scf.h5\"), 'r')\n",
    "        \n",
    "        datasetNames = [n for n in rasscf_h5.keys()]\n",
    "        NBAS = rasscf_h5.attrs['NBAS']\n",
    "        NACTEL = rasscf_h5.attrs['NACTEL']\n",
    "        \n",
    "        #Keys: MO_VECTORS, MO_ENERGIES, MO_OCCUPATIONS\n",
    "        casMO_dict = {k:np.array(rasscf_h5[k]) for k in datasetNames if \"MO_E\" in k or \"MO_O\" in k}\n",
    "        scfMO_dict = {k:np.array(scf_h5[k]) for k in datasetNames if \"MO_E\" in k or \"MO_O\" in k}\n",
    "        \n",
    "        \n",
    "        # MO features made easy!\n",
    "        MO_df = pd.DataFrame.from_dict(scfMO_dict).rename(columns={\"MO_ENERGIES\":\"MO_ENERGIES_SCF\",\"MO_OCCUPATIONS\":\"MO_OCCUPATIONS_SCF\"})\n",
    "        MO_df['MO_ENERGIES']=CASSCF_fock\n",
    "        MO_df['MO_OCCUPATIONS']=casMO_dict['MO_OCCUPATIONS']\n",
    "        # MO_df = MO_df.reset_index()\n",
    "        MO_df.index = self.basis_dict.keys()\n",
    "        self.MO_df = MO_df\n",
    "        \n",
    "        # Get two-electron indices\n",
    "        \n",
    "        two_el_ex_labels = {i.split('.')[0].replace(\"GMJ_RHS_\",\"\"):[re.sub(r'(?<!\\d)0+(\\d+)', r'\\1', j) for j in pd.read_csv(i,header=None)[0].values] for i in glob(os.path.join(self.path,\"GMJ_RHS_*.csv\"))}\n",
    "        \n",
    "        pair_labels = {i.split('.')[0].replace(\"GMJ_RHS_\",\"\"):['_'.join(re.sub(r'(?<!\\d)0+(\\d+)', r'\\1', j).split('_')[0:2]) for j in pd.read_csv(i,header=None)[0].values] for i in glob(os.path.join(self.path,\"GMJ_RHS_*.csv\"))}\n",
    "        \n",
    "        # CASPT2 E_pq E_rs ordering\n",
    "        self.index_dict = {\"A\":{\"p\":0,\"q\":1,\"r\":2,\"s\":3},\n",
    "        \"B_P\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"B_M\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"C\":{\"p\":2,\"q\":3,\"r\":0,\"s\":1},\n",
    "        \"D\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"E_P\":{\"p\":3,\"q\":0,\"r\":2,\"s\":1},\n",
    "        \"E_M\":{\"p\":3,\"q\":0,\"r\":2,\"s\":1},\n",
    "        \"F_P\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"F_M\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"G_P\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"G_M\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"H_P\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1},\n",
    "        \"H_M\":{\"p\":2,\"q\":0,\"r\":3,\"s\":1}}\n",
    "        \n",
    "        self.typedict = {v:k for k,v in dict(enumerate([\"A\", \"B_P\", \"B_M\", \"C\", \"D\", \"E_P\", \"E_M\", \"F_P\", \"F_M\", \"G_P\", \"G_M\", \"H_P\", \"H_M\"])).items()}\n",
    "        \n",
    "        \n",
    "        \n",
    "        # IVECW and IRHS should have same indices\n",
    "        # Same as IVECC2, it should all be element wise\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        if self.n_jobs==None:\n",
    "            self.pairs = np.vstack([self.gen_pairs(i) for i in tqdm(glob(os.path.join(self.path,\"GMJ_e2_*.csv\")),desc=\"Pairs\")])    \n",
    "        else:\n",
    "            self.pairs = np.vstack(Parallel(n_jobs=self.n_jobs)(delayed(self.gen_pairs)(i) for i in tqdm(glob(os.path.join(self.path,\"GMJ_e2_*.csv\")),desc=\"Pairs\")))  \n",
    "        # self.pairs = np.vstack(Parallel(n_jobs=-1)(delayed(self.gen_pairs)(i) for i in tqdm(glob(os.path.join(self.path,\"GMJ_e2_*.csv\")),desc=\"Pairs\")))  \n",
    "        \n",
    "        # qs pairs!\n",
    "        uniquepairs = np.unique(self.pairs[:,3])\n",
    "        self.uniquepairs = uniquepairs\n",
    "        self.checkE2=0\n",
    "\n",
    "        \n",
    "        self.h_features = []\n",
    "        self.CASPT2Fockfeatures = []\n",
    "        self.b4_type = []\n",
    "        self.binary_feat = []\n",
    "        self.MO_feat = []\n",
    "        self.two_el_feats = []\n",
    "        self.pairenergylist = []\n",
    "\n",
    "        \n",
    "        if self.n_jobs==None:\n",
    "            out = []\n",
    "            for i in tqdm(self.uniquepairs,desc=\"Features\"):\n",
    "                outpar = self.parallel_feat(i)\n",
    "\n",
    "        else:\n",
    "            outpar=Parallel(n_jobs=self.n_jobs)(delayed(self.parallel_feat)(i) for i in tqdm(self.uniquepairs,desc=\"Features\"))\n",
    "            for i in outpar:\n",
    "                self.checkE2 += i[0]\n",
    "                self.h_features.append(i[1])\n",
    "                self.CASPT2Fockfeatures.append(i[2])\n",
    "                self.b4_type.append(i[3])\n",
    "                self.binary_feat.append(i[4])\n",
    "                self.MO_feat.append(i[5])\n",
    "                self.two_el_feats.append(i[6])\n",
    "                self.pairenergylist.append(i[7])\n",
    "        \n",
    "  \n",
    "            self.h_features = sum(self.h_features,[])\n",
    "            self.CASPT2Fockfeatures = sum(self.CASPT2Fockfeatures,[])\n",
    "            self.b4_type = sum(self.b4_type,[])\n",
    "            self.binary_feat = sum(self.binary_feat,[])\n",
    "            self.MO_feat = sum(self.MO_feat,[])\n",
    "            self.two_el_feats = sum(self.two_el_feats,[])\n",
    "            self.pairenergylist = sum(self.pairenergylist,[])\n",
    "        \n",
    "        # local_vars = list(locals().items())\n",
    "        # bytez=0\n",
    "        # for var, obj in local_vars:\n",
    "        #     print(var, sys.getsizeof(obj))\n",
    "        #     bytez+=sys.getsizeof(obj)\n",
    "        # print(bytez * 1e-6)\n",
    "        \n",
    "        self.gen_df()\n",
    "        \n",
    "    \n",
    "    def __call__(self,run=True):\n",
    "        '''\n",
    "        Create input, run file, write energies to file, generate feature data, and clean up\n",
    "        '''\n",
    "        if run==True:\n",
    "            self.write_input()\n",
    "        \n",
    "        top = os.getcwd()\n",
    "        os.chdir(self.path)\n",
    "        \n",
    "        if run==True:\n",
    "            call(['pymolcas','-new','-clean',os.path.join(self.path,f'{self.name}.input'), '-oe', os.path.join(self.path,f'{self.name}.output')])\n",
    "        self.write_energies()\n",
    "            \n",
    "        self.gen_feats()\n",
    "        \n",
    "        if self.clean:\n",
    "            self.del_useless()\n",
    "        os.chdir(top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4df74a-edfe-443d-9e8d-86439fb211a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in glob(\"GMJ*csv\")+glob(\"*GMJ*int*csv\")+glob('*h5'):\n",
    "# #     os.remove(i)\n",
    "# DDCASPT2('./','ANO-RCC-MB','988-v',10,8,None,previous=\"$CurrDir/988-v.RasOrb\",symmetry=1,spin=4,UHF=True,charge=2,clean=False,n_jobs=12)(run=False)\n",
    "# parallelfeat = pd.read_csv('988-v.csv',compression='zip',index_col=0)\n",
    "# # serialfeat = pd.read_csv('../new_DDCASPT2/O3_106.00.csv',compression='zip',index_col=0)\n",
    "# # print(f\"O3={(parallelfeat == serialfeat).all().all()}\")\n",
    "# # print((parallelfeat == serialfeat).all()[~(parallelfeat == serialfeat).all()])\n",
    "# print(*pd.read_excel('988-v_energies.xlsx',index_col=0).loc['E2'].values,parallelfeat['Pair_Energies'].sum())\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7dcca-40c7-4123-a493-c93f3bdc46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext memory_profiler\n",
    "\n",
    "# for i in glob(\"GMJ*csv\")+glob(\"*GMJ*int*csv\")+glob('*h5'):\n",
    "#     os.remove(i)\n",
    "# %memit DDCASPT2('./','ANO-RCC-VDZP','O3_106.00',4,3,10,previous=None,symmetry=1,spin=0,UHF=False,charge=0,clean=False,n_jobs=-1)(run=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eaaa55-4c69-46b9-9039-81fa76c0a764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in glob(\"GMJ*csv\")+glob(\"*GMJ*int*csv\")+glob('*h5'):\n",
    "#     os.remove(i)\n",
    "\n",
    "%load_ext memory_profiler\n",
    "%memit DDCASPT2('./','ANO-RCC-MB','988-v',10,8,None,previous=\"$CurrDir/988-v.RasOrb\",symmetry=1,spin=4,UHF=True,charge=2,clean=False,n_jobs=12)(run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23af8f6-219e-4887-96e0-7f286d4e0206",
   "metadata": {},
   "outputs": [],
   "source": [
    "788823520 * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c5c0f-ad43-4d35-9dd7-1a1395903ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "13214.25 * 0.00104858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e921192-e43f-4426-8c15-59ed69c61387",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ed1f95-4fe2-4ba9-841e-69b8795e346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST==True:\n",
    "    for j in [None,16]:\n",
    "        for c in [True,False]:\n",
    "            print(f\"jobs: {j}\\nclean: {c}\")    \n",
    "            for i in glob(\"GMJ*csv\")+glob(\"*GMJ*int*csv\")+glob('*h5'):\n",
    "                os.remove(i)\n",
    "            DDCASPT2('./','ANO-RCC-VDZP','H2',2,2,0,previous=None,symmetry=1,spin=0,UHF=False,charge=0,clean=c,n_jobs=j)(run=True)\n",
    "            parallelfeat = pd.read_csv('H2.csv',compression='zip',index_col=0)\n",
    "            serialfeat = pd.read_csv('../new_DDCASPT2/H2.csv',compression='zip',index_col=0)\n",
    "            print(f\"H2={(parallelfeat == serialfeat).all().all()}\")\n",
    "            print((parallelfeat == serialfeat).all()[~(parallelfeat == serialfeat).all()])\n",
    "            print(*pd.read_excel('H2_energies.xlsx',index_col=0).loc['E2'].values,parallelfeat['Pair_Energies'].sum())\n",
    "        \n",
    "            DDCASPT2('./','ANO-RCC-VDZP','O3_106.00',4,3,10,previous=None,symmetry=1,spin=0,UHF=False,charge=0,clean=c,n_jobs=j)(run=True)\n",
    "            parallelfeat = pd.read_csv('O3_106.00.csv',compression='zip',index_col=0)\n",
    "            # serialfeat = pd.read_csv('../new_DDCASPT2/O3_106.00.csv',compression='zip',index_col=0)\n",
    "            # print(f\"O3={(parallelfeat == serialfeat).all().all()}\")\n",
    "            # print((parallelfeat == serialfeat).all()[~(parallelfeat == serialfeat).all()])\n",
    "            print(*pd.read_excel('O3_106.00_energies.xlsx',index_col=0).loc['E2'].values,parallelfeat['Pair_Energies'].sum())\n",
    "            print()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3298c1-1d4e-4603-b076-da29470ebdae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
